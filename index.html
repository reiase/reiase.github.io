
<!DOCTYPE html>

<html class="no-js" lang="zh">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Overfitting: Where we deliberately dive too deep into ML algorithms,  mathematical principles and hardware implementations." name="description"/>
<meta content="reiase &lt;reiase@gmail.com&gt;" name="author"/>
<link href="https://reiase.github.io/" rel="canonical"/>
<link href="category/ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/" rel="next"/>
<link href="assets/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.6.21" name="generator"/>
<title>Blog - Overfitting: From Algorithms to Silicon</title>
<link href="assets/stylesheets/main.2a3383ac.min.css" rel="stylesheet"/>
<link href="assets/stylesheets/palette.06af60db.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Source+Han+Sans+SC:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Source Han Sans SC";--md-code-font:"Roboto Mono"}</style>
<link href="assets/_markdown_exec_pyodide.css" rel="stylesheet"/>
<link href="extra.css" rel="stylesheet"/>
<script>__md_scope=new URL(".",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-LMDTYMWWTF"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-LMDTYMWWTF",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-LMDTYMWWTF",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
 <link href="assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="indigo" data-md-color-primary="indigo" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#blog">
          跳转至
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="页眉" class="md-header__inner md-grid">
<a aria-label="Overfitting: From Algorithms to Silicon" class="md-header__button md-logo" data-md-component="logo" href="." title="Overfitting: From Algorithms to Silicon">
<svg viewbox="0 0 89 89" xmlns="http://www.w3.org/2000/svg">
<path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z"></path>
<path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5"></path>
<path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z"></path>
<path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25"></path>
</svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Overfitting: From Algorithms to Silicon
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Blog
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary="indigo" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4M7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3"></path></svg>
</label>
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="indigo" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary="black" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_0" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3"></path></svg>
</label>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="搜索" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="搜索" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="查找" class="md-search__options">
<a aria-label="分享" class="md-search__icon md-icon" data-clipboard="" data-clipboard-text="" data-md-component="search-share" href="javascript:void(0)" tabindex="-1" title="分享">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg>
</a>
<button aria-label="清空当前内容" class="md-search__icon md-icon" tabindex="-1" title="清空当前内容" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
<div class="md-search__suggest" data-md-component="search-suggest"></div>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<nav aria-label="标签" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href=".">
          
  
  
    
  
  博客

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="tags/">
        
  
  
    
  
  标签

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="nodes/AdamW/">
          
  
  
    
  
  代码片段

        </a>
</li>
</ul>
</div>
</nav>
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="导航栏" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Overfitting: From Algorithms to Silicon" class="md-nav__button md-logo" data-md-component="logo" href="." title="Overfitting: From Algorithms to Silicon">
<svg viewbox="0 0 89 89" xmlns="http://www.w3.org/2000/svg">
<path d="M3.136,17.387l0,42.932l42.932,21.467l-42.932,-64.399Z"></path>
<path d="M21.91,8l42.933,64.398l-18.775,9.388l-42.932,-64.399l18.774,-9.387Z" style="fill-opacity: 0.5"></path>
<path d="M67.535,17.387l-27.262,18.156l21.878,32.818l5.384,2.691l0,-53.665Z"></path>
<path d="M67.535,17.387l0,53.666l18.774,-9.388l0,-53.665l-18.774,9.387Z" style="fill-opacity: 0.25"></path>
</svg>
</a>
    Overfitting: From Algorithms to Silicon
  </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_1" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link md-nav__link--active" href=".">
<span class="md-ellipsis">
    博客
    
  </span>
</a>
<label class="md-nav__link md-nav__link--active" for="__nav_1" id="__nav_1_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_1_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_1">
<span class="md-nav__icon md-icon"></span>
            博客
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_1_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_1_2" id="__nav_1_2_label" tabindex="">
<span class="md-ellipsis">
    归档
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_1_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_2">
<span class="md-nav__icon md-icon"></span>
            归档
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="archive/2025/">
<span class="md-ellipsis">
    2025
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="archive/2024/">
<span class="md-ellipsis">
    2024
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_1_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_1_3" id="__nav_1_3_label" tabindex="">
<span class="md-ellipsis">
    分类
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_1_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_1_3">
<span class="md-nav__icon md-icon"></span>
            分类
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="category/ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/">
<span class="md-ellipsis">
    AI基础设施
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="category/fp8/">
<span class="md-ellipsis">
    FP8
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="category/llm/">
<span class="md-ellipsis">
    LLM
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="category/rl/">
<span class="md-ellipsis">
    RL
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="category/training/">
<span class="md-ellipsis">
    Training
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="category/training-dynamics/">
<span class="md-ellipsis">
    Training Dynamics
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="category/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">
<span class="md-ellipsis">
    分布式训练
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="tags/">
<span class="md-ellipsis">
    标签
    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
<span class="md-ellipsis">
    代码片段
    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            代码片段
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="nodes/AdamW/">
<span class="md-ellipsis">
    AdamW
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="nodes/Importance%20Sampling/">
<span class="md-ellipsis">
    Importance Sampling
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="nodes/Minorize%20Maximization/">
<span class="md-ellipsis">
    Minorize-Maximization
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="nodes/Random%20Round/">
<span class="md-ellipsis">
    Random Round
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="nodes/Scaling%20Law%20%E8%AE%A1%E7%AE%97%E5%99%A8/">
<span class="md-ellipsis">
    Scaling Law 计算器
    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="nodes/kaplan%20vs%20chinchilla/">
<span class="md-ellipsis">
    Kaplan Scaling Law vs Chinchilla Optimal
    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="目录" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      目录
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#nvidia">
<span class="md-ellipsis">
      深度解析NVIDIA的超节点架构演进
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#probingprofiling">
<span class="md-ellipsis">
      Probing分布式探针开发随笔（三）：分布式训练的Profiling
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#probing">
<span class="md-ellipsis">
      Probing分布式探针开发随笔（二）：探针机制
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#probing">
<span class="md-ellipsis">
      Probing分布式探针开发随笔（一）：背景与设计理念
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#training-dynamicsoutlierllm">
<span class="md-ellipsis">
      从Training Dynamics到Outlier——LLM模型训练过程中的数值特性分析
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#int8">
<span class="md-ellipsis">
      INT8也能训练
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#deepseek-v3fp8">
<span class="md-ellipsis">
      从DeepSeek V3看FP8训练的挑战
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#deepseek-r1">
<span class="md-ellipsis">
      从强化学习到DeepSeek R1
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#_1">
<span class="md-ellipsis">
      关于分布式模型并行的分正式评论
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#scaling-law">
<span class="md-ellipsis">
      关于Scaling Law的非正式评论
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<div class="md-content__inner">
<header class="md-typeset">
<h1 id="blog">Blog<a class="headerlink" href="#blog" title="Permanent link">¶</a></h1>
</header>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2025-10-01 00:00:00+00:00">2025年10月1日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/">AI基础设施</a>, 
              <a class="md-meta__link" href="category/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/">分布式训练</a></li>
<li class="md-meta__item">
            
              需要 12 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="nvidia"><a class="toclink" href="2025/10/01/superpod-ai-architecture/">深度解析NVIDIA的超节点架构演进</a></h2>
<p><em>本文为原创文章，版权归作者所有。未经许可，禁止转载。</em></p>
<p>超节点无疑是过去半年最为火热的一个概念。从NVIDIA发布NVL72，宣称单套系统提供 <strong>1,440 PFLOPS</strong> 算力；到华为的CloudMatrix 384号称提供 <strong>300 PFLOPs FP16算力</strong> ，达到英伟达GB200 NVL72系统（约180 PFLOPs）的 <strong>近两倍</strong> 。各家国产GPU厂商也普遍不甘示弱，纷纷推出了自己的32卡或64卡超节点方案。互联协议作为兵家必争之地，连阿里、腾讯和字节都不甘示弱投身其中。从UALink、ALS（阿里）、Eth-X（腾讯），再到OSIA（中移动）、EthLink（字节），大有大鸣大放的趋势。大家看起来像是从一场盛宴赶赴另一场盛宴，唯恐拿不到入场卷。每个人都身着时髦的礼服，彼此紧张地打量着，但是没人知道自己能否坚持到这场盛宴结束，只能寄希望于运气，或者自己在漂亮的小礼服上下得一点点小心思，比如一根羽毛或者一块亮片。而场外NVIDIA和华为则把自己武装到了牙齿…</p>
<p>这就是研究了一个月下来的感受，超节点远不止堆砌服务器和GPU那么简单，远不止用高速互联代替RDMA。那么到底什么是超节点呢？</p>
<h3 id="_1"><a class="toclink" href="2025/10/01/superpod-ai-architecture/#_1">什么是超节点</a></h3>
<p>超节点是借助高速无损互联技术，突破传统计算节点以CPU和PCIe总线为核心的通信边界，构建的新一代计算架构。<strong>在硬件互联层面</strong>，超节点采用NVLink、CXL或专用交换网络等先进互连协议，在加速卡（GPU/NPU）之间构建了高带宽、低延迟的直接通信域（Scale-Up Domain，或称高带宽域，High Bandwidth Domain, HBD）。这种设计实现了计算单元间的大规模高效互连，缓解了传统架构中因GPU间通信必须经由CPU与PCIe总线而形成的性能瓶颈，为海量数据并行处理奠定了物理基础。<strong>在软件与系统层面</strong>，其资源管理范式也随之转变：硬件间的高速通信通常直接绕过（bypass）操作系统内核繁复的协议栈，转而通过用户态集合通信库（如NCCL、HCCL）进行调度，从而显著降低通信开销。</p>
<h4 id="nvidia_1"><a class="toclink" href="2025/10/01/superpod-ai-architecture/#nvidia_1">NVIDIA超节点产品</a></h4>
<p>2020年，NVIDIA在其推出的HGX-A100系统中，通过第二代NVSwitch将两个八卡A100以背板方式连接，构成一个16卡系统。2022年，随Hopper架构推出的第三代NVSwitch支持更灵活的组网方式，能够实现32颗GH200（32x GPU）的互联（NVL32）<sup id="fnref:gh200"><a class="footnote-ref" href="2025/10/01/superpod-ai-architecture/#fn:gh200">1</a></sup>，最大可实现256颗GH100的互联（NVL256）。2024年Blackwell发布时，第四代NVSwitch能够实现36个GB200超级芯片（共72颗GPU）的互联（NVL72）<sup id="fnref:gb200"><a class="footnote-ref" href="2025/10/01/superpod-ai-architecture/#fn:gb200">2</a></sup>，最大支持288个GB200超级芯片（共576颗GPU）的互联。未来的Vera Rubin系列将进一步实现144个超级芯片的互联。以下是Hopper与Blackwell两代GPU所对应的超节点产品：</p>
<table>
<thead>
<tr>
<th style="text-align: right;">参数</th>
<th style="text-align: center;">NVL32</th>
<th style="text-align: center;">GH200 SuperPod</th>
<th style="text-align: center;">NVL72</th>
<th style="text-align: center;">GB200 SuperPod</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: right;"><strong>架构</strong></td>
<td style="text-align: center;">Hopper</td>
<td style="text-align: center;">Hopper</td>
<td style="text-align: center;">Blackwell</td>
<td style="text-align: center;">Blackwell</td>
</tr>
<tr>
<td style="text-align: right;"><strong>HBM 大小</strong></td>
<td style="text-align: center;">32 x 144GB = 4.6 TB</td>
<td style="text-align: center;">256 x 96GB = 24.5 TB</td>
<td style="text-align: center;">36 x 384GB = 13.8 TB</td>
<td style="text-align: center;">288 x 384GB = 110 TB</td>
</tr>
<tr>
<td style="text-align: right;"><strong>LPDDR5X 大小</strong></td>
<td style="text-align: center;">32 x 480GB = 15.4 TB</td>
<td style="text-align: center;">256 x 480GB = 123 TB</td>
<td style="text-align: center;">36 x 480GB = 17.3 TB</td>
<td style="text-align: center;">288 x 480GB = 138 TB</td>
</tr>
<tr>
<td style="text-align: right;"><strong>HBM 带宽</strong></td>
<td style="text-align: center;">3.35 TB/s</td>
<td style="text-align: center;">4.8 TB/s</td>
<td style="text-align: center;">8 TB/s</td>
<td style="text-align: center;">8 TB/s</td>
</tr>
<tr>
<td style="text-align: right;"><strong>FP16 (FLOPS)</strong></td>
<td style="text-align: center;">32 PetaFLOPS</td>
<td style="text-align: center;">256 PetaFLOPS</td>
<td style="text-align: center;">180 PetaFLOPS</td>
<td style="text-align: center;">1440 PetaFLOPS</td>
</tr>
<tr>
<td style="text-align: right;"><strong>INT8 (OPS)</strong></td>
<td style="text-align: center;">64 PetaOPS</td>
<td style="text-align: center;">64 PetaOPS</td>
<td style="text-align: center;">360 PetaOPS</td>
<td style="text-align: center;">2880 PetaOPS</td>
</tr>
<tr>
<td style="text-align: right;"><strong>FP8 (FLOPS)</strong></td>
<td style="text-align: center;">64 PetaFLOPS</td>
<td style="text-align: center;">64 PetaFLOPS</td>
<td style="text-align: center;">360 PetaFLOPS</td>
<td style="text-align: center;">2880 PetaFLOPS</td>
</tr>
<tr>
<td style="text-align: right;"><strong>FP6 (FLOPS)</strong></td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">360 PetaFLOPS</td>
<td style="text-align: center;">2880 PetaFLOPS</td>
</tr>
<tr>
<td style="text-align: right;"><strong>FP4 (FLOPS)</strong></td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">N/A</td>
<td style="text-align: center;">720 PetaFLOPS</td>
<td style="text-align: center;">5760 PetaFLOPS</td>
</tr>
<tr>
<td style="text-align: right;"><strong>GPU-GPU 带宽</strong></td>
<td style="text-align: center;">0.9 TB/s</td>
<td style="text-align: center;">0.9 TB/s</td>
<td style="text-align: center;">1.8 TB/s</td>
<td style="text-align: center;">1.8 TB/s</td>
</tr>
<tr>
<td style="text-align: right;"><strong>NVSwitch</strong></td>
<td style="text-align: center;">Gen3 64 Port</td>
<td style="text-align: center;">Gen3 64 Port</td>
<td style="text-align: center;">Gen4 72 Port</td>
<td style="text-align: center;">Gen4 72 Port</td>
</tr>
<tr>
<td style="text-align: right;"><strong>NVLink 带宽</strong></td>
<td style="text-align: center;">36 x 0.9 TB/s = 32 TB/s</td>
<td style="text-align: center;">256 x 0.9 TB/s = 230 TB/s</td>
<td style="text-align: center;">72 x 1.8 TB/s = 130 TB/s</td>
<td style="text-align: center;">576 x 1.8 TB/s = 1 PB/s</td>
</tr>
<tr>
<td style="text-align: right;"><strong>Ethernet 带宽</strong></td>
<td style="text-align: center;">16 x 200 Gb/s</td>
<td style="text-align: center;">256 x 200 Gb/s</td>
<td style="text-align: center;">18 x 400 Gb/s</td>
<td style="text-align: center;">576 x 400 Gb/s</td>
</tr>
<tr>
<td style="text-align: right;"><strong>IB 带宽</strong></td>
<td style="text-align: center;">32 x 400 Gb/s</td>
<td style="text-align: center;">256 x 400 Gb/s</td>
<td style="text-align: center;">72 x 800 Gb/s</td>
<td style="text-align: center;">576 x 800 Gb/s</td>
</tr>
<tr>
<td style="text-align: right;"><strong>GPUs Power</strong></td>
<td style="text-align: center;">32 x 1 kW = 32 kW</td>
<td style="text-align: center;">256 x 1 kW = 256 kW</td>
<td style="text-align: center;">36 x 2.7 kW = 97.2 kW</td>
<td style="text-align: center;">Not provided</td>
</tr>
</tbody>
</table>
<h4 id="_2"><a class="toclink" href="2025/10/01/superpod-ai-architecture/#_2">超节点技术趋势分析</a></h4>
<p>在2022年Hopper架构发布之际，NVIDIA提出了十年内GPU算力增长1000倍的“黄氏定律” (Huang’s Law)<sup id="fnref:huangs_law"><a class="footnote-ref" href="2025/10/01/superpod-ai-architecture/#fn:huangs_law">3</a></sup>。其中，低精度数值格式、Tensor Core和工艺进步分别贡献了约16倍、12倍和2.5倍的算力提升。这揭示出NVIDIA是一家系统供应商而非单纯的芯片供应商，其算力增长并非仅依赖芯片本身。</p>
<p>回顾从Volta到Rubin系列的演进，NVIDIA的技术战略非常清晰：<strong>通过算力、互联、存储和封装等多个维度的协同创新，实现系统层面的指数级性能增长</strong> 。其目标是每两年提供约6倍的系统算力提升，并计划在十年内实现7000倍的增长（若考虑芯片在低精度和稀疏上能力的进步，这个增长可能超过10000倍）。这种复合式增长并非依赖单一技术突破，而是通过一套精心设计的“组合策略”实现：</p>
<ul>
<li><strong>单芯片算力</strong>：每代提升约3倍。</li>
<li><strong>Scale-Up域</strong>：互联规模和带宽同步翻倍。</li>
<li><strong>内存系统</strong>：HBM带宽翻倍，容量提升3倍。</li>
</ul>
<nav class="md-post__action">
<a href="2025/10/01/superpod-ai-architecture/">
          继续阅读
        </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2025-04-28 00:00:00+00:00">2025年4月28日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a>, 
              <a class="md-meta__link" href="category/training/">Training</a></li>
<li class="md-meta__item">
            
              需要 4 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="probingprofiling"><a class="toclink" href="2025/04/28/dist_probe_3/">Probing分布式探针开发随笔（三）：分布式训练的Profiling</a></h2>
<p>在前两篇系列文章中，介绍了 Probing 分布式探针的核心理念与技术探索，包括其应对 ABI 兼容性挑战的动态注入机制，以及基于 DataFusion 构建的可扩展查询引擎。虽然仍处于技术原型阶段，但也确实看到了实现一个“完美”工具的可能性。最近在解决某千卡训练项目时，浪费了大量时间在实验、抓数据与复现等工作上，越来越感觉到传统工具的限制，也越来越急迫地需要将Probing推向生产。</p>
<h3 id="profiler"><a class="toclink" href="2025/04/28/dist_probe_3/#profiler">传统Profiler的困境</a></h3>
<p>Profiling是性能优化工程师最为主要的优化手段，为了分析性能我们有形形色色的Profiler工具。大到Intel VTune和Nvidia Insight这种系列工具，有着完备的分析工具与可视化手段，很多问题都能一目了然；小到<code>perf top</code>这样”简陋”的调用栈采样工具，得边看边猜整个系统的行为。但是这些工具有一个共同的问题：他们都是单机工具，并不能很好的解决分布式系统中的性能问题。比如，PyTorch提供了<code>torch.profiler</code>，一个强大的内置性能分析工具，使用也极为方便：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch.profiler</span><span class="w"> </span><span class="kn">import</span> <span class="n">profile</span><span class="p">,</span> <span class="n">CPU</span><span class="p">,</span> <span class="n">CUDA</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>
</span><span id="__span-0-3"><a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="k">with</span> <span class="n">profile</span><span class="p">(</span><span class="n">activities</span><span class="o">=</span><span class="p">[</span><span class="n">CPU</span><span class="p">,</span> <span class="n">CUDA</span><span class="p">])</span> <span class="k">as</span> <span class="n">prof</span><span class="p">:</span>
</span><span id="__span-0-4"><a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
</span><span id="__span-0-5"><a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>        <span class="n">train_one_step</span><span class="p">()</span>
</span><span id="__span-0-6"><a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>        <span class="n">prof</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></code></pre></div>
<p><code>torch.profiler</code>能够抓取PyTorch中的算子执行与显存分配行为，并且可以通过Tensorboard对结果进行可视化。但对于千卡规模的分布式训练，<code>torch.profiler</code>还远远不够用：</p>
<ol>
<li>性能开销问题：profiler会显著影响性能，导致Profiling结果不准确；</li>
<li>数据爆炸：单卡长生上G的数据，千卡需要上T存储；</li>
<li>缺乏协调：各节点数据相互独立，难以进行关联分析，特别是引入模型并行之后；</li>
</ol>
<h3 id="timeline"><a class="toclink" href="2025/04/28/dist_probe_3/#timeline">思路转变：从Timeline到统计方法</a></h3>
<h4 id="timeline_1"><a class="toclink" href="2025/04/28/dist_probe_3/#timeline_1">Timeline困境</a></h4>
<p>单节点的性能分析中，Timeline技术备受追捧。原因无他：直观，每个阶段的执行，开销的资源与消耗的时间都可以在一个时间轴上精确展示出来。但是Timeline数据庞大，并且借助浏览器渲染时速度也欠佳。几个G的Timeline数据很快会让你的笔记本成为一个小火炉。Timeline也存在明显的局限性：</p>
<ul>
<li>一般只能分析单个节点单个Step：</li>
<li>多节点多Step的数据，看不过来（虽然有些人在此会很倔强）；</li>
<li>每个Step都有差异，导致难以给出结论（可以给定性结论，但结论复现存在难度）；</li>
<li>难以捕捉这个系统的随机性与不确定性：</li>
<li>单个节点单个Step是确定的，但是一千个节点的同一个Step，充满了随机性；</li>
<li>Timeline无法刻画出整个系统性能层面的统计特性，比如耗时的99线；</li>
<li>忽略了负载不均衡现象：</li>
<li>在经典的Dense LLM中，因为模型并行会导致每个节点实际负载各不相同；</li>
<li>在流行的MoE LLM中，专家路由也会导致计算负载不均衡问题；</li>
</ul>
<p>上述这些问题难以在Timeline框架下靠修修补补来解决：</p>
<ol>
<li>
<p>在由上千节点与数千线缆构成的复杂计算集群中，节点与节点间互联必然存在随机性与不确定性，这正是分布式系统的核心挑战。因此，分布式系统的性能分析需要从单节点上精准timeline的个体样本方法**转向能够描述随机性与整体特性的统计方法**。</p>
</li>
<li>
<p>单节点的Profiling数据量非常巨大，却又缺乏有效的数据压缩与处理手段。单机尚能撑住，扩展到千卡集群就直接原地爆炸。分布式Profiling必然需要**转向现代化的数据基建，全面拥抱分布式的数据存储与分析技术**。</p>
</li>
<li>
<p>分布式系统中很难保证时间一致与时间精度，多机timeline很难进行对齐，也很难可视化分析（可以想象下一千张卡的timelime等你去看）。<strong>如何在不依赖精准时间戳的情况下进行数据关联分析、识别性能异常节点(Stragglers)，也成为分布式系统性能分析的关键挑战</strong>。</p>
</li>
</ol>
<h5 id="_1"><a class="toclink" href="2025/04/28/dist_probe_3/#_1">分布式系统的统计思想</a></h5>
<p>分布式系统最常见的性能分析范式是分布式Tracing，如OpenTelemetry这类系统已在微服务领域取得了成功，这些系统的核心理念可以适配到分布式训练环境：</p>
<ol>
<li>
<p><strong>借鉴Span概念</strong>：将训练过程分解自顶向下的、嵌套的span。前向传播、反向传播作为顶级Span，每个layer的计算作为子Span。这种层次化的视图只需要明确层次关系，而无须精确的时间戳对齐。</p>
</li>
<li>
<p><strong>优化采样策略</strong>：不同于timeline的全量采样，分布式profiling可以通过设计采样策略来控制开销：<br/>
   - 结构化采样：根据模型结构进行采样而非完全随机采样；<br/>
   - 分布式采样：将采样操作分布到不同的节点，降低每个节点的采样量；</p>
</li>
<li>
<p><strong>分析效率</strong>：模型训练中每个span内的计算量与通信量可以精确计算，结合span计时即可分析每一段时间的硬件利用率与瓶颈，而无须像timeline那样精需要精准的时间信息。</p>
</li>
<li>
<p><strong>统计视角替代精确时间线</strong>：关注分布特性（均值、中位数、百分位数）而非单个精确时间点，使问题分析更符合分布式系统的随机性特质。</p>
</li>
</ol>
<p>不过分布式训练的通信模式是集合通信而非调用树，可以尝试为训练系统单独设计一套分布式Profiling方案。</p>
<h3 id="profiling"><a class="toclink" href="2025/04/28/dist_probe_3/#profiling">基于探针的分布式Profiling</a></h3>
<p>训练系统分布式Profiling需要克服的主要困难有两个：</p>
<ol>
<li>没有配套的数据系统：训练过程中的数据大多数没有业务价值，不会配套专门的数据处理与存储系统；</li>
<li>数据量庞大：每个GPU在一个训练Step内就会产生数万个事件，而总数据量会随着step树与节点数增长而快速爆炸；</li>
</ol>
<p>Probing 的解决方案是：<strong>本地化存储数据 + 分布式查询分析</strong>，将数据存储和分析的压力分散到每个节点上。以下是一个简单的示意图，用于说明理想情况下probing如何工作：</p>
<pre class="mermaid"><code>---
title: Probing 分布式 Profiling 架构
---
graph TD
    subgraph "控制平面 (用户)"
        UI[Web UI]
        CLI[命令行]
        API[SQL查询+HTTP协议]
        UI &amp; CLI --&gt; API
    end

    subgraph "分布式训练集群"
        direction LR
        subgraph "Node 1 (Rank 0)"
            P1[训练进程 Rank 0]
            PR1[Probe]
            H1[采集Hooks e.g., PyTorch]
            P1 --&gt; H1 -- 本地数据 --&gt; PR1
        end
        subgraph "Node 2 (Rank 1)"
            P2[训练进程 Rank 1]
            PR2[Probe]
            H2[采集Hooks e.g., PyTorch]
            P2 --&gt; H2 -- 本地数据 --&gt; PR2
        end
        subgraph "Node N (Rank N-1)"
            PN[训练进程 Rank N-1]
            PRN[Probe]
            HN[采集Hooks e.g., PyTorch]
            PN --&gt; HN -- 本地数据 --&gt; PRN
        end
    end

    API -- SQL查询 --&gt; PR1;
    PR1 -- 分布式查询协调 --&gt; PR2;
    PR1 -- 分布式查询协调 --&gt; PRN;
    PR2 -- 本地查询/聚合 --&gt; PR2;
    PRN -- 本地查询/聚合 --&gt; PRN;
    PR2 -- 部分结果 --&gt; PR1;
    PRN -- 部分结果 --&gt; PR1;
    PR1 -- 最终聚合 --&gt; API;

    style P1 fill:#f9f,stroke:#333
    style P2 fill:#f9f,stroke:#333
    style PN fill:#f9f,stroke:#333
    style PR1 fill:#bfb,stroke:#333
    style PR2 fill:#bfb,stroke:#333
    style PRN fill:#bfb,stroke:#333
    style H1 fill:#ccf,stroke:#333
    style H2 fill:#ccf,stroke:#333
    style HN fill:#ccf,stroke:#333</code></pre>
<p>在这个架构下，可以借助分布式查询系统，将过滤、采样与聚合操作下推到每个节点去执行，并结合良好设计的采样机制与策略来平衡性能分析的精度与开销。接下来是在这个架构下设计数据采集、存储和分析的链路</p>
<h4 id="_2"><a class="toclink" href="2025/04/28/dist_probe_3/#_2">采集链路</a></h4>
<h5 id="_3"><a class="toclink" href="2025/04/28/dist_probe_3/#_3">基于钩子的数据采集</a></h5>
<p>虽然修改代码加日志是最直观的数据采集手段，也日志往往过于随意、缺乏设计，为后续的分析与使用带来困难。不修改代码采集数据就需要对代码进行自动插桩。好在PyTorch提供了钩子（Hooks）机制，能够”不侵入”代码的情况下完成插桩。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="kn">from</span><span class="w"> </span><span class="nn">torch.optim.optimizer</span><span class="w"> </span><span class="kn">import</span> <span class="n">register_optimizer_step_post_hook</span>
</span><span id="__span-1-2"><a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a>
</span><span id="__span-1-3"><a href="#__codelineno-1-3" id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="n">register_optimizer_step_post_hook</span><span class="p">(</span><span class="n">optimizer_step_post_hook</span><span class="p">)</span>
</span></code></pre></div>
<p><code>register_optimizer_step_post_hook</code> 帮我们向torch注册一个钩子函数，在每个Optimzier完成<code>step()</code>调用后执行。这个插桩时机极为关键：</p>
<ol>
<li>模型已完成构建，可获取完整模型定义</li>
<li>前向传播、反向传播与优化器都已完成预热</li>
</ol>
<p>接下来，借助Python的垃圾回收(GC)机制与反射能力来捕获进程中的模型结构：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">get_toplevel_module</span><span class="p">():</span>
</span><span id="__span-2-2"><a href="#__codelineno-2-2" id="__codelineno-2-2" name="__codelineno-2-2"></a>    <span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
</span><span id="__span-2-3"><a href="#__codelineno-2-3" id="__codelineno-2-3" name="__codelineno-2-3"></a>
</span><span id="__span-2-4"><a href="#__codelineno-2-4" id="__codelineno-2-4" name="__codelineno-2-4"></a>    <span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
</span><span id="__span-2-5"><a href="#__codelineno-2-5" id="__codelineno-2-5" name="__codelineno-2-5"></a>
</span><span id="__span-2-6"><a href="#__codelineno-2-6" id="__codelineno-2-6" name="__codelineno-2-6"></a>    <span class="n">objs</span> <span class="o">=</span> <span class="p">[</span><span class="n">obj</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">gc</span><span class="o">.</span><span class="n">get_objects</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)]</span>
</span><span id="__span-2-7"><a href="#__codelineno-2-7" id="__codelineno-2-7" name="__codelineno-2-7"></a>    <span class="n">is_child</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
</span><span id="__span-2-8"><a href="#__codelineno-2-8" id="__codelineno-2-8" name="__codelineno-2-8"></a>    <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objs</span><span class="p">:</span>
</span><span id="__span-2-9"><a href="#__codelineno-2-9" id="__codelineno-2-9" name="__codelineno-2-9"></a>        <span class="k">for</span> <span class="n">child</span> <span class="ow">in</span> <span class="n">obj</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
</span><span id="__span-2-10"><a href="#__codelineno-2-10" id="__codelineno-2-10" name="__codelineno-2-10"></a>            <span class="n">is_child</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">child</span><span class="p">))</span>
</span><span id="__span-2-11"><a href="#__codelineno-2-11" id="__codelineno-2-11" name="__codelineno-2-11"></a>    <span class="k">return</span> <span class="p">[</span><span class="n">obj</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">objs</span> <span class="k">if</span> <span class="nb">id</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">is_child</span><span class="p">]</span>
</span></code></pre></div>
<p>通过<code>gc</code>模块我们可以获得当前进程中的全部Python对象列表，再通过反射调用<code>isinstance(obj, torch.nn.Module)</code>找出全部<code>torch.nn.Module</code>对象。最后再根据module之间的父子关系来发现顶层Module。</p>
<p>获取顶层Module后，我们可以注册完整的前向/反向传播钩子链，完成接下来的插桩：</p>
<ol>
<li>Module.register_forward_pre_hook - 前向传播开始前</li>
<li>Module.register_forward_hook - 前向传播完成后</li>
<li>Module.register_full_backward_pre_hook - 反向传播开始前</li>
<li>Module.register_full_backward_hook - 反向传播完成后</li>
<li>Optimizer.register_step_pre_hook - 优化器步骤开始前</li>
<li>Optimizer.register_step_post_hook - 优化器步骤完成后</li>
</ol>
<p>这些钩子构成了训练过程中的完整监控链，允许我们精确测量模型各组件的执行性能。</p>
<h5 id="_4"><a class="toclink" href="2025/04/28/dist_probe_3/#_4">结构化采样</a></h5>
<p>考虑到PyTorch模型包含大量嵌套子模块，对每个模块都执行计时操作会带来显著性能开销。随机采样虽然能够降低插桩的开销，但需要等待较长时间才能保证采样充分。这里我们引入一种结构化采样方法来加速性能数据的采集：</p>
<ol>
<li>span分解：将模型执行分解为一系列span，每个module的前向和反向传播分别构成独立span</li>
<li>层次化排序：按照嵌套关系对span进行排序<ul>
<li>粗粒度span（如整个模型的前向传播）排序靠前</li>
<li>细粒度span（如单个卷积层的操作）排序靠后</li>
</ul>
</li>
<li>自适应采样：从粗到细逐步采样<ul>
<li>命中采样时，记录当前span计时，并移至下一个span</li>
<li>未命中采样时，跳过计算以减少开销</li>
</ul>
</li>
</ol>
<p>这种结构化采样确保每个训练步骤只对一个特定粒度的span进行采样，使模型性能分析由粗到细逐步进行，在控制开销的同时提供全面性能视图。</p>
<h4 id="cuda-event"><a class="toclink" href="2025/04/28/dist_probe_3/#cuda-event">基于CUDA Event的精确计时</a></h4>
<p>GPU上异步执行的计时通常通过CUDA Event来实现。CUDA Event能保证在CUDA Stream上的执行顺序，并且是测量GPU操作时间的最准确方式。一个CUDA Event的生命周期包括以下几个阶段：</p>
<ol>
<li>创建(Create)：通过torch.cuda.Event()或CUDA原生API创建Event对象</li>
<li>记录(Record)：通过event.record()将Event标记到特定CUDA Stream的当前位置</li>
<li>同步(Synchronize)：通过event.synchronize()等待Event标记的操作完成</li>
<li>查询(Query)：通过event.query()非阻塞地检查Event是否完成</li>
<li>计时(Elapsed Time)：通过start_event.elapsed_time(end_event)计算两个Event之间的时间差</li>
</ol>
<p>在实际应用中，同步(Synchronize)操作会导致GPU等待并强制Stream清空，可能显著影响性能。为解决这一问题，我们采用延迟计时(Delayed Timing)策略，将时间读取推迟到优化器执行完成后进行。这种方法有效降低了计时操作对训练性能的干扰，特别适合分布式训练环境。</p>
<h3 id="_5"><a class="toclink" href="2025/04/28/dist_probe_3/#_5">基于统计的性能/故障分析方法</a></h3>
<p>在大规模分布式训练环境中，我们面临的不仅是如何采集数据，更重要的是如何有效利用这些数据发现并解决问题。Probing采用统计分析方法，将分散在各节点的性能数据转化为可操作的洞察。</p>
<h4 id="_6"><a class="toclink" href="2025/04/28/dist_probe_3/#_6">分布式训练中的常见性能问题</a></h4>
<p>在实践中，分布式训练的性能问题通常表现为以下几种典型模式：</p>
<ol>
<li>慢节点(Straggler)问题：个别节点显著慢于集群平均水平，拖慢整体训练进度</li>
<li>负载不均衡：计算或内存负载在节点间分布不均，导致资源利用率低下</li>
<li>通信瓶颈：节点间数据交换速度不足，制约训练效率提升</li>
<li>异常波动：性能指标在时间维度上出现突发性异常</li>
<li>集群分层：性能根据硬件配置或网络拓扑自然分层，形成性能梯队利用统计数据定位问题</li>
</ol>
<h4 id="_7"><a class="toclink" href="2025/04/28/dist_probe_3/#_7">节点性能差异分析</a></h4>
<p>通过简单SQL查询，我们可以快速识别集群中的异常节点：</p>
<div class="language-SQL highlight"><pre><span></span><code><span id="__span-3-1"><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="c1">-- 查找前向传播耗时异常的节点</span>
</span><span id="__span-3-2"><a href="#__codelineno-3-2" id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="k">SELECT</span><span class="w"> </span>
</span><span id="__span-3-3"><a href="#__codelineno-3-3" id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="w">    </span><span class="n">rank</span><span class="p">,</span><span class="w"> </span>
</span><span id="__span-3-4"><a href="#__codelineno-3-4" id="__codelineno-3-4" name="__codelineno-3-4"></a><span class="w">    </span><span class="k">AVG</span><span class="p">(</span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">avg_forward_time</span><span class="p">,</span>
</span><span id="__span-3-5"><a href="#__codelineno-3-5" id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="w">    </span><span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">sample_count</span><span class="p">,</span>
</span><span id="__span-3-6"><a href="#__codelineno-3-6" id="__codelineno-3-6" name="__codelineno-3-6"></a><span class="w">    </span><span class="p">(</span><span class="k">AVG</span><span class="p">(</span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span>
</span><span id="__span-3-7"><a href="#__codelineno-3-7" id="__codelineno-3-7" name="__codelineno-3-7"></a><span class="w">     </span><span class="p">(</span><span class="k">SELECT</span><span class="w"> </span><span class="k">AVG</span><span class="p">(</span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">torch_traces</span><span class="w"> </span><span class="k">WHERE</span><span class="w"> </span><span class="k">operation</span><span class="o">=</span><span class="s1">'forward'</span><span class="p">))</span><span class="w"> </span>
</span><span id="__span-3-8"><a href="#__codelineno-3-8" id="__codelineno-3-8" name="__codelineno-3-8"></a><span class="w">     </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="k">SELECT</span><span class="w"> </span><span class="n">STDDEV</span><span class="p">(</span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">torch_traces</span><span class="w"> </span><span class="k">WHERE</span><span class="w"> </span><span class="k">operation</span><span class="o">=</span><span class="s1">'forward'</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-3-9"><a href="#__codelineno-3-9" id="__codelineno-3-9" name="__codelineno-3-9"></a><span class="w">     </span><span class="k">as</span><span class="w"> </span><span class="n">z_score</span>
</span><span id="__span-3-10"><a href="#__codelineno-3-10" id="__codelineno-3-10" name="__codelineno-3-10"></a><span class="k">FROM</span><span class="w"> </span><span class="n">python</span><span class="p">.</span><span class="n">torch_traces</span>
</span><span id="__span-3-11"><a href="#__codelineno-3-11" id="__codelineno-3-11" name="__codelineno-3-11"></a><span class="k">WHERE</span><span class="w"> </span><span class="k">operation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'forward'</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">step_id</span><span class="w"> </span><span class="k">BETWEEN</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="mi">200</span>
</span><span id="__span-3-12"><a href="#__codelineno-3-12" id="__codelineno-3-12" name="__codelineno-3-12"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">rank</span>
</span><span id="__span-3-13"><a href="#__codelineno-3-13" id="__codelineno-3-13" name="__codelineno-3-13"></a><span class="k">HAVING</span><span class="w"> </span><span class="n">z_score</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">2</span><span class="p">.</span><span class="mi">0</span><span class="w">  </span><span class="c1">-- 标准差超过2倍的视为异常</span>
</span><span id="__span-3-14"><a href="#__codelineno-3-14" id="__codelineno-3-14" name="__codelineno-3-14"></a><span class="k">ORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">avg_forward_time</span><span class="w"> </span><span class="k">DESC</span><span class="p">;</span>
</span></code></pre></div>
<p>这种查询允许我们立即发现性能显著偏离集群平均水平的节点，而无需手动检查每个节点的timeline。</p>
<h4 id="_8"><a class="toclink" href="2025/04/28/dist_probe_3/#_8">层次性能分布图</a></h4>
<p>分布式训练中，模型的不同组件在不同节点上的性能表现极具研究价值。Probing通过层次性能分布图直观展示这种多维度性能数据，帮助工程师快速定位瓶颈。通过Probing可以采集如下格式的数据：</p>
<div class="language-SQL highlight"><pre><span></span><code><span id="__span-4-1"><a href="#__codelineno-4-1" id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="n">ts</span><span class="p">:</span><span class="w"> </span><span class="err">事件时间戳</span>
</span><span id="__span-4-2"><a href="#__codelineno-4-2" id="__codelineno-4-2" name="__codelineno-4-2"></a><span class="n">node</span><span class="err">：节点名称</span>
</span><span id="__span-4-3"><a href="#__codelineno-4-3" id="__codelineno-4-3" name="__codelineno-4-3"></a><span class="n">module</span><span class="err">：模块名称</span>
</span><span id="__span-4-4"><a href="#__codelineno-4-4" id="__codelineno-4-4" name="__codelineno-4-4"></a><span class="n">stage</span><span class="err">：阶段名称，比如</span><span class="n">forward或者backward</span>
</span><span id="__span-4-5"><a href="#__codelineno-4-5" id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="n">mem_allocated</span><span class="p">:</span><span class="w"> </span><span class="err">已经分配的显存</span>
</span><span id="__span-4-6"><a href="#__codelineno-4-6" id="__codelineno-4-6" name="__codelineno-4-6"></a><span class="n">mem_cached</span><span class="p">:</span><span class="w"> </span><span class="err">已经缓存的显存</span>
</span><span id="__span-4-7"><a href="#__codelineno-4-7" id="__codelineno-4-7" name="__codelineno-4-7"></a><span class="n">duration</span><span class="err">：时间开销</span>
</span></code></pre></div>
<p>通过对采集的结构化数据进行多维度聚合与可视化，我们可以构建如下分析图表：</p>
<div class="language-SQL highlight"><pre><span></span><code><span id="__span-5-1"><a href="#__codelineno-5-1" id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="c1">-- 分析每个模型层在不同节点上的性能分布</span>
</span><span id="__span-5-2"><a href="#__codelineno-5-2" id="__codelineno-5-2" name="__codelineno-5-2"></a><span class="k">SELECT</span>
</span><span id="__span-5-3"><a href="#__codelineno-5-3" id="__codelineno-5-3" name="__codelineno-5-3"></a><span class="w">    </span><span class="n">module</span><span class="p">,</span>
</span><span id="__span-5-4"><a href="#__codelineno-5-4" id="__codelineno-5-4" name="__codelineno-5-4"></a><span class="w">    </span><span class="n">node</span><span class="p">,</span>
</span><span id="__span-5-5"><a href="#__codelineno-5-5" id="__codelineno-5-5" name="__codelineno-5-5"></a><span class="w">    </span><span class="k">AVG</span><span class="p">(</span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">avg_duration</span><span class="p">,</span>
</span><span id="__span-5-6"><a href="#__codelineno-5-6" id="__codelineno-5-6" name="__codelineno-5-6"></a><span class="w">    </span><span class="n">PERCENTILE_CONT</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">5</span><span class="p">)</span><span class="w"> </span><span class="n">WITHIN</span><span class="w"> </span><span class="k">GROUP</span><span class="w"> </span><span class="p">(</span><span class="k">ORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">median</span><span class="p">,</span>
</span><span id="__span-5-7"><a href="#__codelineno-5-7" id="__codelineno-5-7" name="__codelineno-5-7"></a><span class="w">    </span><span class="n">PERCENTILE_CONT</span><span class="p">(</span><span class="mi">0</span><span class="p">.</span><span class="mi">95</span><span class="p">)</span><span class="w"> </span><span class="n">WITHIN</span><span class="w"> </span><span class="k">GROUP</span><span class="w"> </span><span class="p">(</span><span class="k">ORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">p95</span><span class="p">,</span>
</span><span id="__span-5-8"><a href="#__codelineno-5-8" id="__codelineno-5-8" name="__codelineno-5-8"></a><span class="w">    </span><span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">samples</span>
</span><span id="__span-5-9"><a href="#__codelineno-5-9" id="__codelineno-5-9" name="__codelineno-5-9"></a><span class="k">FROM</span><span class="w"> </span><span class="n">python</span><span class="p">.</span><span class="n">torch_traces</span>
</span><span id="__span-5-10"><a href="#__codelineno-5-10" id="__codelineno-5-10" name="__codelineno-5-10"></a><span class="k">WHERE</span><span class="w"> </span><span class="k">operation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'forward'</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="n">step_id</span><span class="w"> </span><span class="k">BETWEEN</span><span class="w"> </span><span class="mi">1000</span><span class="w"> </span><span class="k">AND</span><span class="w"> </span><span class="mi">2000</span>
</span><span id="__span-5-11"><a href="#__codelineno-5-11" id="__codelineno-5-11" name="__codelineno-5-11"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">module</span><span class="p">,</span><span class="w"> </span><span class="n">node</span>
</span><span id="__span-5-12"><a href="#__codelineno-5-12" id="__codelineno-5-12" name="__codelineno-5-12"></a><span class="k">ORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">module</span><span class="p">,</span><span class="w"> </span><span class="n">avg_duration</span><span class="w"> </span><span class="k">DESC</span><span class="p">;</span>
</span></code></pre></div>
<p>这种查询能够生成深度学习模型中每个组件在集群不同节点上的性能热力图，通过这种热力图，我们可以立即观察到：</p>
<ul>
<li>水平方向：同一节点上不同模型层的相对性能</li>
<li>垂直方向：同一模型层在不同节点上的性能差异</li>
<li>热点区域：特定节点-组件组合的性能异常</li>
</ul>
<p>在一次实际分析中，我们通过层次性能分布图发现了某DNN模型中有趣的性能模式：</p>
<ul>
<li>组件级差异：Attention层在所有节点上都比其他层耗时更长（水平模式）</li>
<li>节点级差异：特定的4个节点在处理卷积层时显著慢于其他节点（垂直模式）</li>
<li>交互效应：某些节点仅在处理特定类型的层时出现性能下降（局部热点）</li>
</ul>
<h4 id="_9"><a class="toclink" href="2025/04/28/dist_probe_3/#_9">时间维度的性能演变分析</a></h4>
<p>分布式训练的性能问题常常随时间动态变化。通过跟踪关键指标的时间序列，我们可以发现潜在问题：</p>
<div class="language-SQL highlight"><pre><span></span><code><span id="__span-6-1"><a href="#__codelineno-6-1" id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="c1">-- 分析训练过程中的性能趋势</span>
</span><span id="__span-6-2"><a href="#__codelineno-6-2" id="__codelineno-6-2" name="__codelineno-6-2"></a><span class="k">SELECT</span><span class="w"> </span>
</span><span id="__span-6-3"><a href="#__codelineno-6-3" id="__codelineno-6-3" name="__codelineno-6-3"></a><span class="w">    </span><span class="n">FLOOR</span><span class="p">(</span><span class="n">step_id</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mi">50</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">50</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">step_bucket</span><span class="p">,</span><span class="w">  </span><span class="c1">-- 按50步为单位分桶</span>
</span><span id="__span-6-4"><a href="#__codelineno-6-4" id="__codelineno-6-4" name="__codelineno-6-4"></a><span class="w">    </span><span class="k">AVG</span><span class="p">(</span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">avg_duration</span><span class="p">,</span>
</span><span id="__span-6-5"><a href="#__codelineno-6-5" id="__codelineno-6-5" name="__codelineno-6-5"></a><span class="w">    </span><span class="n">STDDEV</span><span class="p">(</span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="k">AVG</span><span class="p">(</span><span class="n">duration_ms</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">cv</span><span class="w">  </span><span class="c1">-- 变异系数</span>
</span><span id="__span-6-6"><a href="#__codelineno-6-6" id="__codelineno-6-6" name="__codelineno-6-6"></a><span class="k">FROM</span><span class="w"> </span><span class="n">torch_traces</span>
</span><span id="__span-6-7"><a href="#__codelineno-6-7" id="__codelineno-6-7" name="__codelineno-6-7"></a><span class="k">WHERE</span><span class="w"> </span><span class="k">operation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">'forward'</span><span class="w"> </span>
</span><span id="__span-6-8"><a href="#__codelineno-6-8" id="__codelineno-6-8" name="__codelineno-6-8"></a><span class="k">GROUP</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">step_bucket</span>
</span><span id="__span-6-9"><a href="#__codelineno-6-9" id="__codelineno-6-9" name="__codelineno-6-9"></a><span class="k">ORDER</span><span class="w"> </span><span class="k">BY</span><span class="w"> </span><span class="n">step_bucket</span><span class="p">;</span>
</span></code></pre></div>
<p>通过这种分析，我们可以发现：</p>
<ul>
<li>训练初期的预热效应</li>
<li>性能随时间的逐渐劣化</li>
<li>可能的内存泄漏或资源竞争问题</li>
<li>周期性波动（如系统GC或后台任务影响）</li>
</ul>
<h4 id="_10"><a class="toclink" href="2025/04/28/dist_probe_3/#_10">分布式系统的层次化分析</a></h4>
<p>在大型集群中，仅分析个体节点往往不够。Probing支持按网络拓扑、硬件型号等进行分组分析：</p>
<div class="language-SQL highlight"><pre><span></span><code><span id="__span-7-1"><a href="#__codelineno-7-1" id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="w"> </span><span class="o">#</span><span class="w"> </span><span class="err">按网络拓扑分组分析通信性能</span>
</span><span id="__span-7-2"><a href="#__codelineno-7-2" id="__codelineno-7-2" name="__codelineno-7-2"></a><span class="n">rack_perf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">probe</span><span class="p">.</span><span class="k">sql</span><span class="p">(</span><span class="ss">"""</span>
</span><span id="__span-7-3"><a href="#__codelineno-7-3" id="__codelineno-7-3" name="__codelineno-7-3"></a><span class="ss">    SELECT </span>
</span><span id="__span-7-4"><a href="#__codelineno-7-4" id="__codelineno-7-4" name="__codelineno-7-4"></a><span class="ss">        CASE </span>
</span><span id="__span-7-5"><a href="#__codelineno-7-5" id="__codelineno-7-5" name="__codelineno-7-5"></a><span class="ss">            WHEN src_rank / 8 = dst_rank / 8 THEN 'same_node'</span>
</span><span id="__span-7-6"><a href="#__codelineno-7-6" id="__codelineno-7-6" name="__codelineno-7-6"></a><span class="ss">            WHEN src_rank / 32 = dst_rank / 32 THEN 'same_rack'</span>
</span><span id="__span-7-7"><a href="#__codelineno-7-7" id="__codelineno-7-7" name="__codelineno-7-7"></a><span class="ss">            ELSE 'cross_rack'</span>
</span><span id="__span-7-8"><a href="#__codelineno-7-8" id="__codelineno-7-8" name="__codelineno-7-8"></a><span class="ss">        END as topology,</span>
</span><span id="__span-7-9"><a href="#__codelineno-7-9" id="__codelineno-7-9" name="__codelineno-7-9"></a><span class="ss">        AVG(bytes_per_sec) as avg_bandwidth,</span>
</span><span id="__span-7-10"><a href="#__codelineno-7-10" id="__codelineno-7-10" name="__codelineno-7-10"></a><span class="ss">        COUNT(*) as sample_count</span>
</span><span id="__span-7-11"><a href="#__codelineno-7-11" id="__codelineno-7-11" name="__codelineno-7-11"></a><span class="ss">    FROM comm_events</span>
</span><span id="__span-7-12"><a href="#__codelineno-7-12" id="__codelineno-7-12" name="__codelineno-7-12"></a><span class="ss">    GROUP BY topology</span>
</span><span id="__span-7-13"><a href="#__codelineno-7-13" id="__codelineno-7-13" name="__codelineno-7-13"></a><span class="ss">"""</span><span class="p">).</span><span class="n">fetchall</span><span class="p">()</span>
</span><span id="__span-7-14"><a href="#__codelineno-7-14" id="__codelineno-7-14" name="__codelineno-7-14"></a>
</span><span id="__span-7-15"><a href="#__codelineno-7-15" id="__codelineno-7-15" name="__codelineno-7-15"></a><span class="k">for</span><span class="w"> </span><span class="k">row</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">rack_perf</span><span class="p">:</span>
</span><span id="__span-7-16"><a href="#__codelineno-7-16" id="__codelineno-7-16" name="__codelineno-7-16"></a><span class="w">    </span><span class="n">print</span><span class="p">(</span><span class="n">f</span><span class="ss">"{row.topology}: {row.avg_bandwidth/1e9:.2f} GB/s ({row.sample_count} samples)"</span><span class="p">)</span>
</span><span id="__span-7-17"><a href="#__codelineno-7-17" id="__codelineno-7-17" name="__codelineno-7-17"></a><span class="o">#</span><span class="w"> </span><span class="err">输出</span><span class="p">:</span>
</span><span id="__span-7-18"><a href="#__codelineno-7-18" id="__codelineno-7-18" name="__codelineno-7-18"></a><span class="o">#</span><span class="w"> </span><span class="n">same_node</span><span class="p">:</span><span class="w"> </span><span class="mi">87</span><span class="p">.</span><span class="mi">32</span><span class="w"> </span><span class="n">GB</span><span class="o">/</span><span class="n">s</span><span class="w"> </span><span class="p">(</span><span class="mi">12453</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span>
</span><span id="__span-7-19"><a href="#__codelineno-7-19" id="__codelineno-7-19" name="__codelineno-7-19"></a><span class="o">#</span><span class="w"> </span><span class="n">same_rack</span><span class="p">:</span><span class="w"> </span><span class="mi">23</span><span class="p">.</span><span class="mi">76</span><span class="w"> </span><span class="n">GB</span><span class="o">/</span><span class="n">s</span><span class="w"> </span><span class="p">(</span><span class="mi">8721</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span><span class="w"> </span>
</span><span id="__span-7-20"><a href="#__codelineno-7-20" id="__codelineno-7-20" name="__codelineno-7-20"></a><span class="o">#</span><span class="w"> </span><span class="n">cross_rack</span><span class="p">:</span><span class="w"> </span><span class="mi">11</span><span class="p">.</span><span class="mi">89</span><span class="w"> </span><span class="n">GB</span><span class="o">/</span><span class="n">s</span><span class="w"> </span><span class="p">(</span><span class="mi">5432</span><span class="w"> </span><span class="n">samples</span><span class="p">)</span>
</span></code></pre></div>
<p>这种分析揭示了网络拓扑对通信性能的影响，启发我们优化通信算法和数据分片策略以减少跨机架通信。</p>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2025-03-28 00:00:00+00:00">2025年3月28日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a>, 
              <a class="md-meta__link" href="category/training/">Training</a></li>
<li class="md-meta__item">
            
              需要 4 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="probing"><a class="toclink" href="2025/03/28/dist_probe_2/">Probing分布式探针开发随笔（二）：探针机制</a></h2>
<h3 id="_1"><a class="toclink" href="2025/03/28/dist_probe_2/#_1">引言</a></h3>
<p>在前一篇文章中，我们介绍了探针思路的设计理念，以及 Probing 分布式探针系统的整体架构。本文将详细介绍 Probing 的探针机制，包括探针的动态注入与运行时加载，以及如何规避 C/C++常见的 ABI 兼容性问题。</p>
<p>为何探针的动态注入能力尤为重要？因为故障和性能问题的发生总是不期而至，我们无法保证每次出现问题时都能提前部署探针。因此，任何需要提前部署的工具都迫使工程师必须”复现”问题才能进行分析，这无疑大大增加了诊断难度和时间成本。而分布式场景下，复现的成本与难度更是倍增，毕竟难以预留千卡或者万卡资源来复现问题。</p>
<p>异构计算则是另一个让复现问题变得更加困难的因素。在异构计算中，程序状态不再单纯地保存在 CPU 的内存中，而是同时分布在 GPU、TPU 等计算单元的内存中。这些计算设备的内存中不存在类似调用栈这种结构化数据，我们无法简单地通过 dump 调用栈来捕获故障时刻的状态，而是需要 dump 整个计算设备的内存内容。对于常见的单机八卡配置，完整 dump 一次设备内存需要占用 640GB 的存储空间，这无疑是一个巨大的挑战。而管理这些数据的元数据通常存储在 Python 解释器中，这意味着必须开发一个跨设备、跨语言的调试工具，才能实现完整的故障诊断。</p>
<p>探针则是尝试另一种解决问题的思路：</p>
<ul>
<li>通过动态注入，即可实现在任意条件下调试与诊断；</li>
<li>借助探针动态操作目标进程的 Python 解释器，利用其自然可以实现跨语言、跨设备的调试能力；</li>
</ul>
<h3 id="_2"><a class="toclink" href="2025/03/28/dist_probe_2/#_2">探针机制</a></h3>
<p>探针注入的关键在于在目标进程的代码逻辑之外，额外向进程植入一段代码。常见的代码植入方式有两种：</p>
<ol>
<li><code>LD_PRELOAD</code>方法：通过<code>LD_PRELOAD</code>环境变量，可以让 ld.so 在加载目标进程的时候，优先加载指定的动态链接库从而实现代码植入。这种方法的优点是简单易用，但是只能在进程启动时生效，无法在进程运行时动态注入；</li>
<li><code>ptrace</code>方法：通过<code>ptrace</code>系统调用，可以在进程运行时动态修改进程的内存，从而实现代码植入。这种方法的优点是可以在进程运行时动态注入，但是需要对目标进程有一定的权限，且对目标进程的性能影响较大。</li>
</ol>
<p>本文重点介绍<code>ptrace</code>方法的实现，<code>LD_PRELOAD</code>方法介绍的文章很多，本文不再赘述。</p>
<h4 id="ptrace"><a class="toclink" href="2025/03/28/dist_probe_2/#ptrace"><code>ptrace</code>系统调用介绍</a></h4>
<p><code>ptrace</code>是一个 Linux 系统调用，用于监控和控制另一个进程。<code>ptrace</code>的调用方式如下：</p>
<div class="language-c highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;sys/ptrace.h&gt;</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>
</span><span id="__span-0-3"><a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a><span class="kt">long</span><span class="w"> </span><span class="nf">ptrace</span><span class="p">(</span><span class="k">enum</span><span class="w"> </span><span class="n">__ptrace_request</span><span class="w"> </span><span class="n">op</span><span class="p">,</span><span class="w"> </span><span class="kt">pid_t</span><span class="w"> </span><span class="n">pid</span><span class="p">,</span>
</span><span id="__span-0-4"><a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="w">            </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">addr</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="o">*</span><span class="n">data</span><span class="p">);</span>
</span></code></pre></div>
<p><code>ptrace</code> 提供了一种控制目标进程执行的方法，它可以让调试器与目标进程进行交互，从而实现调试功能。__ptrace_request 常用的取值如下：</p>
<ul>
<li><code>PTRACE_ATTACH</code>: 附加到目标进程，使其成为当前进程的 tracee；</li>
<li><code>PTRACE_INTERRUPT</code>: 暂停目标 tracee；</li>
<li><code>PTRACE_CONT</code>: 让目标进程继续执行；</li>
<li><code>PTRACE_DETACH</code>: 释放目标 tracee；</li>
<li><code>PTRACE_GETREGS/PTRACE_SETREGS</code>: 读写目标进程寄存器；</li>
<li><code>PTRACE_PEEKDATA/PTRACE_POKEDATA</code>： 读写目标进程内存，一次一个 WORD；</li>
<li><code>/proc/&lt;pid&gt;/mem</code>: 大块读写内存；</li>
</ul>
<p>常见的一个 debugger 的工作流程如下：</p>
<ol>
<li>attach 到目标进程；</li>
<li>通过读写目标进程 TEXT 段插入断点；</li>
<li>恢复目标进程执行，并用<code>waitpid</code>等待目标进程断点暂停；</li>
<li>等到目标进程暂停，通过读写内存查看信息；</li>
</ol>
<h4 id="_3"><a class="toclink" href="2025/03/28/dist_probe_2/#_3">探针注入流程</a></h4>
<p>这里参考了 <a href="https://github.com/Artemis21/ptrace-inject">https://github.com/Artemis21/ptrace-inject</a> 项目，进行了一些修改。注入流程如下：</p>
<ol>
<li>通过<code>PTRACE_ATTACH</code>附加到目标进程；</li>
</ol>
<p>Rust 中可以通过<code>pete</code>库对<code>ptrace</code>的封装来使用<code>ptrace</code>系统调用：</p>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">tracer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pete</span><span class="p">::</span><span class="n">Ptracer</span><span class="p">::</span><span class="n">new</span><span class="p">();</span>
</span><span id="__span-1-2"><a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a><span class="n">tracer</span>
</span><span id="__span-1-3"><a href="#__codelineno-1-3" id="__codelineno-1-3" name="__codelineno-1-3"></a><span class="w">    </span><span class="p">.</span><span class="n">attach</span><span class="p">((</span><span class="o">&amp;</span><span class="n">proc</span><span class="p">).</span><span class="n">into</span><span class="p">())</span>
</span><span id="__span-1-4"><a href="#__codelineno-1-4" id="__codelineno-1-4" name="__codelineno-1-4"></a><span class="w">    </span><span class="p">.</span><span class="n">context</span><span class="p">(</span><span class="s">"failed to attach to given process"</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-1-5"><a href="#__codelineno-1-5" id="__codelineno-1-5" name="__codelineno-1-5"></a><span class="n">log</span><span class="p">::</span><span class="n">trace</span><span class="o">!</span><span class="p">(</span><span class="s">"Attached to process with PID {}"</span><span class="p">,</span><span class="w"> </span><span class="n">proc</span><span class="p">);</span>
</span></code></pre></div>
<ol start="2">
<li>写入 shellcode 到目标进程的内存中；</li>
</ol>
<p>首先找到一处合适的内存地址，具有执行权限，可以写入 shellcode。这里我们通过读取目标进程的内存映射信息，找到一个具有执行权限的内存区域：</p>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-2-1"><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a><span class="sd">/// Find a suitable address to inject the shellcode into.</span>
</span><span id="__span-2-2"><a href="#__codelineno-2-2" id="__codelineno-2-2" name="__codelineno-2-2"></a><span class="k">pub</span><span class="p">(</span><span class="k">crate</span><span class="p">)</span><span class="w"> </span><span class="k">fn</span><span class="w"> </span><span class="nf">find_executable_space</span><span class="p">(</span><span class="o">&amp;</span><span class="bp">self</span><span class="p">)</span><span class="w"> </span><span class="p">-&gt;</span><span class="w"> </span><span class="nb">Result</span><span class="o">&lt;</span><span class="kt">u64</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-2-3"><a href="#__codelineno-2-3" id="__codelineno-2-3" name="__codelineno-2-3"></a><span class="w">    </span><span class="n">log</span><span class="p">::</span><span class="n">trace</span><span class="o">!</span><span class="p">(</span><span class="s">"Finding executable space in target process"</span><span class="p">);</span>
</span><span id="__span-2-4"><a href="#__codelineno-2-4" id="__codelineno-2-4" name="__codelineno-2-4"></a><span class="w">    </span><span class="bp">self</span><span class="p">.</span><span class="mi">0</span>
</span><span id="__span-2-5"><a href="#__codelineno-2-5" id="__codelineno-2-5" name="__codelineno-2-5"></a><span class="w">        </span><span class="p">.</span><span class="n">maps</span><span class="p">()</span><span class="w"> </span><span class="c1">// 读取 /proc/&lt;pid&gt;/maps 文件，获取进程的内存映射信息</span>
</span><span id="__span-2-6"><a href="#__codelineno-2-6" id="__codelineno-2-6" name="__codelineno-2-6"></a><span class="w">        </span><span class="p">.</span><span class="n">context</span><span class="p">(</span><span class="s">"failed to read process memory maps to find executable region"</span><span class="p">)</span><span class="o">?</span>
</span><span id="__span-2-7"><a href="#__codelineno-2-7" id="__codelineno-2-7" name="__codelineno-2-7"></a><span class="w">        </span><span class="p">.</span><span class="n">into_iter</span><span class="p">()</span>
</span><span id="__span-2-8"><a href="#__codelineno-2-8" id="__codelineno-2-8" name="__codelineno-2-8"></a><span class="w">        </span><span class="p">.</span><span class="n">find</span><span class="p">(</span><span class="o">|</span><span class="n">m</span><span class="o">|</span><span class="w"> </span><span class="n">m</span><span class="p">.</span><span class="n">perms</span><span class="p">.</span><span class="n">contains</span><span class="p">(</span><span class="n">process</span><span class="p">::</span><span class="n">MMPermissions</span><span class="p">::</span><span class="n">EXECUTE</span><span class="p">))</span>
</span><span id="__span-2-9"><a href="#__codelineno-2-9" id="__codelineno-2-9" name="__codelineno-2-9"></a><span class="w">        </span><span class="p">.</span><span class="n">map</span><span class="p">(</span><span class="o">|</span><span class="n">m</span><span class="o">|</span><span class="w"> </span><span class="n">m</span><span class="p">.</span><span class="n">address</span><span class="p">.</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-2-10"><a href="#__codelineno-2-10" id="__codelineno-2-10" name="__codelineno-2-10"></a><span class="w">        </span><span class="p">.</span><span class="n">ok_or_else</span><span class="p">(</span><span class="o">||</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-2-11"><a href="#__codelineno-2-11" id="__codelineno-2-11" name="__codelineno-2-11"></a><span class="w">            </span><span class="n">anyhow</span><span class="p">::</span><span class="n">anyhow</span><span class="o">!</span><span class="p">(</span><span class="s">"could not find an executable region in the target process"</span><span class="p">)</span>
</span><span id="__span-2-12"><a href="#__codelineno-2-12" id="__codelineno-2-12" name="__codelineno-2-12"></a><span class="w">        </span><span class="p">})</span>
</span><span id="__span-2-13"><a href="#__codelineno-2-13" id="__codelineno-2-13" name="__codelineno-2-13"></a><span class="p">}</span>
</span></code></pre></div>
<p>上述代码通过读取<code>/proc/&lt;pid&gt;/maps</code>文件，获取进程的内存映射信息，找到一个具有执行权限的内存区域。接下来我们先保存这个内存区域的内容，然后写入 shellcode：</p>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-3-1"><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a><span class="c1">// 打开 /proc/&lt;pid&gt;/mem 文件，供后续读写内存使用</span>
</span><span id="__span-3-2"><a href="#__codelineno-3-2" id="__codelineno-3-2" name="__codelineno-3-2"></a><span class="kd">let</span><span class="w"> </span><span class="n">mem</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fs</span><span class="p">::</span><span class="n">OpenOptions</span><span class="p">::</span><span class="n">new</span><span class="p">().</span><span class="n">read</span><span class="p">(</span><span class="kc">true</span><span class="p">).</span><span class="n">write</span><span class="p">(</span><span class="kc">true</span><span class="p">)</span>
</span><span id="__span-3-3"><a href="#__codelineno-3-3" id="__codelineno-3-3" name="__codelineno-3-3"></a><span class="w">    </span><span class="p">.</span><span class="n">open</span><span class="p">(</span><span class="s">"/proc/&lt;pid&gt;/mem"</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-3-4"><a href="#__codelineno-3-4" id="__codelineno-3-4" name="__codelineno-3-4"></a>
</span><span id="__span-3-5"><a href="#__codelineno-3-5" id="__codelineno-3-5" name="__codelineno-3-5"></a><span class="c1">// 根据偏移量，读取目标进程的内存</span>
</span><span id="__span-3-6"><a href="#__codelineno-3-6" id="__codelineno-3-6" name="__codelineno-3-6"></a><span class="kd">let</span><span class="w"> </span><span class="n">len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mem</span><span class="p">.</span><span class="n">read_at</span><span class="p">(</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">addr</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-3-7"><a href="#__codelineno-3-7" id="__codelineno-3-7" name="__codelineno-3-7"></a>
</span><span id="__span-3-8"><a href="#__codelineno-3-8" id="__codelineno-3-8" name="__codelineno-3-8"></a><span class="c1">// 将shellcode写入目标进程的内存</span>
</span><span id="__span-3-9"><a href="#__codelineno-3-9" id="__codelineno-3-9" name="__codelineno-3-9"></a><span class="kd">let</span><span class="w"> </span><span class="n">len</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mem</span><span class="p">.</span><span class="n">write_at</span><span class="p">(</span><span class="n">shellcode</span><span class="p">,</span><span class="w"> </span><span class="n">addr</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span></code></pre></div>
<p>其中<code>data</code>是一个<code>[u8; 1024]</code>大小的数组，用于保存原内存区域的内容；<code>shellcode</code>是我们要写入的 shellcode，内容如下</p>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-4-1"><a href="#__codelineno-4-1" id="__codelineno-4-1" name="__codelineno-4-1"></a><span class="sd">/// The x64 shellcode that will be injected into the tracee.</span>
</span><span id="__span-4-2"><a href="#__codelineno-4-2" id="__codelineno-4-2" name="__codelineno-4-2"></a><span class="k">const</span><span class="w"> </span><span class="n">SHELLCODE</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="kt">u8</span><span class="p">;</span><span class="w"> </span><span class="mi">6</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span>
</span><span id="__span-4-3"><a href="#__codelineno-4-3" id="__codelineno-4-3" name="__codelineno-4-3"></a><span class="w">    </span><span class="c1">// Nop slide to make up for the fact that jumping is imprecise.</span>
</span><span id="__span-4-4"><a href="#__codelineno-4-4" id="__codelineno-4-4" name="__codelineno-4-4"></a><span class="w">    </span><span class="mh">0x90</span><span class="p">,</span><span class="w"> </span><span class="mh">0x90</span><span class="p">,</span><span class="w"> </span><span class="c1">// nop; nop</span>
</span><span id="__span-4-5"><a href="#__codelineno-4-5" id="__codelineno-4-5" name="__codelineno-4-5"></a><span class="w">    </span><span class="c1">// The tracer does most of the work by putting the arguments into the</span>
</span><span id="__span-4-6"><a href="#__codelineno-4-6" id="__codelineno-4-6" name="__codelineno-4-6"></a><span class="w">    </span><span class="c1">// relevant registers, and the function pointer into `r9`.</span>
</span><span id="__span-4-7"><a href="#__codelineno-4-7" id="__codelineno-4-7" name="__codelineno-4-7"></a><span class="w">    </span><span class="mh">0x41</span><span class="p">,</span><span class="w"> </span><span class="mh">0xff</span><span class="p">,</span><span class="w"> </span><span class="mh">0xd1</span><span class="p">,</span><span class="w"> </span><span class="c1">// call r9</span>
</span><span id="__span-4-8"><a href="#__codelineno-4-8" id="__codelineno-4-8" name="__codelineno-4-8"></a><span class="w">    </span><span class="c1">// Trap so that the tracer can set up the next call.</span>
</span><span id="__span-4-9"><a href="#__codelineno-4-9" id="__codelineno-4-9" name="__codelineno-4-9"></a><span class="w">    </span><span class="mh">0xcc</span><span class="p">,</span><span class="w"> </span><span class="c1">// int3</span>
</span><span id="__span-4-10"><a href="#__codelineno-4-10" id="__codelineno-4-10" name="__codelineno-4-10"></a><span class="p">];</span>
</span></code></pre></div>
<p>shellcode 主要由三部分组成：</p>
<ul>
<li>两个<code>nop</code>指令，避免跳转时的不精确性带来问题；</li>
<li>一个<code>call r9</code>指令，调用<code>r9</code>寄存器中的函数指针，此处调用会遵循 X86_64 下的标准调用协议，通过寄存器传参；</li>
<li>一个<code>int3</code>指令，触发中断，控制流程回到 tracer；</li>
</ul>
<ol start="3">
<li>通过设置寄存器调用目标函数：</li>
</ol>
<p>在 tracer 中设置寄存器，让目标进程调用函数：</p>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-5-1"><a href="#__codelineno-5-1" id="__codelineno-5-1" name="__codelineno-5-1"></a><span class="bp">self</span><span class="p">.</span><span class="n">tracee</span>
</span><span id="__span-5-2"><a href="#__codelineno-5-2" id="__codelineno-5-2" name="__codelineno-5-2"></a><span class="w">    </span><span class="p">.</span><span class="n">set_registers</span><span class="p">(</span><span class="n">pete</span><span class="p">::</span><span class="n">Registers</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-5-3"><a href="#__codelineno-5-3" id="__codelineno-5-3" name="__codelineno-5-3"></a><span class="w">        </span><span class="n">rip</span><span class="p">:</span><span class="w"> </span><span class="nc">shellcode_address</span><span class="p">,</span>
</span><span id="__span-5-4"><a href="#__codelineno-5-4" id="__codelineno-5-4" name="__codelineno-5-4"></a><span class="w">        </span><span class="c1">// shellcode会通过r9寄存器调用函数</span>
</span><span id="__span-5-5"><a href="#__codelineno-5-5" id="__codelineno-5-5" name="__codelineno-5-5"></a><span class="w">        </span><span class="n">r9</span><span class="p">:</span><span class="w"> </span><span class="nc">fn_address</span><span class="p">,</span>
</span><span id="__span-5-6"><a href="#__codelineno-5-6" id="__codelineno-5-6" name="__codelineno-5-6"></a><span class="w">        </span><span class="c1">// 根据x86-64 ABI要求，将函数入参传递到寄存器中</span>
</span><span id="__span-5-7"><a href="#__codelineno-5-7" id="__codelineno-5-7" name="__codelineno-5-7"></a><span class="w">        </span><span class="n">rdi</span><span class="p">,</span>
</span><span id="__span-5-8"><a href="#__codelineno-5-8" id="__codelineno-5-8" name="__codelineno-5-8"></a><span class="w">        </span><span class="n">rsi</span><span class="p">,</span>
</span><span id="__span-5-9"><a href="#__codelineno-5-9" id="__codelineno-5-9" name="__codelineno-5-9"></a><span class="w">        </span><span class="c1">// 根据x86-64 ABI要求，确保栈指针对齐到16字节</span>
</span><span id="__span-5-10"><a href="#__codelineno-5-10" id="__codelineno-5-10" name="__codelineno-5-10"></a><span class="w">        </span><span class="n">rsp</span><span class="p">:</span><span class="w"> </span><span class="nc">self</span><span class="p">.</span><span class="n">saved_registers</span><span class="p">.</span><span class="n">rsp</span><span class="w"> </span><span class="o">&amp;</span><span class="w"> </span><span class="o">!</span><span class="mh">0xf</span><span class="p">,</span>
</span><span id="__span-5-11"><a href="#__codelineno-5-11" id="__codelineno-5-11" name="__codelineno-5-11"></a><span class="w">        </span><span class="o">..</span><span class="bp">self</span><span class="p">.</span><span class="n">saved_registers</span>
</span><span id="__span-5-12"><a href="#__codelineno-5-12" id="__codelineno-5-12" name="__codelineno-5-12"></a><span class="w">    </span><span class="p">})</span>
</span></code></pre></div>
<p>函数<code>fn_address</code>是我们要调用的函数在目标进程中的虚拟地址，<code>rdi</code>和<code>rsi</code>是根据 x86-64 调用约定传递的前两个函数参数，<code>rsp</code>是栈指针，必须对齐到 16 字节以符合 ABI 要求。特别注意，<code>fn_address</code>必须是目标进程地址空间中的有效地址，否则会触发<code>SIGSEGV</code>信号导致进程崩溃。而目标进程的地址是不固定的，我们需要通过函数相对 so 文件的偏移量来计算。首先分别获取<code>libc.so</code>在 tracer 和 tracee 中的地址，可以通过<code>/proc/&lt;pid&gt;/maps</code>文件获取每个 so 映射到内存的地址。再根据函数在 tracer 中的地址计算函数在<code>libc.so</code>中的偏移量。最后在 tracee 中根据<code>libc.so</code>的地址与函数偏移量计算目标函数在 tracee 中的真实地址，即可根据该地址进行调用。</p>
<p>获取函数真实地址的代码比较冗长，感兴趣的话可以参考<a href="https://github.com/reiase/probing/blob/master/probing/cli/src/inject/libc_addresses.rs">仓库中的源码</a>。</p>
<p>通过上述步骤，我们可以在 tracee 中调用<code>dlopen</code>函数，加载动态链接库，实现动态注入。</p>
<h4 id="_4"><a class="toclink" href="2025/03/28/dist_probe_2/#_4">探针实现</a></h4>
<p><code>ptrace</code>只是帮助我们实现了探针的动态注入，而真正的探针逻辑还需要我们自己实现。根据前文所述，借助<code>ptrace</code>可以让目标进程调用<code>dlopen</code>来加载动态链接库。而在动态库加载的过程中，会读取 ELF（Executable and Linkable Format） 文件中的<code>.init_array</code>段，该段中存放了一系列初始化函数的地址。C/C++编译器一般支持<code>__attribute__((constructor))</code>属性，可以将函数注册到<code>.init_array</code>段中。</p>
<div class="language-c highlight"><pre><span></span><code><span id="__span-6-1"><a href="#__codelineno-6-1" id="__codelineno-6-1" name="__codelineno-6-1"></a><span class="n">__attribute__</span><span class="p">((</span><span class="n">constructor</span><span class="p">))</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">my_init</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-6-2"><a href="#__codelineno-6-2" id="__codelineno-6-2" name="__codelineno-6-2"></a><span class="w">    </span><span class="c1">// 初始化代码</span>
</span><span id="__span-6-3"><a href="#__codelineno-6-3" id="__codelineno-6-3" name="__codelineno-6-3"></a><span class="p">}</span>
</span></code></pre></div>
<p>而 Rust 中可以通过<code>#[ctor]</code>宏实现类似的功能：</p>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-7-1"><a href="#__codelineno-7-1" id="__codelineno-7-1" name="__codelineno-7-1"></a><span class="cp">#[ctor]</span>
</span><span id="__span-7-2"><a href="#__codelineno-7-2" id="__codelineno-7-2" name="__codelineno-7-2"></a><span class="k">fn</span><span class="w"> </span><span class="nf">my_init</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-3"><a href="#__codelineno-7-3" id="__codelineno-7-3" name="__codelineno-7-3"></a><span class="w">    </span><span class="c1">// 初始化代码</span>
</span><span id="__span-7-4"><a href="#__codelineno-7-4" id="__codelineno-7-4" name="__codelineno-7-4"></a><span class="p">}</span>
</span></code></pre></div>
<p>Probing 的注入框架不仅支持其内置探针模块，还支持用户自定义的探针库，提供了极高的扩展性。关于探针的具体设计细节，我们将在后续文章中深入探讨。</p>
<h3 id="abi"><a class="toclink" href="2025/03/28/dist_probe_2/#abi">ABI 兼容性</a></h3>
<p>传统的 C/C++项目经常受 ABI（Application Binary Interface）兼容性的困扰。常见的 ABI 兼容性问题有两类：</p>
<ol>
<li>glibc 中函数的版本问题：为了保证 ABI 的兼容性，glibc 中的函数会有多个版本，比如<code>malloc</code>函数就有<code>malloc@GLIBC_2.2.5</code>、<code>malloc@GLIBC_2.3</code>等多个版本。而动态链接库在链接时会在当前 glibc 中选取一个最新的版本，这就导致了在较新的系统下编译的 so 文件在较旧的系统上无法运行；</li>
<li>C++的 ABI 问题：C++的 ABI 问题主要由于最近几年 C++标准的更新较快，导致 libstdc++库的 ABI 不断变化。其中最为常见的一种错误是<code>std::string</code>类型在 C++11 标准中引入了短字符串优化（SSO）机制，导致<code>std::string</code>的内存布局发生了变化。而在 C++11 之前编译的 so 文件在 C++11 标准下运行时，会出现内存布局不一致的问题；</li>
</ol>
<p>Probing 主要通过两种方式解决 ABI 兼容性问题：纯静态链接与 zigbuild。</p>
<h4 id="_5"><a class="toclink" href="2025/03/28/dist_probe_2/#_5">纯静态链接</a></h4>
<p>静态链接是解决 ABI 兼容性的一种经典方法，通过将所有依赖库代码打包到一个 so 文件中，并在链接阶段完成所有符号的解析，从而避免了运行时出现 ABI 问题。Rust 在构建 so 文件的时候默认使用纯静态链接，能够很大程度上避免 C/C++项目中的 ABI 兼容性问题。</p>
<h4 id="zigbuild"><a class="toclink" href="2025/03/28/dist_probe_2/#zigbuild">zigbuild</a></h4>
<p>Zig 是一种新兴的系统级编程语言，内置完整的交叉编译工具链，可针对不同 glibc 版本生成二进制文件：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-8-1"><a href="#__codelineno-8-1" id="__codelineno-8-1" name="__codelineno-8-1"></a>zig<span class="w"> </span>cc<span class="w"> </span>main.c<span class="w"> </span>-o<span class="w"> </span>main<span class="w"> </span>-Dtarget<span class="o">=</span>arch64-linux-gnu.2.31
</span></code></pre></div>
<p>这使得使用 Zig 工具链构建的 so 文件可以通过指定低版本的 glibc 来增加 so 文件的兼容性。</p>
<p><code>cargo-zigbuild</code>是 Rust 构建工具<code>cargo</code>的一个扩展，可以在编译时指定 glibc 的版本，并借助 Zig 的工具链完成 so 文件的链接。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-9-1"><a href="#__codelineno-9-1" id="__codelineno-9-1" name="__codelineno-9-1"></a>cargo<span class="w"> </span>zigbuild<span class="w"> </span>--target<span class="w"> </span>x86_64-unknown-linux-gnu.2.17
</span></code></pre></div>
<h3 id="_6"><a class="toclink" href="2025/03/28/dist_probe_2/#_6">打包发布</a></h3>
<p>前文已经讨论了探针的动态注入与 ABI 兼容性问题，两者都尽最大的可能让 Probing 可以在任意环境下直接运行，而无须额外的配置。接下来我们将讨论 Probing 的打包发布问题，这是让 Probing 真正成为一个通用的工具的关键。</p>
<p>二进制工具发布通常有三种渠道：</p>
<ol>
<li>发布源码：将源码发布到 github 等代码托管平台，用户可以自行编译；但往往构建一个复杂项目的环境是非常困难的，尤其是在分布式环境下；</li>
<li>发行版包管理器：将二进制工具打包成 rpm、deb 等包，发布到发行版的包管理器中，用户可以通过包管理器安装；但是不同发行版的包管理器不同，维护成本较高；并且同一个发行版的不同版本需要维护不同的包；</li>
<li>pip/conda 等第三方发布平台：将二进制工具打包成 pip/conda 包，发布到第三方平台，用户可以通过 pip/conda 安装；但是这种方式往往需要用户安装额外的包管理器，不够方便；</li>
</ol>
<p>不过对于 AI 领域的工具来说，Python 是必不可免的，因此基于 Python 包管理工具 pip 或者 conda 来发布 Probing 是一个不错的选择。</p>
<p>不同于一般的 python 包，Probing 是一个以 Rust 为主要开发语言的工具，因此并不适合使用 setup.py 等传统方式来构建 python 包。这里我们选择直接使用脚本来打包<code>whl</code>:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a href="#__codelineno-10-1" id="__codelineno-10-1" name="__codelineno-10-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">write_wheel_file</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">contents</span><span class="p">):</span>
</span><span id="__span-10-2"><a href="#__codelineno-10-2" id="__codelineno-10-2" name="__codelineno-10-2"></a>    <span class="k">with</span> <span class="n">WheelFile</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">wheel</span><span class="p">:</span>
</span><span id="__span-10-3"><a href="#__codelineno-10-3" id="__codelineno-10-3" name="__codelineno-10-3"></a>        <span class="k">for</span> <span class="n">member_info</span><span class="p">,</span> <span class="n">member_source</span> <span class="ow">in</span> <span class="n">contents</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="__span-10-4"><a href="#__codelineno-10-4" id="__codelineno-10-4" name="__codelineno-10-4"></a>            <span class="o">...</span>
</span><span id="__span-10-5"><a href="#__codelineno-10-5" id="__codelineno-10-5" name="__codelineno-10-5"></a>    <span class="k">return</span> <span class="n">filename</span>
</span><span id="__span-10-6"><a href="#__codelineno-10-6" id="__codelineno-10-6" name="__codelineno-10-6"></a>
</span><span id="__span-10-7"><a href="#__codelineno-10-7" id="__codelineno-10-7" name="__codelineno-10-7"></a>
</span><span id="__span-10-8"><a href="#__codelineno-10-8" id="__codelineno-10-8" name="__codelineno-10-8"></a><span class="k">def</span><span class="w"> </span><span class="nf">write_wheel</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">version</span><span class="p">,</span> <span class="n">tag</span><span class="p">,</span> <span class="n">metadata</span><span class="p">,</span> <span class="n">description</span><span class="p">,</span> <span class="n">contents</span><span class="p">):</span>
</span><span id="__span-10-9"><a href="#__codelineno-10-9" id="__codelineno-10-9" name="__codelineno-10-9"></a>    <span class="n">name_snake</span> <span class="o">=</span> <span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">"-"</span><span class="p">,</span> <span class="s2">"_"</span><span class="p">)</span>
</span><span id="__span-10-10"><a href="#__codelineno-10-10" id="__codelineno-10-10" name="__codelineno-10-10"></a>    <span class="n">wheel_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name_snake</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">version</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">tag</span><span class="si">}</span><span class="s2">.whl"</span>
</span><span id="__span-10-11"><a href="#__codelineno-10-11" id="__codelineno-10-11" name="__codelineno-10-11"></a>    <span class="n">dist_info</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">name_snake</span><span class="si">}</span><span class="s2">-</span><span class="si">{</span><span class="n">version</span><span class="si">}</span><span class="s2">.dist-info"</span>
</span><span id="__span-10-12"><a href="#__codelineno-10-12" id="__codelineno-10-12" name="__codelineno-10-12"></a>    <span class="k">return</span> <span class="n">write_wheel_file</span><span class="p">(</span>
</span><span id="__span-10-13"><a href="#__codelineno-10-13" id="__codelineno-10-13" name="__codelineno-10-13"></a>        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">out_dir</span><span class="p">,</span> <span class="n">wheel_name</span><span class="p">),</span>
</span><span id="__span-10-14"><a href="#__codelineno-10-14" id="__codelineno-10-14" name="__codelineno-10-14"></a>        <span class="p">{</span>
</span><span id="__span-10-15"><a href="#__codelineno-10-15" id="__codelineno-10-15" name="__codelineno-10-15"></a>            <span class="o">**</span><span class="n">contents</span><span class="p">,</span>
</span><span id="__span-10-16"><a href="#__codelineno-10-16" id="__codelineno-10-16" name="__codelineno-10-16"></a>            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">dist_info</span><span class="si">}</span><span class="s2">/METADATA"</span><span class="p">:</span> <span class="n">make_message</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
</span><span id="__span-10-17"><a href="#__codelineno-10-17" id="__codelineno-10-17" name="__codelineno-10-17"></a>            <span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">dist_info</span><span class="si">}</span><span class="s2">/WHEEL"</span><span class="p">:</span> <span class="n">make_message</span><span class="p">(</span><span class="o">...</span><span class="p">),</span>
</span><span id="__span-10-18"><a href="#__codelineno-10-18" id="__codelineno-10-18" name="__codelineno-10-18"></a>        <span class="p">},</span>
</span><span id="__span-10-19"><a href="#__codelineno-10-19" id="__codelineno-10-19" name="__codelineno-10-19"></a>    <span class="p">)</span>
</span><span id="__span-10-20"><a href="#__codelineno-10-20" id="__codelineno-10-20" name="__codelineno-10-20"></a>
</span><span id="__span-10-21"><a href="#__codelineno-10-21" id="__codelineno-10-21" name="__codelineno-10-21"></a>
</span><span id="__span-10-22"><a href="#__codelineno-10-22" id="__codelineno-10-22" name="__codelineno-10-22"></a><span class="k">def</span><span class="w"> </span><span class="nf">write_probing_wheel</span><span class="p">(</span>
</span><span id="__span-10-23"><a href="#__codelineno-10-23" id="__codelineno-10-23" name="__codelineno-10-23"></a>    <span class="n">out_dir</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">platform</span><span class="o">=</span><span class="s2">"manylinux_2_12_x86_64.manylinux2010_x86_64"</span>
</span><span id="__span-10-24"><a href="#__codelineno-10-24" id="__codelineno-10-24" name="__codelineno-10-24"></a><span class="p">):</span>
</span><span id="__span-10-25"><a href="#__codelineno-10-25" id="__codelineno-10-25" name="__codelineno-10-25"></a>    <span class="o">...</span>
</span><span id="__span-10-26"><a href="#__codelineno-10-26" id="__codelineno-10-26" name="__codelineno-10-26"></a>
</span><span id="__span-10-27"><a href="#__codelineno-10-27" id="__codelineno-10-27" name="__codelineno-10-27"></a>    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">path</span> <span class="ow">in</span> <span class="p">{</span>
</span><span id="__span-10-28"><a href="#__codelineno-10-28" id="__codelineno-10-28" name="__codelineno-10-28"></a>        <span class="s2">"probing"</span><span class="p">:</span> <span class="s2">"target/x86_64-unknown-linux-gnu/release/probing"</span><span class="p">,</span>
</span><span id="__span-10-29"><a href="#__codelineno-10-29" id="__codelineno-10-29" name="__codelineno-10-29"></a>        <span class="s2">"libprobing.so"</span><span class="p">:</span> <span class="s2">"target/x86_64-unknown-linux-gnu/release/libprobing.so"</span><span class="p">,</span>
</span><span id="__span-10-30"><a href="#__codelineno-10-30" id="__codelineno-10-30" name="__codelineno-10-30"></a>    <span class="p">}</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
</span><span id="__span-10-31"><a href="#__codelineno-10-31" id="__codelineno-10-31" name="__codelineno-10-31"></a>        <span class="n">zip_info</span> <span class="o">=</span> <span class="n">ZipInfo</span><span class="p">(</span><span class="sa">f</span><span class="s2">"probing-</span><span class="si">{</span><span class="n">metadata</span><span class="p">[</span><span class="s2">"version"</span><span class="p">]</span><span class="si">}</span><span class="s2">.data/scripts/</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="__span-10-32"><a href="#__codelineno-10-32" id="__codelineno-10-32" name="__codelineno-10-32"></a>        <span class="n">zip_info</span><span class="o">.</span><span class="n">external_attr</span> <span class="o">=</span> <span class="p">(</span><span class="n">stat</span><span class="o">.</span><span class="n">S_IFREG</span> <span class="o">|</span> <span class="mo">0o755</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="mi">16</span>
</span><span id="__span-10-33"><a href="#__codelineno-10-33" id="__codelineno-10-33" name="__codelineno-10-33"></a>        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span><span id="__span-10-34"><a href="#__codelineno-10-34" id="__codelineno-10-34" name="__codelineno-10-34"></a>            <span class="n">contents</span><span class="p">[</span><span class="n">zip_info</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</span><span id="__span-10-35"><a href="#__codelineno-10-35" id="__codelineno-10-35" name="__codelineno-10-35"></a>    <span class="o">...</span>
</span><span id="__span-10-36"><a href="#__codelineno-10-36" id="__codelineno-10-36" name="__codelineno-10-36"></a>    <span class="k">return</span> <span class="n">write_wheel</span><span class="p">(</span>
</span><span id="__span-10-37"><a href="#__codelineno-10-37" id="__codelineno-10-37" name="__codelineno-10-37"></a>        <span class="n">out_dir</span><span class="p">,</span>
</span><span id="__span-10-38"><a href="#__codelineno-10-38" id="__codelineno-10-38" name="__codelineno-10-38"></a>        <span class="n">name</span><span class="o">=</span><span class="s2">"probing"</span><span class="p">,</span>
</span><span id="__span-10-39"><a href="#__codelineno-10-39" id="__codelineno-10-39" name="__codelineno-10-39"></a>        <span class="n">version</span><span class="o">=</span><span class="n">metadata</span><span class="p">[</span><span class="s2">"version"</span><span class="p">],</span>
</span><span id="__span-10-40"><a href="#__codelineno-10-40" id="__codelineno-10-40" name="__codelineno-10-40"></a>        <span class="n">tag</span><span class="o">=</span><span class="sa">f</span><span class="s2">"py3-none-</span><span class="si">{</span><span class="n">platform</span><span class="si">}</span><span class="s2">"</span><span class="p">,</span>
</span><span id="__span-10-41"><a href="#__codelineno-10-41" id="__codelineno-10-41" name="__codelineno-10-41"></a>        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="o">...</span><span class="p">},</span>
</span><span id="__span-10-42"><a href="#__codelineno-10-42" id="__codelineno-10-42" name="__codelineno-10-42"></a>        <span class="n">description</span><span class="o">=</span><span class="n">description</span><span class="p">,</span>
</span><span id="__span-10-43"><a href="#__codelineno-10-43" id="__codelineno-10-43" name="__codelineno-10-43"></a>        <span class="n">contents</span><span class="o">=</span><span class="n">contents</span><span class="p">,</span>
</span><span id="__span-10-44"><a href="#__codelineno-10-44" id="__codelineno-10-44" name="__codelineno-10-44"></a>    <span class="p">)</span>
</span><span id="__span-10-45"><a href="#__codelineno-10-45" id="__codelineno-10-45" name="__codelineno-10-45"></a>
</span><span id="__span-10-46"><a href="#__codelineno-10-46" id="__codelineno-10-46" name="__codelineno-10-46"></a>
</span><span id="__span-10-47"><a href="#__codelineno-10-47" id="__codelineno-10-47" name="__codelineno-10-47"></a><span class="k">def</span><span class="w"> </span><span class="nf">main</span><span class="p">():</span>
</span><span id="__span-10-48"><a href="#__codelineno-10-48" id="__codelineno-10-48" name="__codelineno-10-48"></a>    <span class="n">wheel_path</span> <span class="o">=</span> <span class="n">write_probing_wheel</span><span class="p">(</span><span class="s2">"dist/"</span><span class="p">)</span>
</span><span id="__span-10-49"><a href="#__codelineno-10-49" id="__codelineno-10-49" name="__codelineno-10-49"></a>    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">wheel_path</span><span class="p">,</span> <span class="s2">"rb"</span><span class="p">)</span> <span class="k">as</span> <span class="n">wheel</span><span class="p">:</span>
</span><span id="__span-10-50"><a href="#__codelineno-10-50" id="__codelineno-10-50" name="__codelineno-10-50"></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"  </span><span class="si">{</span><span class="n">wheel_path</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="__span-10-51"><a href="#__codelineno-10-51" id="__codelineno-10-51" name="__codelineno-10-51"></a>        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"    </span><span class="si">{</span><span class="n">hashlib</span><span class="o">.</span><span class="n">sha256</span><span class="p">(</span><span class="n">wheel</span><span class="o">.</span><span class="n">read</span><span class="p">())</span><span class="o">.</span><span class="n">hexdigest</span><span class="p">()</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</span><span id="__span-10-52"><a href="#__codelineno-10-52" id="__codelineno-10-52" name="__codelineno-10-52"></a>
</span><span id="__span-10-53"><a href="#__codelineno-10-53" id="__codelineno-10-53" name="__codelineno-10-53"></a>
</span><span id="__span-10-54"><a href="#__codelineno-10-54" id="__codelineno-10-54" name="__codelineno-10-54"></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">"__main__"</span><span class="p">:</span>
</span><span id="__span-10-55"><a href="#__codelineno-10-55" id="__codelineno-10-55" name="__codelineno-10-55"></a>    <span class="n">main</span><span class="p">()</span>
</span></code></pre></div>
<p>该脚本主要使用<code>wheel</code>包中的<code>WheelFile</code>类来构建<code>whl</code>文件，并将构建出来的二进制写入到<code>probing-{version}.data/scripts</code>目录下。此外需要提供<code>METADATA</code>和<code>WHEEL</code>文件，分别用于描述包的元信息和 wheel 的版本信息。</p>
<h3 id="_7"><a class="toclink" href="2025/03/28/dist_probe_2/#_7">总结</a></h3>
<p>本文主要讨论了 Probing 的核心机制——探针注入，并讨论了如何将这一机制变成一个通用工具，让其能使用到复杂多样的生产环境中，能够快速发布给尽可能多的用户。所有这些设计都是为了 Probing 的一个核心设计理念：解决问题时，应直接面对根本问题，避免陷入工具配置、环境搭建等元问题的循环中。或者可以认为这一设计理念是马斯克第一性原则的一种体现，缩短解决问题的路径，提高解决问题的效率。</p>
<p>在下一篇文章中将会介绍探针 so 的设计与实现。</p>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2025-03-26 00:00:00+00:00">2025年3月26日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a>, 
              <a class="md-meta__link" href="category/training/">Training</a></li>
<li class="md-meta__item">
            
              需要 1 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="probing"><a class="toclink" href="2025/03/26/dist_probe_1/">Probing分布式探针开发随笔（一）：背景与设计理念</a></h2>
<h3 id="_1"><a class="toclink" href="2025/03/26/dist_probe_1/#_1">分布式训练系统的泥潭</a></h3>
<p>在过去半年多的时间里，我一直在支持千卡规模的LLM分布式训练。坦白讲，千卡训练的过程并不愉快，尤其是在性能调优和故障排查方面。在这个过程中，我们遇到了一系列棘手的问题：训练无法正常启动、通信库突然hang住、节点性能不及预期、训练速度不稳定等等。这些问题不仅严重影响了训练效率，还大幅增加了调试的复杂度，导致我们不得不花费大量时间和精力在性能调优和故障排查上。</p>
<p>有人可能会说，千卡（乃至万卡）规模的稳定性问题在大厂内部已经解决得相当好了。然而，那些耗费无数人力堆砌出来的系统，往往只是在这些大厂已有的复杂基础设施上打补丁，解决眼前可见的问题，而且很多时候仅仅是在处理问题的表象。大规模分布式异构训练真正需要的是类似Hadoop、Spark、Kubernetes或TensorFlow这样具有前瞻性的系统设计，能够解决问题的本质，并提供解决问题的框架，而不仅仅是一些堆砌在特定基础设施上、不具备任何迁移性的”补丁”。我们需要一种更加系统化、可扩展的方法来应对这些挑战。</p>
<h3 id="probing_1"><a class="toclink" href="2025/03/26/dist_probe_1/#probing_1">Probing——分布式探针系统的原型探索</a></h3>
<p>在解决问题的过程中，我一直思索自己到底需要什么。我需要一种能够在任何时刻动态启用，无需预先部署或插桩，在生产任务中以极低性能开销持续运行，实现实时监控与故障追溯的诊断工具。我需要一种不仅支持单机诊断，还能无缝覆盖分布式训练环境，无论集群规模如何，都能确保数据采集与故障分析的一致性的诊断工具。我需要一种能够从硬件层面的诊断数据、芯片互联状态，到框架、系统和模型各层数据的全面采集，构建完整的闭环监控系统的诊断工具。而现有的种种工具，要么需要侵入式的代码修改和预先部署，要么会严重影响性能，要么只能关注单机，无法覆盖分布式环境，要么只能关注单一维度，无法实现综合分析。</p>
<p>基于自己的需求，我开始尝试设计一种“探针”系统：</p>
<ul>
<li>可以在任意时刻通过动态注入的方式启用，无需预先部署或插桩；</li>
<li>运行开销极低或者无开销，可以在生产任务中持续收集性能数据和故障数据；</li>
<li>“寄生”在目标进程中，具有相同的内存地址空间与权限，进而实现观测和调试；</li>
<li>支持分布式，更好地覆盖大规模分布式训练环境；</li>
</ul>
<p>这套探针系统大致用法如下：</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a>$<span class="w"> </span>probing<span class="w"> </span>&lt;pid&gt;<span class="w"> </span>inject<span class="w"> </span><span class="c1"># 注入探针</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>$<span class="w"> </span>probing<span class="w"> </span>&lt;pid&gt;<span class="w"> </span><span class="nb">eval</span><span class="w"> </span><span class="s2">"print('Hello, Probing!')"</span><span class="w"> </span><span class="c1"># 在目标进程中执行代码</span>
</span><span id="__span-0-3"><a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>$<span class="w"> </span>probing<span class="w"> </span>&lt;pid&gt;<span class="w"> </span>query<span class="w"> </span><span class="s2">"SHOW tables"</span><span class="w"> </span><span class="c1"># 查看可用数据</span>
</span><span id="__span-0-4"><a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>$<span class="w"> </span>probing<span class="w"> </span>&lt;pid&gt;<span class="w"> </span>query<span class="w"> </span><span class="s2">"SELECT * FROM process.envs"</span><span class="w"> </span><span class="c1"># 查询进程环境变量</span>
</span></code></pre></div>
<p><code>probing</code>通过<code>query</code>命令提供SQL查询接口，并在这一接口下标准化了不同类型的数据，包括进程状态、硬件性能指标、网络状态、文件系统状态等，使用户无须单独学习每种数据的获取和分析方式。另一方面，SQL查询也提供和AI接入能力，用户可以借助AI生成查询与分析语句，实现自动化的性能分析与故障诊断。后续也会直接扩展SQL支持分布是查询，实现对整个集群的性能分析与故障诊断。</p>
<p>在接下来的一系列文章里，我将详细介绍Probing的设计与实现，包括探针机制、数据采集、分析方法等方面。希望这个探索能够为大规模分布式训练的性能分析与故障诊断提供一些启发。以下是接下来需要进行讨论的内容：</p>
<ol>
<li>如何实现探针的动态注入与运行时加载，如何规避C/C++常见的ABI兼容性问题；</li>
<li>如何实现高频数据的采集和存储，如何实现数据的压缩和优化；</li>
<li>如何避免跨节点时钟漂移带来的事件时间不一致问题；</li>
</ol>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2025-02-20 00:00:00+00:00">2025年2月20日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a>, 
              <a class="md-meta__link" href="category/training/">Training</a>, 
              <a class="md-meta__link" href="category/training-dynamics/">Training Dynamics</a></li>
<li class="md-meta__item">
            
              需要 5 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="training-dynamicsoutlierllm"><a class="toclink" href="2025/02/20/training_dynamics/">从Training Dynamics到Outlier——LLM模型训练过程中的数值特性分析</a></h2>
<p>Training Dynamics是一个未被严格定义的词，泛指模型训练过程中观测到的各种现象、变化和行为规律。我们可以从loss、泛化loss、梯度大小以及等等表现来观察模型内部的演变机制，并总结出类似涌现现象（Emergency）、Scaling Law、Double Decent和Gradient Pathologies等现象。</p>
<p>特别地，权重矩阵与激活值的动态演变(Dynamics)会直接影响数值表达范围，进而决定硬件计算精度选择与量化误差控制策略。本文聚焦Transformer架构中关键组件的数值动态特性，重点分析其对低精度训练与推理的工程影响。</p>
<h3 id="_1"><a class="toclink" href="2025/02/20/training_dynamics/#_1">权重与激活的数值演变特征</a></h3>
<p>这里先给出权重与梯度的直观数值变化，帮助直观理解训练过程。下图取自某开源仓库<sup id="fnref:llm_facts"><a class="footnote-ref" href="2025/02/20/training_dynamics/#fn:llm_facts">1</a></sup>，展示了权重数值的直方分布随训练进行的变化情况：</p>
<figure><br/>
<img alt="" src="imgs/tdynamics/weight_histograms_all_together_animation_mlp_h24h_800m.gif" width="500"/><br/>
</figure>
<p>可以发现，各个block的FFN部分权重从随机初始化的高斯分布，开始时较为稳定；在2000 step左右开始剧烈变化；随后整体分布再次稳定下来。权重整体保留了高斯分布，但是存在一些不是非常大的outlier。</p>
<p>接下来再看一下激活值的分布变化，在训练开始后，残差激活值迅速从高斯分布转变为逻辑分布（Logistic Distribution），并且出现较大的outlier：</p>
<figure><br/>
<img alt="" src="imgs/tdynamics/acc.gif" width="500"/><br/>
</figure>
<p>这种激活上的outlier会对模型量化过程产生极大的影响，因此诸如AWQ等量化方法会重点关注激活中的outlier情况，以保证模型推理时的精度。</p>
<p>梯度分布的变化趋势与权重类似，训练过程也未出现较大的outlier，说明梯度本身也具备较好的稳定性，存在低精度计算和存储的可能性。</p>
<figure><br/>
<img alt="" src="imgs/tdynamics/grad.gif" width="500"/><br/>
</figure>
<nav class="md-post__action">
<a href="2025/02/20/training_dynamics/">
          继续阅读
        </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2025-02-15 00:00:00+00:00">2025年2月15日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a>, 
              <a class="md-meta__link" href="category/training/">Training</a>, 
              <a class="md-meta__link" href="category/fp8/">FP8</a></li>
<li class="md-meta__item">
            
              需要 2 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="int8"><a class="toclink" href="2025/02/15/int8_training/">INT8也能训练</a></h2>
<p>在 <a href="../../../../../../../2025/02/12/fp8_training">前一篇博客</a> 中，我们深入探讨了DeepSeek V3如何通过FP8实现高效训练，并成功克服了精度挑战。本文探讨另一个问题：如果用INT8代替FP8做训练，会发生什么？</p>
<h3 id="int8_1"><a class="toclink" href="2025/02/15/int8_training/#int8_1">INT8 量化</a></h3>
<p>给定一个浮点数向量 <span class="arithmatex">\(x \in \mathbb{R}^n\)</span>，INT8量化的目标是将其映射到 [-128, 127] 的整数空间。这一过程需要确定缩放因子 <span class="arithmatex">\(\alpha\)</span> 和零点偏移 <span class="arithmatex">\(\beta\)</span>，使得：</p>
<div class="arithmatex">\[ x_q = round(\frac{x}{\alpha}) + \beta \]</div>
<p>其中 <span class="arithmatex">\(x_q\)</span> 表示量化后的INT8值。缩放因子 <span class="arithmatex">\(\alpha\)</span> 通常通过以下方式计算：</p>
<div class="arithmatex">\[ \alpha = \frac{max(|x|)}{127} \]</div>
<p>这确保了量化后的值不会超出INT8的表示范围。而零点偏移 <span class="arithmatex">\(\beta\)</span> 在对称量化场景下通常设置为0，在非对称量化时则需要根据数据分布来确定。</p>
<p>对于LLM训练场景，由于权重和激活值通常呈现对称分布，我们可以使用对称量化方案：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">symmetric_quantize</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
</span><span id="__span-0-2"><a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a>    <span class="n">alpha</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">/</span> <span class="mf">127.0</span>  <span class="c1"># 计算缩放因子</span>
</span><span id="__span-0-3"><a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>    <span class="n">x_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">x</span> <span class="o">/</span> <span class="n">alpha</span><span class="p">)</span>   <span class="c1"># 量化</span>
</span><span id="__span-0-4"><a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a>    <span class="n">x_q</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">x_q</span><span class="p">,</span> <span class="o">-</span><span class="mi">128</span><span class="p">,</span> <span class="mi">127</span><span class="p">)</span>  <span class="c1"># 截断</span>
</span><span id="__span-0-5"><a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a>    <span class="k">return</span> <span class="n">x_q</span><span class="p">,</span> <span class="n">alpha</span>
</span></code></pre></div>
<p>反量化操作则是将INT8值映射回浮点数空间：</p>
<div class="arithmatex">\[ x_r = (x_q - \beta) \times \alpha \]</div>
<p>其中 <span class="arithmatex">\(x_r\)</span> 是反量化后的浮点数值。在对称量化场景下，由于 <span class="arithmatex">\(\beta = 0\)</span>，反量化简化为：</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a><span class="k">def</span><span class="w"> </span><span class="nf">symmetric_dequantize</span><span class="p">(</span><span class="n">x_q</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-1-2"><a href="#__codelineno-1-2" id="__codelineno-1-2" name="__codelineno-1-2"></a>    <span class="k">return</span> <span class="n">x_q</span> <span class="o">*</span> <span class="n">alpha</span>
</span></code></pre></div>
<p>与FP8的浮点量化不同，INT8采用均匀量化方案：</p>
<ul>
<li>优势区间：大值区域精度更高（固定量化步长）</li>
<li>劣势区间：小值区域精度较低（相对误差更大）</li>
</ul>
<p>这种特性使得INT8对数据分布形态更为敏感，需要针对性优化策略。</p>
<nav class="md-post__action">
<a href="2025/02/15/int8_training/">
          继续阅读
        </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2025-02-12 00:00:00+00:00">2025年2月12日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a>, 
              <a class="md-meta__link" href="category/training/">Training</a>, 
              <a class="md-meta__link" href="category/fp8/">FP8</a></li>
<li class="md-meta__item">
            
              需要 9 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="deepseek-v3fp8"><a class="toclink" href="2025/02/12/fp8_training/">从DeepSeek V3看FP8训练的挑战</a></h2>
<p>DeepSeek V3 的发布引起了对 FP8 训练的广泛关注，业界也出现了大量文章解析 How 的问题——DeepSeek 是怎么进行 FP8 训练的，与传统方案有哪些不同。但是目前鲜有文章对 Why 问题进行深入探讨，为何 DeepSeek 的方案能够取得成功。本文尝试对 FP8 训练所面临的挑战进行深入解析，并尝试猜测 DeepSeek 团队设计其 FP 方案的背后原理。（如果你对 INT8 训练感兴趣，可以参考本文的姊妹篇：<a href="../../../../../../../2025/02/15/int8_training">INT8 训练</a>）</p>
<h3 id="1-fp8"><a class="toclink" href="2025/02/12/fp8_training/#1-fp8">1. FP8 浮点格式</a></h3>
<h4 id="11-fp8"><a class="toclink" href="2025/02/12/fp8_training/#11-fp8">1.1 FP8 格式的历史</a></h4>
<p>FP8 是一种遵循 IEEE 754 规范<sup id="fnref:ieee754"><a class="footnote-ref" href="2025/02/12/fp8_training/#fn:ieee754">1</a></sup>的 8 位浮点数格式，由 Nvidia 在 2022 年发布的 H100 GPU 中首次引入。在此之前，Nvidia 硬件上浮点数格式的发展历程如下<sup id="fnref:huang_law_1"><a class="footnote-ref" href="2025/02/12/fp8_training/#fn:huang_law_1">2</a></sup>：</p>
<ul>
<li>2016 年 P100 GPU 首次引入 FP16 数据格式，直接开启了深度学习混合精度训练的技术路线；</li>
<li>2017 年 V100 GPU 首次引入 Tensor Core, 用于加速 FP16 矩阵乘法运算；</li>
<li>2020 年 A100 GPU 首次引入 TF32 数据格式，可通过 Tensor Core 加速；引入 bfloat16 数据格式，提供比 FP16 更宽的动态范围（当下 BF16 已经成为 LLM 训练的主流方案）；</li>
<li>2022 年 H100 GPU 首次引入 FP8 数据格式；</li>
</ul>
<p>FP8 被 Nvidia 给予厚望，认为其成功的延续了 CEO 提出的 Huang’s Law<sup id="fnref:huang_law_2"><a class="footnote-ref" href="2025/02/12/fp8_training/#fn:huang_law_2">3</a></sup>，即 10 年间 GPU 硬件算力提升 1000 倍。在过去的 10 年间，新型数值表达的引入了 16 倍算力提升，是诸多技术中贡献最大者，GPU 架构与复杂指令集紧随其后带来了 12.5 倍提升，而制程进步带来的收益非常有限，仅 2.5 倍<sup id="fnref:nvidia_gpu"><a class="footnote-ref" href="2025/02/12/fp8_training/#fn:nvidia_gpu">4</a></sup>。</p>
<h4 id="12-ieee-754"><a class="toclink" href="2025/02/12/fp8_training/#12-ieee-754">1.2. 常见浮点数与 IEEE 754</a></h4>
<p>IEEE 754 是目前广为使用的浮点数规范，定义了浮点数的 bitwise 表达与量化方式。浮点数的二进制表达分为三部分：</p>
<ul>
<li>符号位（sign）</li>
<li>指数位（exponent）</li>
<li>尾数位（mantissa）</li>
</ul>
<p>常见的浮点数格式的二进制表达如下图所示：</p>
<pre class="mermaid"><code>block-beta
    columns 33
    FP32["fp32"]
    S1["S"]
    E1["E"]
    E2["E"]
    E3["E"]
    E4["E"]
    E5["E"]
    E6["E"]
    E7["E"]
    E8["E"]
    M1["M"]
    M2["M"]
    M3["M"]
    M4["M"]
    M5["M"]
    M6["M"]
    M7["M"]
    M8["M"]
    M9["M"]
    M10["M"]
    M11["M"]
    M12["M"]
    M13["M"]
    M14["M"]
    M15["M"]
    M16["M"]
    M17["M"]
    M18["M"]
    M19["M"]
    M20["M"]
    M21["M"]
    M22["M"]
    M23["M"]

    BF16["bf16"]
    SS1["S"]
    EE1["E"]
    EE2["E"]
    EE3["E"]
    EE4["E"]
    EE5["E"]
    EE6["E"]
    EE7["E"]
    EE8["E"]
    MM1["M"]
    MM2["M"]
    MM3["M"]
    MM4["M"]
    MM5["M"]
    MM6["M"]
    MM7["M"]
    space:16

    FP16["fp16"]
    space:3
    ss1["S"]
    ee1["E"]
    ee2["E"]
    ee3["E"]
    ee4["E"]
    ee5["E"]
    mm1["M"]
    mm2["M"]
    mm3["M"]
    mm4["M"]
    mm5["M"]
    mm6["M"]
    mm7["M"]
    mm8["M"]
    mm9["M"]
    mm10["M"]
    space:13

    E5M2["fp8"]
    space:3
    s1["S"]
    e1["E"]
    e2["E"]
    e3["E"]
    e4["E"]
    e5["E"]
    m1["M"]
    m2["M"]
    space:21

    E4M3["fp8"]
    space:4
    sss1["S"]
    eee1["E"]
    eee2["E"]
    eee3["E"]
    eee4["E"]
    mmm1["M"]
    mmm2["M"]
    mmm3["M"]
    space:21

    classDef name fill:#00000000, stroke:#00000000
    class FP32,BF16,FP16,E4M3,E5M2 name

    classDef sign fill:#EE0000, stroke:#00000000
    class S1,SS1,s1,ss1,sss1 sign

    classDef exp fill:#00EE00, stroke:#00000000
    class E1,E2,E3,E4,E5,E6,E7,E8 exp
    class EE1,EE2,EE3,EE4,EE5,EE6,EE7,EE8 exp
    class e1,e2,e3,e4,e5,e6,e7,e8 exp
    class ee1,ee2,ee3,ee4,ee5,ee6,ee7,ee8 exp
    class eee1,eee2,eee3,eee4,eee5,eee6,eee7,eee8 exp</code></pre>
<h4 id="13-fp8"><a class="toclink" href="2025/02/12/fp8_training/#13-fp8">1.3. FP8 有两种格式</a></h4>
<p>随着浮点数位数从 16 位进一步降低到 8 位，动态范围不足的问题逐渐显现。因此 Nvidia、Arm 和 Intel 在 FP8 规范中设计了两种浮点数类型<sup id="fnref:fp8"><a class="footnote-ref" href="2025/02/12/fp8_training/#fn:fp8">5</a></sup>：E4M3 和 E5M2</p>
<table>
<thead>
<tr>
<th></th>
<th>E4M3</th>
<th>E5M2</th>
</tr>
</thead>
<tbody>
<tr>
<td>format(s/e/m)</td>
<td>1:4:3</td>
<td>1:5:2</td>
</tr>
<tr>
<td>Exponent bias</td>
<td>7</td>
<td>15</td>
</tr>
<tr>
<td>Infinities</td>
<td>N/A</td>
<td>S.11111.00</td>
</tr>
<tr>
<td>NaN</td>
<td>S.1111.111</td>
<td>S.11111.{01,10,11}</td>
</tr>
<tr>
<td>Zeros</td>
<td>S.0000.000</td>
<td>S.00000.00</td>
</tr>
<tr>
<td>Max normal</td>
<td>S.1111.110 = <span class="arithmatex">\(1.75 \times 2^8\)</span> = 448</td>
<td>S.11110.11 = <span class="arithmatex">\(1.75 \times 2^15\)</span> = 57.344</td>
</tr>
<tr>
<td>Min normal</td>
<td>S.0001.0000 = <span class="arithmatex">\(2^{-6}\)</span></td>
<td>S.00001.00 = <span class="arithmatex">\(2^{-14}\)</span></td>
</tr>
<tr>
<td>Max subnorm</td>
<td>S.0000.111 = <span class="arithmatex">\(0.875 \times 2^{-6}\)</span></td>
<td>S.00000.11 = <span class="arithmatex">\(0.75\times 2^{-14}\)</span></td>
</tr>
<tr>
<td>Min subnorm</td>
<td>S.0000.001 = <span class="arithmatex">\(2^{-9}\)</span></td>
<td>S.00000.01 = $ 2^{-16}$</td>
</tr>
</tbody>
</table>
<p>浮点数都会分配一些二进制表达来表示特殊值**NaN**和 <strong><span class="arithmatex">\(\mathbb{\pm}\)</span>Inf</strong>，IEEE 754 规范约定使用指数位全**1**的二进制表达来表示这些特殊值。对于 E4M3 格式来说，若严格遵循 IEEE 754 规范，会 8 个二进制表达。因此在定义 E4M3 规范时对这些二进制表达进行了额外开发，仅在指数位尾数位同时全为 <strong>1</strong> 时才表示 <strong>NaN</strong>，全为 <strong>0</strong> 的时候表示 <strong><span class="arithmatex">\(\pm\)</span>Inf</strong>。</p>
<p>H100 的 Tensor Core 提供 3 倍 A100 FP16 性能，若启用 FP8 算力能够再次翻倍。</p>
<p><img alt="" src="https://developer-blogs.nvidia.com/zh-cn-blog/wp-content/uploads/sites/2/2024/04/%E8%A1%A81-1536x819.png"/></p>
<nav class="md-post__action">
<a href="2025/02/12/fp8_training/">
          继续阅读
        </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2025-02-09 00:00:00+00:00">2025年2月9日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a>, 
              <a class="md-meta__link" href="category/training/">Training</a>, 
              <a class="md-meta__link" href="category/rl/">RL</a></li>
<li class="md-meta__item">
            
              需要 6 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="deepseek-r1"><a class="toclink" href="2025/02/09/rl_ds_r1/">从强化学习到DeepSeek R1</a></h2>
<h3 id="1-rl-reinforcement-learning"><a class="toclink" href="2025/02/09/rl_ds_r1/#1-rl-reinforcement-learning">1. 什么是强化学习(RL, Reinforcement Learning)</a></h3>
<p>传统的机器学习，包括深度学习，其本质是数学性的，严格遵守函数的数学定义：对于给定输入，产生确定的输出</p>
<div class="arithmatex">\[F(x) = y\]</div>
<p>随着输入<span class="arithmatex">\(x\)</span>和输出<span class="arithmatex">\(y\)</span>的不同，这一范式可以适配各种不同的任务，比如：</p>
<ul>
<li><span class="arithmatex">\(x\)</span> 是图像，<span class="arithmatex">\(y\)</span>是类别，那么<span class="arithmatex">\(F\)</span>就是Resnet这种图像模型；</li>
<li><span class="arithmatex">\(x\)</span> 是语音信号，<span class="arithmatex">\(y\)</span>是文字，那么<span class="arithmatex">\(F\)</span>就是一个语音识别模型；</li>
<li><span class="arithmatex">\(x\)</span> 是文本输入，<span class="arithmatex">\(y\)</span>是文本输出，那么<span class="arithmatex">\(F\)</span>就是时下火热的大语言模型；<br/>
…</li>
</ul>
<p>强化学习（Reinforcement Learning）的本质上则是哲学性的，它探讨三个核心问题：</p>
<ul>
<li>我是谁？一个Agent</li>
<li>我在哪？处于某个State</li>
<li>到哪里去？采取一个Action</li>
</ul>
<p>如果站在上帝视角去观测这个Agent，我们还会发现：</p>
<ul>
<li>Agent处在一个环境中（Environment）</li>
<li>Agent有一个用来策略（Policy）告诉我该采取什么动作（Action）</li>
<li>每执行一个动作（Action），环境都会给我反馈 (Reward)</li>
</ul>
<p>以上就是强化学习中的主要概念。</p>
<p><img alt="alt text" src="imgs/rl.png"/></p>
<h3 id="2"><a class="toclink" href="2025/02/09/rl_ds_r1/#2">2. 如何进行强化学习</a></h3>
<p>这里以一个迷宫问题为例，介绍如何进行强化学习：</p>
<p>迷宫：(S: Start, E: End, W: Wall)</p>
<pre class="mermaid"><code>block-beta
  columns 3
  S1["S1(S)"] S2 S3["S3(W)"]
  S4 S5 S6
  S7["S7(W)"] S8 S9["S9(E)"]
</code></pre>
<p>这个迷宫就是一个Environment。我们放置一个机器人在开始处（Start），让机器人自动学习如何走迷宫的策略（Policy）。这个策略可以记成<span class="arithmatex">\(\pi(s)\rightarrow a, s \in [1-9], a \in [上, 下, 左, 右]\)</span>。开始时机器人对于迷宫一无所知，所以<span class="arithmatex">\(\pi(s)会随机输出一个方向\)</span>。</p>
<nav class="md-post__action">
<a href="2025/02/09/rl_ds_r1/">
          继续阅读
        </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2024-01-25 00:00:00+00:00">2024年1月25日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a>, 
              <a class="md-meta__link" href="category/training/">Training</a></li>
<li class="md-meta__item">
            
              需要 2 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="_1"><a class="toclink" href="2024/01/25/review-dist-train/">关于分布式模型并行的分正式评论</a></h2>
<p>关于Data Parallel（DP）、Tensor Parallel（TP）和Pipeline Parallel（PP）等分布式并行策略，与Megatron、DeepSpeed和FSDP等实现的一些深入研究与讨论。分布式并行训练主要解决两类问题：</p>
<ol>
<li>模型分片：模型大小远超单节点存储上来，需要多节点分片存储和计算担；</li>
<li>并行训练：提高单位时间内的算力密度，进而降低整体训练时间；<br/>
分布式并行训练几乎总是会引入昂贵的成本，比如增加了昂贵的多节点通信、引入了额外的多机稳定性问题、以及额外的开发与调试成本等，因此我们应该尽量避免引入分布式并行训练。而不得不引入分布式训练的场景中，也应充分考虑通信开销，尽量降低并行的规模。</li>
</ol>
<h3 id="3d"><a class="toclink" href="2024/01/25/review-dist-train/#3d">3D模型并行</a></h3>
<p>根据切分维度的不同，并行策略主要分为如下几类：</p>
<ol>
<li>Data Parallel（DP）：将数据切分成N份，每个instance采用完全相同的配置，在计算梯度后通过all reduce全局同步梯度，并分别更新；</li>
<li>Tensor Parallel（TP）：将每个tensor切分成N份，在矩阵乘法等计算时进行同步；也称为横切</li>
<li>Pipeline Parallel （PP）：将模型按执行前后顺序切分多分（通常按layer切分），并根据顺序依次执行；</li>
<li>Zero Redundancy Optimizer（ZeRO）：同样将tensor切分成N份，但是在前向与后向计算时在每个分布式节点重建原始Tensor；</li>
<li>Sequence Parallel（SP）：在超长序列上进行训练时，将计算切分至多个节点；</li>
</ol>
<p><img alt="dp_tp_pp.png" src="imgs/dp_tp_pp.png" title="dp_tp_pp.png"/></p>
<nav class="md-post__action">
<a href="2024/01/25/review-dist-train/">
          继续阅读
        </a>
</nav>
</div>
</article>
<article class="md-post md-post--excerpt">
<header class="md-post__header">
<div class="md-post__meta md-meta">
<ul class="md-meta__list">
<li class="md-meta__item">
<time datetime="2024-01-21 00:00:00+00:00">2024年1月21日</time></li>
<li class="md-meta__item">
            分类于
            
              <a class="md-meta__link" href="category/llm/">LLM</a></li>
<li class="md-meta__item">
            
              需要 3 分钟阅读时间
            
          </li>
</ul>
</div>
</header>
<div class="md-post__content md-typeset">
<h2 id="scaling-law"><a class="toclink" href="2024/01/21/review-scaling-law/">关于Scaling Law的非正式评论</a></h2>
<p>大模型被广泛关注的起点是OpenAI发布ChatGPT，凭借优秀的对话能力与In-Context Learning的能力，吸引了整个AI圈的关注。<br/>
LLM技术的发展主要得益于Scaling Law给出的一系列预测，这些预测主导了最近几年LLM模型在参数、数据和算力规模上快速增长。<br/>
甚至有人提出了”Scale is All You Need!”。本文主要讨论LLM行为的可预测性，记录关于Scaling Law、Grokking和Double descent等empirical phenomenon的讨论。</p>
<h3 id="_1"><a class="toclink" href="2024/01/21/review-scaling-law/#_1">大模型的良好泛化性</a></h3>
<p>OpenAI在GPT3论文中提出GPT-3等语言模型（language model）是few shot learner。这一概念出自In-Context Learning，具体是指在模型预测时通过上下文中给出足够的背景知识和任务描述，然后直接预测<sup id="fnref:1"><a class="footnote-ref" href="2024/01/21/review-scaling-law/#fn:1">1</a></sup>，比如：</p>
<ul>
<li>Zero-shot（没有示例）：{<mark>8+9=?</mark>}</li>
<li>One-shot（一个示例）：5+5=10, {<mark>8+9=?</mark>}</li>
<li>Few-shot（多个示例）：6+7=13,6+6=12,5+5=10, {==8+9=? ==}</li>
</ul>
<p>Open AI在2020年的大模型Scaling Law论文中发现，若将模型迁移到新的数据集，新数据集上的测试loss与训练数据集上的测试loss存在一个相对恒定的offset。随着模型规模的增大，训练数据集和新数据集上的测试loss近似同步下降。这也就意味着可以通过持续增大模型大小来降低模型在所有数据集上的loss。</p>
<p><img alt="Pasted image 20240121235222.png" src="imgs/Pasted%20image%2020240121235222.png" title="Pasted image 20240121235222.png"/></p>
<p>这种优秀的泛化性给出了一种全新的探索方向：相比探索更复杂的模型结构，探索更大的模型是否能够成为深度学习的全新路径。</p>
<nav class="md-post__action">
<a href="2024/01/21/review-scaling-law/">
          继续阅读
        </a>
</nav>
</div>
</article>
<nav class="md-pagination">
<span class="md-pagination__current">1</span> <a class="md-pagination__link" href="page/2/">2</a>
</nav>
</div>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  回到页面顶部
</button>
</main>
<footer class="md-footer">
<nav aria-label="页脚" class="md-footer__inner md-grid">
<a aria-label="下一页: AI基础设施" class="md-footer__link md-footer__link--next" href="category/ai%E5%9F%BA%E7%A1%80%E8%AE%BE%E6%96%BD/">
<div class="md-footer__title">
<span class="md-footer__direction">
                下一页
              </span>
<div class="md-ellipsis">
                AI基础设施
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Copyright © 2023 - 2025 Reiase
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/reiase" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 7.0.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": ".", "features": ["content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.tooltips", "navigation.tabs", "navigation.sections", "navigation.footer", "navigation.indexes", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script>
<script src="assets/javascripts/bundle.f55a23d4.min.js"></script>
<script src="assets/_markdown_exec_pyodide.js"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
<script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>