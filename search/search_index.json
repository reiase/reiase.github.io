{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stemmer"]},"docs":[{"location":"","title":"Blog","text":""},{"location":"tags/","title":"\u6807\u7b7e","text":""},{"location":"tags/#tag:fp8","title":"FP8","text":"<ul> <li>            INT8\u4e5f\u80fd\u8bad\u7ec3          </li> <li>            \u4eceDeepSeek V3\u770bFP8\u8bad\u7ec3\u7684\u6311\u6218          </li> </ul>"},{"location":"tags/#tag:llm","title":"LLM","text":"<ul> <li>            INT8\u4e5f\u80fd\u8bad\u7ec3          </li> <li>            Kaplan Scaling Law vs Chinchilla Optimal          </li> <li>            LLM\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u975e\u6b63\u5f0f\u8bc4\u8bba          </li> <li>            \u4eceDeepSeek V3\u770bFP8\u8bad\u7ec3\u7684\u6311\u6218          </li> <li>            \u4ece\u5f3a\u5316\u5b66\u4e60\u5230DeepSeek R1          </li> <li>            \u5173\u4e8e\u5206\u5e03\u5f0f\u6a21\u578b\u5e76\u884c\u7684\u5206\u6b63\u5f0f\u8bc4\u8bba          </li> </ul>"},{"location":"tags/#tag:optimization","title":"Optimization","text":"<ul> <li>            Minorize-Maximization          </li> </ul>"},{"location":"tags/#tag:pretrain","title":"Pretrain","text":"<ul> <li>            Kaplan Scaling Law vs Chinchilla Optimal          </li> <li>            LLM\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u975e\u6b63\u5f0f\u8bc4\u8bba          </li> </ul>"},{"location":"tags/#tag:rl","title":"RL","text":"<ul> <li>            Importance Sampling          </li> <li>            Minorize-Maximization          </li> <li>            \u4ece\u5f3a\u5316\u5b66\u4e60\u5230DeepSeek R1          </li> </ul>"},{"location":"tags/#tag:training","title":"Training","text":"<ul> <li>            AdamW          </li> <li>            INT8\u4e5f\u80fd\u8bad\u7ec3          </li> <li>            \u4eceDeepSeek V3\u770bFP8\u8bad\u7ec3\u7684\u6311\u6218          </li> <li>            \u4ece\u5f3a\u5316\u5b66\u4e60\u5230DeepSeek R1          </li> <li>            \u5173\u4e8e\u5206\u5e03\u5f0f\u6a21\u578b\u5e76\u884c\u7684\u5206\u6b63\u5f0f\u8bc4\u8bba          </li> </ul>"},{"location":"nodes/AdamW/","title":"AdamW","text":"<p>LLM\u8bad\u7ec3\u4e2d\u901a\u5e38\u4f7f\u7528AdamW\u4f18\u5316\u5668\uff0c\u914d\u5408grad clip\u53c2\u65701.0\u4e0eweight decay\u53c2\u65700.1\u4f7f\u7528\u3002AdamW\u4f18\u5316\u5668\u7684\u4f2a\u4ee3\u7801\u5165\u4e0b\u56fe\u6240\u793a\uff1a </p>","tags":["Training"]},{"location":"nodes/AdamW/#weight-decay","title":"weight decay","text":"<p>\u4e0b\u56fe\u7b80\u5355\u7ed8\u5236\u4e86\u6743\u91cd\u56e0weight decay\u968f\u8bad\u7ec3\u8870\u51cf\u7684\u60c5\u51b5\uff0c\\(\\theta_{t+n} = \\gamma^n\\theta_t\\)\uff0c\u5f53\\(\\gamma\\)\u5206\u522b\u53d60.01\u4e0e0.1\u65f6\uff0c\u8bad\u7ec3100\u4e2astep\u540e\u6743\u91cd\u8870\u51cf\u5982\u4e0b\uff1a  \u5f53\\(\\gamma=0.1\\)\u65f6\uff0c40\u4e2astep\u540e\u6743\u91cd\u8870\u51cf\u4e3a\u539f\u6765\u76841%\uff0c\u57fa\u672c\u53ef\u4ee5\u5ffd\u7565\u4e0d\u8ba1\u3002\u56e0\u6b64\u5728\u5b9e\u9645LLM\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6a21\u578b\u7684\u9057\u5fd8\u4f5c\u7528\u975e\u5e38\u5f3a\u3002</p>","tags":["Training"]},{"location":"nodes/AdamW/#_1","title":"\u7a33\u6001\u5206\u6790","text":"<p>\u82e5\u5c06AdamW\u4f18\u5316\u5668\u770b\u6210\u4e00\u4e2a\u52a8\u529b\u5b66\u7cfb\u7edf\uff0c\u5e76\u5047\u8bbe\u6a21\u578b\u6536\u655b\u65f6\u6743\u91cd\u66f4\u65b0\u8fd1\u4f3c\u4e3a0\uff0c\u5373 $$     \\theta_{t} = \\theta_{t-1} $$ \u5e26\u5165AdamW\u7684\u6700\u540e\u66f4\u65b0\u516c\u5f0f $$     \\theta_t = \\theta_{t-1} - \\lambda \\theta_{t-1} - \\gamma \\frac{m_t}{\\sqrt{v_t}+\\epsilon} $$ \u6709\uff1a $$     \\lambda \\theta_{t-1} = - \\gamma\\frac{m_t}{\\sqrt{v_t}+\\epsilon} $$ \u5373\u7cfb\u7edf\u8fbe\u5230\u7a33\u6001\u65f6\uff0c\u6743\u91cd\u6b63\u6bd4\u4e8e\u77ed\u65f6\u95f4\u5185\u68af\u5ea6\u7684\u6ed1\u52a8\u5e73\u5747\u3002</p>","tags":["Training"]},{"location":"nodes/AdamW/#_2","title":"\u68af\u5ea6\u5206\u6790","text":"<p>\u82e5\u7cfb\u7edf\u8fbe\u5230\u7a33\u6001\uff0c\\(\\theta_t\\) \u8fd1\u4f3c\u4e0d\u53d8\uff0c\u5219\u53ef\u4ee5\u8ba4\u4e3a\u6a21\u578b\u5728\u8be5\u6743\u91cd\u5904\u7684\u68af\u5ea6\u8fd1\u4f3c\u4e0d\u53d8\uff0c\u6b64\u65f6\\(|m_t| \\simeq \\sqrt{v_t}\\)\uff0c\u5219\u6709 $$         \\lambda \\theta_{t-1} = - \\gamma\\frac{m_t / |m_t| }{\\sqrt{v_t}/|m_t|+\\epsilon/|m_t|} = - \\gamma\\frac{sign(m_t)}{1+\\epsilon/|m_t|} $$ $$     \\theta_t = - \\frac{\\gamma}{\\lambda} \\times \\frac{sign(m_t)}{1+\\epsilon/|m_t|} $$ \u8003\u8651\u5230\u7cfb\u7edf\u8fbe\u5230\u7a33\u6001\u65f6\\(m_t = g_t\\)\uff0c\u5219\uff1a $$     \\theta_t = - \\frac{\\gamma}{\\lambda} \\times \\frac{sign(g_t)}{1+\\epsilon/|g_t|} = - \\frac{\\gamma}{\\lambda} \\times \\frac{sign(\\nabla L(\\theta_t))}{1+\\epsilon /  |\\nabla L(\\theta_t)|}  $$ \u4e0a\u8ff0\u516c\u5f0f\u4e3a\u4e00\u4e2a\u4e00\u9636\u5fae\u5206\u65b9\u7a0b\uff0c\u7cfb\u7edf\u7a33\u6001\u5bf9\u5e94\u8be5\u4e00\u9636\u5fae\u5206\u65b9\u7a0b\u7684\u89e3\u3002</p>","tags":["Training"]},{"location":"nodes/Importance%20Sampling/","title":"Importance Sampling","text":"<p>\u5728\u8ba1\u7b97\u671f\u671b\u7684\u65f6\u5019\uff0c\u9700\u8981\u4e00\u4e2a\u6982\u7387\u5206\u5e03\\(p(x)\\):</p> \\[ \\mathbb{E}_p[f(x)] = \\int_x f(x)p(x) dx \\] <p>\u4f46\u662f\u4efb\u610f\u5206\u5e03\\(p(x)\\)\u901a\u5e38\u96be\u4ee5\u4ece\u968f\u673a\u6570\u53d1\u751f\u5668\u6765\u751f\u6210\uff0c\u6b64\u65f6\u9700\u8981\u501f\u52a9\u4e00\u4e2a\u66f4\u52a0\u5bb9\u6613\u83b7\u5f97\u7684\u8f85\u52a9\u5206\u5e03\\(q(x)\\)\u6765\u89e3\u51b3\u95ee\u9898\uff1a</p> \\[ \\mathbb{E}_p[f(x)] = \\int_x f(x)p(x) dx \\\\  = \\int_x f(x)\\frac{p(x)q(x)}{q(x)} dx \\\\  = \\int_x \\left [f(x)\\frac{p(x)}{q(x)} \\right ] q(x) dx \\] <p>\u5176\u4e2d\uff0c\\(\\frac{p(x)}{q(x)}\\)\u4e3a\u91cd\u8981\u6027\u6743\u91cd\u3002\u8fd9\u6837\u5c31\u53ef\u4ee5\u901a\u8fc7\u5206\u5e03\\(q(x)\\)\u8fdb\u884c\u91c7\u6837\u4e86\u3002</p>","tags":["RL"]},{"location":"nodes/Minorize%20Maximization/","title":"Minorize-Maximization","text":"<p>Minorize-Maximization\uff08MM\uff09\u662f\u4e00\u79cd\u8fed\u4ee3\u4f18\u5316\u65b9\u6cd5\u3002\u5f53\u76ee\u6807\u51fd\u6570\u6bd4\u8f83\u590d\u6742\u96be\u4ee5\u4f18\u5316\u65f6\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u8fd1\u4f3c\u51fd\u6570\u6765\u8fed\u4ee3\u6c42\u89e3\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5bf9\u4e8e\u95ee\u9898</p> \\[     x^* = \\arg\\max_x f(x) \\] <p>\u53ef\u4ee5\u5bfb\u627e\u66ff\u4ee3\u51fd\u6570\\(g(x)\\)\uff0c\u5e76\u4f7f\u5176\u6ee1\u8db3\uff1a</p> <ol> <li>\\(g(x)\\)\u662f\\(f(x)\\)\u7684\u4e0b\u754c\uff1a</li> </ol> \\[     f(x) \\ge g(x), \\forall x \\] <ol> <li>\u5728\\(x_0\\)\u5904\uff0c\u4e0b\u754c\u662f\u7d27\u7684\uff1a</li> </ol> \\[     f(x_0) = g(x_0) \\] <p>MM \u65b9\u6cd5\u7684\u4f18\u5316\u6b65\u9aa4\u5982\u4e0b\uff1a</p> <ul> <li>\u6b65\u9aa41:\u5728\\(x_t\\)\u5904\uff0c\u6784\u9020\u4e0b\u754c\u51fd\u6570 \\(g(x)\\)\uff0c\u4f7f\u5176\u6ee1\u8db3\uff1a</li> </ul> \\[     f(x) \\ge g(x), \u4e14 f(x_t) = g(x_t) \\] <ul> <li>\u6b65\u9aa42: \u66f4\u65b0\\(x\\):</li> </ul> \\[     x_{t+1} = \\arg\\max_x g(x) \\] <ul> <li>\u6b65\u9aa43\uff1a\u91cd\u590d\u6b65\u9aa41\uff0c\u91cd\u65b0\u6784\u9020\u4e0b\u754c\u51fd\u6570\uff0c\u8fed\u4ee3\u4f18\u5316\u81f3\u6536\u655b\uff1b</li> </ul>","tags":["RL","Optimization"]},{"location":"nodes/Random%20Round/","title":"Random Round","text":"<p>Random Round\u662f\u6307\u6d6e\u70b9\u6570\u91cf\u5316\u65f6\uff0c\u968f\u673around\u5230\u76f8\u90bb\u7684\u6570\u503c\uff0c\u800c\u4e0d\u662fround\u5230\u6700\u8fd1\u7684\u6570\u503c\u3002\u968f\u673around\u867d\u7136\u589e\u52a0\u4e86\u5355\u4e2a\u6570\u503c\u7684\u91cf\u5316\u8bef\u5dee\uff0c\u4f46\u662f\u80fd\u591f\u907f\u514d\u6574\u4f53\u7684\u6709\u504f\u91cf\u5316\u8bef\u5dee\u3002\u56e0\u6b64\uff0c\u5728\u67d0\u4e9b\u8bad\u7ec3\u573a\u666f\u4e0b\u80fd\u591f\u907f\u514d\u6709\u504f\u91cf\u5316\u8bef\u5dee\u5e26\u6765\u7684\u6536\u655b\u901f\u5ea6\u6162\u95ee\u9898\uff0c\u5177\u4f53\u53ef\u89c1Gopher\u8bba\u6587<sup>1</sup> \u7684Figure A7\u3002 </p> <ol> <li> <p>2021, DeepMind, Scaling Language Models: Methods, Analysis &amp; Insights from Training Gopher\u00a0\u21a9</p> </li> </ol>"},{"location":"nodes/Scaling%20Law%20%E8%AE%A1%E7%AE%97%E5%99%A8/","title":"Scaling Law \u8ba1\u7b97\u5668","text":""},{"location":"nodes/Scaling%20Law%20%E8%AE%A1%E7%AE%97%E5%99%A8/#kaplan-scaling-law","title":"Kaplan Scaling Law","text":"\u8ba1\u7b97\u5668\u9996\u6b21\u52a0\u8f7d\u9700\u8981\u65f6\u95f4 <p> Editor (session: default) Run <pre>import micropip\n\nawait micropip.install(\"https://cdn.holoviz.org/panel/1.3.8/dist/wheels/bokeh-3.3.3-py3-none-any.whl\")\nawait micropip.install(\"https://cdn.holoviz.org/panel/1.3.8/dist/wheels/panel-1.3.8-py3-none-any.whl\")\n\nimport panel as pn\nfrom bokeh.models.formatters import PrintfTickFormatter\n\npn.extension(sizing_mode=\"stretch_width\")\n\nModelSelector = pn.widgets.Select(name=\"model\", value=\"LLaMa2 7B\", options=[\n    \"Custom Model\",\n    \"LLaMa 7B\",\n    \"LLaMa2 7B\",\n])\n\nNSlider = pn.widgets.FloatSlider(start=1, end=200, step=0.1, \n    format=PrintfTickFormatter(format='%.1f B'), name='\u6a21\u578b\u89c4\u6a21\uff08B\uff09')\nDSlider = pn.widgets.FloatSlider(start=1, end=5000, step=100, \n    format=PrintfTickFormatter(format='%.1f B'), name='\u6570\u636e\u89c4\u6a21\uff08B\uff09')\nCText = pn.widgets.StaticText(name=\"\u7b97\u529b\u9700\u6c42C\uff08pf-day\uff09\")\npfday = pn.widgets.StaticText(value=\"pf-day\u4e3a1P FLOPs x 24\u5c0f\u65f6\uff0c\u7ea6\u4e3a8.64E19\")\n\ndef callback(new):\n    ModelSelector.value = \"Custom Model\"\n    CText.value = \"%.1f pf-day\"%(6*NSlider.value*1E9*DSlider.value*1E9/8.64E19)\n    return\n\ndef select_model(new):\n    if new == \"Custom Model\":\n        return\n    if new == \"LLaMa2 7B\":\n        NSlider.value=7.0\n        DSlider.value=2000\n    elif new == \"LLaMa 7B\":\n        NSlider.value=7.0\n        DSlider.value=1500\n\n\npn.Column(\n    ModelSelector,\n    NSlider, DSlider, \n    CText, pfday,\n    pn.bind(callback, NSlider),\n    pn.bind(callback, DSlider),\n    pn.bind(select_model, ModelSelector),\n).servable(target='kaplan_scaling');</pre> Output Clear <pre></pre> </p>"},{"location":"nodes/kaplan%20vs%20chinchilla/","title":"Kaplan Scaling Law vs Chinchilla Optimal","text":"<pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n%matplotlib inline\n</code></pre> <pre><code>def LN(n):\n    return (8.8*(10**13)/n)**0.076\n\ndef LD(d):\n    return (5.4*(10**13)/d)**0.095\n\ndef ld(l):\n    return 5.4*(10**13)/(l**(1/0.095))\n</code></pre> <p>GPT3\u7684\u53c2\u6570\u91cf\u4e3a175B\uff0c\u9884\u6d4b\u7684loss\u503c\u4e3a<code>LN(175*10**9)</code>\uff0c\u6240\u9700token\u6570\u91cf\u4e3a<code>ld(LN(175*10**9))</code>\u3002</p>","tags":["LLM","Pretrain"]},{"location":"2025/02/09/rl_ds_r1/","title":"\u4ece\u5f3a\u5316\u5b66\u4e60\u5230DeepSeek R1","text":"","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#1-rl-reinforcement-learning","title":"1. \u4ec0\u4e48\u662f\u5f3a\u5316\u5b66\u4e60(RL, Reinforcement Learning)","text":"<p>\u4f20\u7edf\u7684\u673a\u5668\u5b66\u4e60\uff0c\u5305\u62ec\u6df1\u5ea6\u5b66\u4e60\uff0c\u5176\u672c\u8d28\u662f\u6570\u5b66\u6027\u7684\uff0c\u4e25\u683c\u9075\u5b88\u51fd\u6570\u7684\u6570\u5b66\u5b9a\u4e49\uff1a\u5bf9\u4e8e\u7ed9\u5b9a\u8f93\u5165\uff0c\u4ea7\u751f\u786e\u5b9a\u7684\u8f93\u51fa</p> \\[F(x) = y\\] <p>\u968f\u7740\u8f93\u5165\\(x\\)\u548c\u8f93\u51fa\\(y\\)\u7684\u4e0d\u540c\uff0c\u8fd9\u4e00\u8303\u5f0f\u53ef\u4ee5\u9002\u914d\u5404\u79cd\u4e0d\u540c\u7684\u4efb\u52a1\uff0c\u6bd4\u5982\uff1a</p> <ul> <li>\\(x\\) \u662f\u56fe\u50cf\uff0c\\(y\\)\u662f\u7c7b\u522b\uff0c\u90a3\u4e48\\(F\\)\u5c31\u662fResnet\u8fd9\u79cd\u56fe\u50cf\u6a21\u578b\uff1b</li> <li>\\(x\\) \u662f\u8bed\u97f3\u4fe1\u53f7\uff0c\\(y\\)\u662f\u6587\u5b57\uff0c\u90a3\u4e48\\(F\\)\u5c31\u662f\u4e00\u4e2a\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\uff1b</li> <li>\\(x\\) \u662f\u6587\u672c\u8f93\u5165\uff0c\\(y\\)\u662f\u6587\u672c\u8f93\u51fa\uff0c\u90a3\u4e48\\(F\\)\u5c31\u662f\u65f6\u4e0b\u706b\u70ed\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff1b \u2026</li> </ul> <p>\u5f3a\u5316\u5b66\u4e60\uff08Reinforcement Learning\uff09\u7684\u672c\u8d28\u4e0a\u5219\u662f\u54f2\u5b66\u6027\u7684\uff0c\u5b83\u63a2\u8ba8\u4e09\u4e2a\u6838\u5fc3\u95ee\u9898\uff1a</p> <ul> <li>\u6211\u662f\u8c01\uff1f\u4e00\u4e2aAgent</li> <li>\u6211\u5728\u54ea\uff1f\u5904\u4e8e\u67d0\u4e2aState</li> <li>\u5230\u54ea\u91cc\u53bb\uff1f\u91c7\u53d6\u4e00\u4e2aAction</li> </ul> <p>\u5982\u679c\u7ad9\u5728\u4e0a\u5e1d\u89c6\u89d2\u53bb\u89c2\u6d4b\u8fd9\u4e2aAgent\uff0c\u6211\u4eec\u8fd8\u4f1a\u53d1\u73b0\uff1a</p> <ul> <li>Agent\u5904\u5728\u4e00\u4e2a\u73af\u5883\u4e2d\uff08Environment\uff09</li> <li>Agent\u6709\u4e00\u4e2a\u7528\u6765\u7b56\u7565\uff08Policy\uff09\u544a\u8bc9\u6211\u8be5\u91c7\u53d6\u4ec0\u4e48\u52a8\u4f5c\uff08Action\uff09</li> <li>\u6bcf\u6267\u884c\u4e00\u4e2a\u52a8\u4f5c\uff08Action\uff09\uff0c\u73af\u5883\u90fd\u4f1a\u7ed9\u6211\u53cd\u9988 (Reward)</li> </ul> <p>\u4ee5\u4e0a\u5c31\u662f\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u4e3b\u8981\u6982\u5ff5\u3002</p> <p></p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#2","title":"2. \u5982\u4f55\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60","text":"<p>\u8fd9\u91cc\u4ee5\u4e00\u4e2a\u8ff7\u5bab\u95ee\u9898\u4e3a\u4f8b\uff0c\u4ecb\u7ecd\u5982\u4f55\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff1a</p> <p>\u8ff7\u5bab\uff1a(S: Start, E: End, W: Wall)</p> <pre><code>block-beta\n  columns 3\n  S1[\"S1(S)\"] S2 S3[\"S3(W)\"]\n  S4 S5 S6\n  S7[\"S7(W)\"] S8 S9[\"S9(E)\"]\n</code></pre> <p>\u8fd9\u4e2a\u8ff7\u5bab\u5c31\u662f\u4e00\u4e2aEnvironment\u3002\u6211\u4eec\u653e\u7f6e\u4e00\u4e2a\u673a\u5668\u4eba\u5728\u5f00\u59cb\u5904\uff08Start\uff09\uff0c\u8ba9\u673a\u5668\u4eba\u81ea\u52a8\u5b66\u4e60\u5982\u4f55\u8d70\u8ff7\u5bab\u7684\u7b56\u7565\uff08Policy\uff09\u3002\u8fd9\u4e2a\u7b56\u7565\u53ef\u4ee5\u8bb0\u6210\\(\\pi(s)\\rightarrow a, s \\in [1-9], a \\in [\u4e0a, \u4e0b, \u5de6, \u53f3]\\)\u3002\u5f00\u59cb\u65f6\u673a\u5668\u4eba\u5bf9\u4e8e\u8ff7\u5bab\u4e00\u65e0\u6240\u77e5\uff0c\u6240\u4ee5\\(\\pi(s)\u4f1a\u968f\u673a\u8f93\u51fa\u4e00\u4e2a\u65b9\u5411\\)\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#21-q-learning","title":"2.1. Q-Learning","text":"<p>Q-Learning\u662f\u6700\u65e9\uff0c\u4e5f\u662f\u6700\u7b80\u5355\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002\u524d\u6587\u63d0\u5230\u7684\u7b56\u7565\\(\\pi(s)\\)\u8fc7\u4e8e\u62bd\u8c61\u4e86\uff0c\u6240\u4ee5\u6211\u4eec\u4e5f\u5b9a\u4e49\u4ee5\u4e0b\u8868\u683c</p> \u4e0a \u4e0b \u5de6 \u53f3 s1 s2 \u2026 <p>\u6211\u4eec\u79f0\u8fd9\u5f20\u8868\u4e3aQ\u503c\u8868\uff0c\u8868\u91cc\u8fb9\u7684\u5143\u7d20 \\(Q(s, a)\\)\u8868\u793a\u5728\u72b6\u6001\\(s\\)\u4e0b\uff0c\u91c7\u53d6\u52a8\u4f5c\\(a\\)\u7684\u5956\u52b1\\(reward\\)\u3002\u57fa\u4e8e\u8fd9\u5f20Q\u503c\u8868\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49\u7b56\u7565\uff1a $$ \\pi(s_i) \\rightarrow \\arg\\max_a Q(s, a)|_{s=s_i} $$ \u5b8c\u6210\u8ff7\u5bab\u6240\u9700\u8981\u7684\u6700\u5c0f\u7684Q\u503c\u8868\u5982\u4e0b\uff1a</p> \u4e0a \u4e0b \u5de6 \u53f3 s1 -1 1 -1 0 s4 0 -1 -1 1 s5 0 1 0 0 s8 0 -1 -1 1 <p>\u53ef\u4ee5\u6307\u6325Agent\u6cbf\u5982\u4e0b\u8def\u5f84\u884c\u8fdb</p> <pre><code>block-beta\n  columns 3\n  S1[\"S1(S)\u2193\"] S2 S3[\"S3(W)\"]\n  S4[\"S4\u2192\"] S5[\"S5\u2193\"] S6\n  S7[\"S7(W)\"] S8[\"S8\u2192\"] S9[\"S9(E)\"]</code></pre> <p>\u4f46\u662f\u6211\u4eec\u5f88\u5feb\u53d1\u73b0Agent\u884c\u8fdb\u7684\u8def\u5f84\u5e76\u4e0d\u552f\u4e00\uff0c\u6bd4\u5982\u4ee5\u4e0b\u8def\u5f84\u4e5f\u80fd\u8ba9Agent\u8d70\u5230\u7ec8\u70b9</p> <pre><code>block-beta\n  columns 3\n  S1[\"S1(S)\u2192\"] S2[\"S2\u2193\"] S3[\"S3(W)\"]\n  S4[\"S4\"] S5[\"S5\u2193\"] S6\n  S7[\"S7(W)\"] S8[\"S8\u2192\"] S9[\"S9(E)\"]\n</code></pre> <p>\u8fd9\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u7b2c\u4e00\u4e2a\u95ee\u9898\uff0c\u6a21\u578b\u7684\u89e3\u4e0d\u552f\u4e00\u3002\u7a0d\u540e\u6211\u4eec\u8ba8\u8bba\u8fd9\u79cd\u89e3\u4e0d\u552f\u4e00\u5e26\u6765\u7684\u95ee\u9898\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#22-q-learning","title":"2.2. Q-Learning \u7684\u5b66\u4e60\u8fc7\u7a0b","text":"<ol> <li>Q\u503c\u8868\u521d\u59cb\u5316\uff0c\u53ef\u4ee5\u5168\u90e8\u521d\u59cb\u5316\u4e3a0\uff1b</li> <li> <p>\u8fed\u4ee3\u5b66\u4e60\uff1a\u6211\u4eec\u5047\u8bbeAgent\u88ab\u521d\u59cb\u5316\u5728S0\u4f4d\u7f6e</p> <ol> <li> <p>\u9009\u62e9action </p> \\[a = \\pi(s_i) = \\arg\\max_a Q(s, a)|_{s=s_i}\\] </li> <li> <p>\u6267\u884caction, \u73af\u5883Environment\u7ed9\u51fa\u4e0b\u4e00\u4e2a\u72b6\u6001\\(s'\u4e0e\u5956\u52b1\\)r$</p> \\[s',r = Environment(s, a)\\] </li> <li> <p>\u66f4\u65b0Q\u503c\uff0c\u8fd9\u91cc\u4e00\u822c\u4f7f\u7528Bellman\u65b9\u7a0b\uff1a</p> \\[Q(s,a)\\leftarrow Q(s,a) + \\alpha [r+\\gamma \\max_{a'}Q(s',a')-Q(s,a)]\\] </li> </ol> <p>\u5176\u4e2d\uff1a</p> <ul> <li>\\(\\alpha\\) \u4e3a\u5b66\u4e60\u7387\uff0c\u63a7\u5236Q\u503c\u8868\u7684\u66f4\u65b0\u5e45\u5ea6\uff1b</li> <li>\\(\\gamma\\) \u4e3a\u6298\u6263\u56e0\u5b50\uff0c\u63a7\u5236\u957f\u671f\u5956\u52b1\u4e0e\u5373\u65f6\u5956\u52b1\u7684\u5e73\u8861\uff1b</li> </ul> </li> </ol> <p>Q-Learning\u672c\u8d28\u4e0a\u5c31\u662f\u8bb0\u4f4f\u5f53\u524d\u683c\u5b50\u7684\u5956\u52b1\uff0c\u540c\u65f6\u4e0d\u65ad\u6839\u636e\u672a\u6765\u4ef7\u503c\u91cd\u65b0\u8bc4\u4f30\u5f53\u524d\u683c\u5b50\u7684\u4ef7\u503c\u3002\u6700\u4f18\u60c5\u51b5\u4e0b\uff0c\u603b\u662f\u9009\u62e9\u672a\u6765\u4ef7\u503c\u6700\u9ad8\u7684\u52a8\u4f5c\u3002\u5728\u5b66\u4e60\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u4e2a\u683c\u5b50\u7684Q\u503c\u603b\u662f\u4f9d\u8d56\u4e8e\u5176\u4ed6\u683c\u5b50\u7684Q\u503c\uff0c\u683c\u5b50\u4e4b\u95f4\u76f8\u4e92\u4f9d\u8d56\uff0c\u975e\u5e38\u5bb9\u6613\u5bfc\u81f4Q\u503c\u957f\u671f\u9707\u8361\u65e0\u6cd5\u6536\u655b\u3002\u6b64\u65f6\u9700\u8981\u5bf9\u5b66\u4e60\u8fc7\u7a0b\u8fdb\u884c\u7cbe\u7ec6\u6311\u53c2\u624d\u80fd\u4fdd\u8bc1\u5b66\u4e60\u8fc7\u7a0b\u7684\u6536\u655b\u6027\u3002\u8fd9\u662f\u5f3a\u5316\u5b66\u4e60\u7684\u7b2c\u4e8c\u4e2a\u95ee\u9898\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#221-exploitation-exploration","title":"2.2.1. \u5229\u7528\u548c\u63a2\u7d22\uff08exploitation &amp; exploration\uff09","text":"<p>\u5982\u679c\u5355\u7eaf\u4f7f\u7528\u4e0a\u8ff0\u5b66\u4e60\u65b9\u6cd5\uff0c\u5f88\u5bb9\u6613\u51fa\u73b0\u5982\u4e0b\u95ee\u9898\uff1a</p> <pre><code>block-beta\n  columns 3\n  S1[\"S1(S)\u2192\"] S2[\"S2\u2193\"] S3[\"S3(W)\"]\n  S4[\"S4\"] S5[\"S5\u2191\"] S6\n  S7[\"S7(W)\"] S8[\"S8\"] S9[\"S9(E)\"]</code></pre> <p>\u5373Agent\u5728S2\u548cS5\u4e4b\u95f4\u53cd\u590d\u9707\u8361\uff0c\u65e0\u6cd5\u771f\u7684\u8d70\u5230\u7ec8\u70b9S9\u3002\u5176\u539f\u56e0\u5728\u4e8eAgent\u53ea\u80fd\u83b7\u53d6\u5176\u5386\u53f2\u8def\u5f84\u4e0a\u7684Q\u503c\uff0c\u7f3a\u4e4f\u5bf9\u6574\u4e2a\u4e16\u754c\uff08Environment\uff09\u7684\u8ba4\u77e5\uff0c\u65e0\u6cd5\u53d1\u73b0S8\u548cS6\u8fd9\u79cd\u66f4\u52a0\u9760\u8fd1\u7ec8\u70b9\u7684\u8def\u5f84\u3002\u6211\u4eec\u79f0\u8fd9\u79cd\u5229\u7528\u5386\u53f2\u77e5\u8bc6\u7684\u8fc7\u7a0b\u4e3a\u201c\u5229\u7528\u201d\uff08exploitation\uff09\u3002</p> <p>\u9664\u4e86\u201c\u5229\u7528\u201d\u4ee5\u5916\uff0c\u6211\u4eec\u8fd8\u9700\u8981\u8ba9Agent\u6709\u4e00\u5b9a\u7684\u201c\u63a2\u7d22\u201d\uff08exploration\uff09\u80fd\u529b\uff0c\u4fdd\u6301\u5bf9\u4e16\u754c\u7684\u597d\u5947\u5fc3\u3002\u6700\u5e38\u89c1\u7684\u63a2\u7d22\u65b9\u6cd5\u662f\u4f7f\u7528\\(\\epsilon-greedy\\)\u6539\u9020\u7b56\u7565 \\(\\phi\\):</p> \\[ \\phi(s_i) =  \\begin{cases}  \\pi(s_i) &amp; \\text{with probability } 1 - \\epsilon \\\\ \\text{random action} &amp; \\text{with probability } \\epsilon  \\end{cases} \\] <p>\u5373\u4ee5\u6982\u7387\\(1-\\epsilon\\)\u9009\u62e9\u6700\u4f18\u52a8\u4f5c\uff0c\u4ee5\u6982\u7387 \\(\\epsilon\\) \u9009\u62e9\u968f\u673a\u52a8\u4f5c\u3002\u4e3a\u4e86\u8ba9Q-Learning\u66f4\u597d\u7684\u6536\u655b\uff0c\u53ef\u4ee5\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9010\u6b65\u964d\u4f4e\u63a2\u7d22\u6982\u7387\\(\\epsilon\\)\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#222","title":"2.2.2. \u5f3a\u5316\u5b66\u4e60\u7684\u76ee\u6807","text":"<p>\u5f3a\u5316\u5b66\u4e60\u7684\u6838\u5fc3\u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u6700\u4f18\u7b56\u7565\\(\\pi^*\\)\uff0c\u4f7fAgent\u5728\u5176\u751f\u547d\u5468\u671f\u5185\u83b7\u5f97\u7684\u671f\u671b\u5956\u52b1\u6700\u5927\u5316\uff1a</p> \\[J(\\pi) = \\mathbb{E}\\left[ \\sum_{t=0}^{\\infty} \\gamma^t R_t \\mid \\pi \\right]\\] <p>\u76f4\u63a5\u5728\u7b56\u7565\u7a7a\u95f4\u4f18\u5316\\(\\pi\\) \u901a\u5e38\u662f\u4e0d\u53ef\u884c\u7684\uff1a</p> <ul> <li>\u7b56\u7565\u7a7a\u95f4\u8fc7\u5927\uff1a\\(\\pi(a|s)\\)\u662f\u4e00\u4e2a\u6982\u7387\u5206\u5e03\uff0c\u6781\u5927\u7684\u589e\u52a0\u4e86\u641c\u7d22\u96be\u5ea6\uff1b</li> <li>\u65e0\u68af\u5ea6\u4fe1\u606f\uff1a\u4e0d\u7ecf\u8fc7\u7279\u6b8a\u8bbe\u8ba1\uff0c\u96be\u4ee5\u76f4\u63a5\u5bf9\u7b56\u7565\u6c42\u5bfc\uff1b</li> </ul> <p>\u4e3a\u4e86\u89e3\u51b3\u4e0a\u8ff0\u95ee\u9898\uff0c\u5f15\u5165\u4e86 \u503c\u51fd\u6570 \u6765\u7b80\u5316\u4f18\u5316\u8fc7\u7a0b\uff0c\u503c\u51fd\u6570\u4e00\u822c\u6709\u4e24\u7c7b\uff1a</p> <ul> <li>\u72b6\u6001\u4ef7\u503c\u51fd\u6570\\(V^\\pi(s)\\): \u8868\u793a\u4ece\u67d0\u4e2a\u72b6\u6001\\(s\\)\u5f00\u59cb\uff0c\u9075\u5faa\u7b56\u7565\\(\\pi\\)\u540e\uff0c\u6240\u80fd\u83b7\u5f97\u7684\u957f\u671f\u56de\u62a5</li> </ul> \\[ V^\\pi(s) = \\mathbb{E} \\left[ \\sum_{t=0}^{\\infty} \\gamma^t r_t \\mid s_0 = s \\right] \\] <ul> <li>\\(\\gamma\\)\u4e3a\u6298\u6263\u56e0\u5b50\uff0c\u63a7\u5236\u672a\u6765\u5956\u52b1\u7684\u91cd\u8981\u6027\uff1b</li> <li>\\(r_t\\)\u4e3a\u65f6\u523b\\(t\\)\u7684\u5373\u65f6\u5956\u52b1\uff1b</li> <li>\\(\\mathbb{{E}}_\\pi\\)\u8868\u793a\u5bf9\u7b56\u7565\\(\\pi\\)\u7684\u6240\u6709\u53ef\u80fd\u591a\u505a\u6c42\u671f\u671b\u3002</li> </ul> <p>Bellman\u65b9\u7a0b\u662f\u4e0a\u8ff0\u503c\u51fd\u6570\u5b9a\u4e49\u7684\u9012\u5f52\u5f62\u4f3c\uff0c\u5c06\u4e0a\u8ff0\u5b9a\u4e49\u62c6\u89e3\u6210\u4e86\u5f53\u524d\u5956\u52b1\u548c\u672a\u6765\u72b6\u6001\u4ef7\u503c\uff1a</p> \\[ V^\\pi(s) = \\sum_{a} \\pi(a|s) [r(s, a)+\\gamma V^\\pi(s')] \\] <ul> <li>\u52a8\u4f5c\u4ef7\u503c\u51fd\u6570\\(Q^\\pi(s, a)\\): \u4e0e\u72b6\u6001\u4ef7\u503c\u51fd\u6570\u7c7b\u4f3c\uff0c\u53ea\u662f\u8868\u793a\u72b6\u6001\\(s\\)\u4e0b\u6267\u884c\u52a8\u4f5c\\(a\\)\u540e\uff0c\u80fd\u591f\u5f97\u5230\u7684\u957f\u671f\u56de\u62a5</li> <li> \\[     Q^\\pi(s,a) = \\mathbb{E} \\left[ \\sum_{t=0}^{\\infty} \\gamma^t r_t \\mid s_0 = s, a_0=a \\right] \\] </li> </ul>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#223","title":"2.2.3. \u5f3a\u5316\u5b66\u4e60\u7684\u6311\u6218","text":"<ol> <li> <p>\u8bad\u7ec3\u6837\u672c\u7684\u6982\u7387\u5206\u5e03\u95ee\u9898 \u4f20\u7edf\u7684\u76d1\u7763\u5b66\u4e60\u4e2d\uff0c\u4e00\u822c\u8981\u6c42\u8bad\u7ec3\u6837\u672c\u548c\u6d4b\u8bd5\u6837\u672c\u72ec\u7acb\u540c\u5206\u5e03\uff0c\u5373\u6837\u672c\u72ec\u7acb\u62bd\u6837\uff0c\u4f46\u6837\u672c\u6765\u6e90\u7684\u6982\u7387\u5206\u5e03\u4fdd\u6301\u4e0d\u53d8\u3002\u8fd9\u6837\u624d\u80fd\u8ba9\u76d1\u7763\u5b66\u4e60\u7b97\u6cd5\u4ece\u6570\u636e\u91cc\u8fb9\u603b\u7ed3\u548c\u5b66\u4e60\u89c4\u5f8b\u3002\u800c\u5f3a\u5316\u5b66\u4e60\u901a\u8fc7\u4e0e\u73af\u5883\u4ea4\u4e92\u6765\u83b7\u53d6\u6837\u672c\uff0cAgent\u7684\u521d\u59cb\u72b6\u6001\u3001\u8fd0\u884c\u8f68\u8ff9\u90fd\u4f1a\u5f71\u54cd\u91c7\u6837\u8fc7\u7a0b\u3002\u5373\u4e0d\u80fd\u4fdd\u8bc1\u4e24\u6b21\u8bad\u7ec3\u4e4b\u95f4\u7684\u6837\u672c\u662f\u72ec\u7acb\u540c\u5206\u5e03\uff0c\u4e5f\u65e0\u6cd5\u4fdd\u8bc1\u6d4b\u8bd5\u4e0e\u8bad\u7ec3\u7684\u6837\u672c\u662f\u72ec\u7acb\u540c\u5206\u5e03\u3002</p> </li> <li> <p>\u90e8\u5206\u89c2\u6d4b\u4e0e\u73af\u5883\u968f\u673a\u6027 \u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u8fc7\u7a0b\u53ea\u80fd\u5bf9\u6574\u4e2a\u4e16\u754c\uff08Environment\uff09\u8fdb\u884c\u90e8\u5206\u89c2\u6d4b\uff0c\u4e0d\u80fd\u611f\u77e5\u6574\u4e2a\u4e16\u754c\uff08\u6ca1\u89c1\u8fc7\u5e02\u9762\uff09\u3002\u6a21\u578b\u7ecf\u5e38\u51fa\u73b0\u5bf9\u5c40\u90e8\u8fc7\u5ea6\u5b66\u4e60\u3001\u8fc7\u62df\u5408\uff0c\u5bf9\u5168\u5c40\u6b20\u62df\u5408\u3002\u7531\u4e8e\u65e0\u6cd5\u754c\u5b9a\u8fc7\u62df\u5408\u548c\u6b20\u62df\u5408\u90e8\u5206\u7684\u8fb9\u754c\uff0c\u96be\u4ee5\u4fdd\u8bc1Agent\u5728\u672a\u89c1\u8fc7\u7684\u65b0\u73af\u5883\u4e2d\u884c\u4e3a\u7684\u5408\u7406\u6027\u548c\u7a33\u5b9a\u6027\u3002</p> </li> <li> <p>\u5ef6\u8fdf\u53cd\u9988\u4e0e\u7a00\u758f\u5956\u52b1 \u5728\u8bb8\u591a\u5f3a\u5316\u5b66\u4e60\u95ee\u9898\u4e2d\uff0c\u5956\u52b1\u4fe1\u53f7\u5f80\u5f80\u662f\u5ef6\u8fdf\u4e14\u7a00\u758f\u7684\uff0c\u5bfc\u81f4Agent\u96be\u4ee5\u53ca\u65f6\u5224\u5b9a\u884c\u4e3a\u7684\u597d\u574f\u3002\u8fd9\u79cd\u6fc0\u52b1\u4fe1\u53f7\u7684\u4e0d\u8fde\u7eed\u6027\u4f7f\u5f97\u4ef7\u503c\u51fd\u6570\u4f30\u8ba1\u65b9\u5dee\u53d8\u5927\uff0c\u4f1a\u589e\u52a0\u4f18\u5316\u96be\u5ea6\uff0c\u5fc5\u987b\u91c7\u7528\u5956\u52b1\u6574\u5f62\u3001\u7ecf\u9a8c\u56de\u653e\u7b49\u7b56\u7565\u6765\u7f13\u89e3\u8fd9\u4e00\u95ee\u9898\u3002</p> </li> </ol>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#3","title":"3. \u7b56\u7565\u68af\u5ea6\u65b9\u6cd5","text":"<p>\u5728\u4ecb\u7ecd\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u6765\u770b\u503c\u51fd\u6570\u65b9\u6cd5\u7684\u51e0\u4e2a\u95ee\u9898\uff1a</p> <ol> <li>\u53ea\u9002\u5408\u79bb\u6563\u72b6\u6001\u4e0e\u52a8\u4f5c\u7a7a\u95f4</li> <li>\u9700\u8981\u989d\u5916\u7ec4\u5408\u63a2\u7d22\u7b56\u7565</li> <li>\u968f\u673a\u63a2\u7d22\u5bf9\u6700\u574f\u60c5\u51b5\u7f3a\u4e4f\u63a7\u5236\uff1b</li> </ol> <p>\u800c\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u662f\u76f4\u63a5\u5bf9\u7b56\u7565\u8fdb\u884c\u6c42\u5bfc\u7684\u65b9\u6cd5\uff0c\u9996\u5148\u9700\u8981\u5c06\u7b56\u7565\u51fd\u6570\u53c2\u6570\u5316\\(\\pi(a|s) \\rightarrow \\pi_\\theta(a|s)\\)\uff0c\u6b64\u65f6\u53ef\u4ee5\u5c06\u5f3a\u5316\u5b66\u4e60\u7684\u76ee\u6807\u51fd\u6570\u5199\u4e3a</p> \\[   J(\\theta) = \\mathbb{E}_{\\tau \\sim p_\\theta(\\tau)}\\left[ R(\\tau) \\right] \\] <p>\u8fd9\u91cc\uff1a</p> <ul> <li>\\(\\tau = (s_0, a_0, s_1, a_1, ..., s_T, a_T)\\)\u662f\u4e00\u4e2a\u8f68\u8ff9\uff1b</li> <li>\\(R(\\tau) = \\sum_{t=0}^{T} r(s_t, a_t)\\) \u662f\u8f68\u8ff9\u7684\u6982\u7387\u5206\u5e03\uff1b</li> <li>\\(p_\\theta(\\tau)\\) \u662f\u8f68\u8ff9\u7684\u6982\u7387\uff0c\u7531\u7b56\u7565\u6982\u7387\u548c\u73af\u5883\u7684\u8f6c\u79fb\u6982\u7387\u7ec4\u6210\uff1b</li> </ul>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#31","title":"3.1. \u7b56\u7565\u68af\u5ea6\u5b9a\u7406","text":"<p>\u7b56\u7565\u68af\u5ea6\u53ef\u4ee5\u6839\u636e\u7b56\u7565\u68af\u5ea6\u5b9a\u7406\u8ba1\u7b97</p> \\[ \\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\tau \\sim p_\\theta(\\tau)}\\left[\\sum_{t=0}^{T} \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t)R(\\tau)\\right] \\] <p>\u5176\u4e2d\uff0c\\(\\nabla_\\theta \\log \\pi_\\theta(a_t|s_t)\\)\u662f\u7b56\u7565\u7684\u68af\u5ea6\uff0c\u901a\u8fc7\u8fd9\u4e2a\u68af\u5ea6\u53ef\u4ee5\u66f4\u65b0\u7b56\u7565\u5728\u72b6\u6001\\(s_t\\)\u4e0b\u91c7\u7528 \\(a_t\\)\u7684\u6982\u7387\u3002\u800c\\(R(\\tau)\\)\u8868\u793a\u7b56\u7565\u5e26\u6765\u7684\u672a\u6765\u56de\u62a5\uff0c\u56de\u62a5\u8d8a\u9ad8\u52a8\u4f5c\u88ab\u91c7\u7eb3\u7684\u6982\u7387\u8d8a\u9ad8\u3002\u4f30\u8ba1\u672a\u6765\u56de\u62a5\u662f\u8ba1\u7b97\u7b56\u7565\u68af\u5ea6\u6700\u91cd\u8981\u7684\u6b65\u9aa4\uff0c\u5e38\u89c1\u5b9e\u73b0\u6709\u4e24\u79cd\uff1a</p> <ul> <li>\u4f7f\u7528\u8499\u7279\u5361\u6d1b\u65b9\u6cd5\u4f30\u8ba1\\(Q_\\pi(s,a)\\)\uff0c\u7531\u4e8e\u4e0d\u9700\u8981\u4f7f\u7528\u6a21\u578b\uff0c\u4e5f\u79f0\u4e3a\u65e0\u6a21\u578b\u7b56\u7565\u68af\u5ea6\u7b97\u6cd5\uff1b</li> <li>\u901a\u8fc7\u5f15\u5165\u4ef7\u503c\u51fd\u6570\uff08\\(V_\\pi\\)\u6216\u8005\\(Q_\\pi\\)\uff09\u6765\u4f30\u8ba1\u672a\u6765\u56de\u62a5\uff1b</li> </ul> <p>\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5bf9\u6bd4\u503c\u51fd\u6570\u65b9\u6cd5\uff0c\u5177\u5907\u5982\u4e0b\u7279\u70b9\uff1a</p> <ul> <li>\u53ef\u4ee5\u57fa\u4e8e\u8f68\u8ff9\u5b66\u4e60\uff0c\u800c\u4e0d\u9700\u8981\u5b9e\u65f6\u4ea4\u4e92\u548c\u53cd\u9988</li> <li>\u9002\u5408\u9ad8\u7ef4\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\uff08\u5305\u62ecembedding\u7a7a\u95f4\uff09</li> <li>\u53ef\u4ee5\u628a\u5e8f\u5217\u751f\u6210\u6a21\u578b\u53ef\u4ee5\u4f5c\u4e3a\u7b56\u7565\uff1a<ul> <li>\u7528\u6237\u8f93\u5165\u4f5c\u4e3a\u72b6\u6001\u7a7a\u95f4\u3000\uff33\uff1b</li> <li>\u6a21\u578b\u8f93\u51fa\u4f5c\u4e3a\u52a8\u4f5c\u7a7a\u95f4\u3000\uff21\uff1b</li> <li>\u6a21\u578b\u53c2\u6570\u4f5c\u4e3a\u7b56\u7565\u53c2\u6570\u3000\\(\\theta\\); </li> </ul> </li> </ul> <p>\u7ed9\u51fa\u4eba\u7c7b\u504f\u597d\u53cd\u9988 \\(R(\\tau)\\)\u5373\u53ef\u76f4\u63a5\u4f7f\u7528PG\u65b9\u6cd5\u8bad\u7ec3LLM\u5bf9\u9f50\u4eba\u7c7b\u504f\u597d\u3002\u4f46PG\u7b97\u6cd5\u7684\u68af\u5ea6\u65b9\u5dee\u8f83\u5927\uff0c\u7a33\u5b9a\u6027\u6b20\u4f73\u3002\u540c\u65f6\\(R(\\tau)\\) \u4e5f\u96be\u4ee5\u76f4\u63a5\u5b9a\u4e49\u3001\u6253\u5206\uff0c\u56e0\u6b64PG\u65b9\u6cd5\u5e76\u672a\u5b9e\u9645\u5e94\u7528\u4e8eLLM\u5bf9\u9f50\u4efb\u52a1\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#32-trpotrust-region-policy-optimization","title":"3.2. \u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u7684\u6539\u8fdb\u2013TRPO\uff08Trust Region Policy Optimization\uff09","text":"<p>\u5f53\u628a\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u5e94\u7528\u4e8e\u8bad\u7ec3\u65f6\uff0c\u53ef\u4ee5\u901a\u8fc7\u4e0b\u5f0f\u8ba1\u7b97minibatch\u68af\u5ea6\uff1a</p> \\[ \\nabla_\\theta J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\sum_{t=0}^{T} \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t)R(\\tau) \\] <p>\u6700\u5927\u5316\u7d2f\u8ba1\u5956\u52b1\uff0c\u9700\u8981\u4f7f\u7528\u68af\u5ea6\u4e0a\u5347\u65b9\u6cd5\u5bf9\u53c2\u6570\u8fdb\u884c\u66f4\u65b0\uff1a</p> \\[   \\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta J(\\theta)  \\] <p>\u7b56\u7565\u66f4\u65b0\u5982\u4f55\u9009\u62e9\u6b65\u957f\\(\\alpha\\)\u662f\u4e00\u4e2a\u975e\u5e38\u5173\u952e\u7684\u95ee\u9898\uff1a</p> <ul> <li>\u8fc7\u5927\u7684\u6b65\u957f\u4f1a\u5bfc\u81f4\u7b56\u7565\u5267\u70c8\u53d8\u5316\uff0c\u7834\u574f\u5df2\u5b66\u5230\u7684\u597d\u7684\u884c\u4e3a</li> <li>\u8fc7\u5c0f\u7684\u6b65\u957f\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b</li> </ul> <p>\u5e38\u89c1\u7684\u6b65\u957f\u9009\u62e9\u65b9\u6cd5\u6709\u4e09\u79cd\uff1a\u56fa\u5b9a\u6b65\u957f\uff0c\u7ebf\u6027\u641c\u7d22\u548c\u4fe1\u8d56\u57df\uff0c\u4ee5\u4e0b\u662f\u4e09\u79cd\u65b9\u6cd5\u7684\u56fe\u793a\uff1a</p> \\[ \\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta J(\\theta)  \\] <p></p> <p>\u56fa\u5b9a\u6b65\u957f\u65b9\u6cd5\u662f\u6700\u4e3a\u6734\u7d20\u7684\u65b9\u6cd5\uff0c\u4f46\u662f\u6b65\u957f\u4f1a\u5f71\u54cd\u6536\u655b\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u5bf9\u5b9e\u9645\u95ee\u9898\u641c\u7d22\u5408\u7406\u6b65\u957f\u4f1a\u6bd4\u8f83\u9ebb\u70e6\uff1b\u7ebf\u6027\u641c\u7d22\u4f1a\u6cbf\u7740\u68af\u5ea6\u65b9\u5411\u5c1d\u8bd5\u591a\u4e2a\u6b65\u957f\uff0c\u5e76\u9009\u62e9\u6700\u4f18\u6b65\u957f\uff0c\u641c\u7d22\u5f00\u9500\u8f83\u5927\uff0c\u4f46\u6548\u679c\u6700\u597d\uff1b\u4fe1\u8d56\u57df\u65b9\u6cd5\u4f1a\u6839\u636e\u68af\u5ea6\u8ba1\u7b97\u81ea\u9002\u5e94\u4fe1\u8d56\u57df\uff0c\u5e76\u4fdd\u8bc1\u5728\u4fe1\u8d56\u57df\u5185\u66f4\u65b0\u3002\u4fe1\u8d56\u57df\u65b9\u6cd5\u4e00\u65b9\u9762\u80fd\u591f\u4fdd\u8bc1\u6bcf\u4e00\u6b65\u66f4\u65b0\u4e0d\u4f1a\u8ddd\u79bb\u539f\u7b56\u7565\u592a\u8fdc\uff0c\u53e6\u4e00\u65b9\u9762\u80fd\u591f\u5728\u68af\u5ea6\u566a\u58f0\u8fc7\u9ad8\u65f6\u81ea\u52a8\u7f29\u5c0f\u4fe1\u8d56\u57df\uff0c\u80fd\u591f\u6bd4\u8f83\u597d\u7684\u89e3\u51b3PG\u65b9\u6cd5\u68af\u5ea6\u566a\u58f0\u9ad8\u95ee\u9898\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#_1","title":"\u4f18\u52bf\u51fd\u6570","text":"<p>\u4e0a\u8fb9\u8ba8\u8bba\u7684\u6b65\u957f\u641c\u7d22\u7b97\u6cd5\u90fd\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u8981\u6c42\u76ee\u6807\u51fd\u6570\u5177\u5907\u51f8\u6027\uff0c\u800c\u5f3a\u5316\u5b66\u4e60\u7684\u76ee\u6807\u663e\u7136\u4e0d\u662f\u51f8\u51fd\u6570\u3002\u4e3a\u4e86\u89e3\u51b3\u76ee\u6807\u51fd\u6570\u51f8\u6027\u7684\u95ee\u9898\uff0cTRPO\u53c8\u5f15\u5165\u4e86 Minorize-Maximization\u601d\u60f3 \uff1a\u5bf9\u4e8e\u4e00\u4e2a\u96be\u4ee5\u4f18\u5316\uff0c\u96be\u4ee5\u6c42\u5bfc\u7684\u76ee\u6807\u51fd\u6570\uff0c\u53ef\u4ee5\u9009\u62e9\u4e00\u4e2a\u66ff\u4ee3\u51fd\u6570\u6765\u63cf\u8ff0\u76ee\u6807\u51fd\u6570\u7684\u4e0a\u5c4a\uff0c\u901a\u8fc7\u8fed\u4ee3\u6700\u5927\u5316\u8fd9\u4e2a\u4e0a\u5c4a\u66ff\u4ee3\u51fd\u6570\u53ef\u4ee5\u5b8c\u6210\u5bf9\u539f\u76ee\u6807\u51fd\u6570\u7684\u4f18\u5316\u3002</p> <p>\u4ec0\u4e48\u662f\u51f8\u6027</p> <p>\u51f8\u6027 \u662f\u4f18\u5316\u7406\u8bba\u4e2d\u6700\u4e3a\u91cd\u8981\u7684\u4e00\u4e2a\u6982\u5ff5\u3002\u82e5\u4e00\u4e2a\u51fd\u6570\u6ee1\u8db3\u4efb\u610f\u4eae\u70b9\\(x_1\\)\u4e0e\\(x_2\\)\uff0c\u6ee1\u8db3\uff1a $$ f(\\lambda x_1 +(1-\\lambda)x_2) \\le \\lambda f(x_1) + (1-\\lambda)f(x_2) $$ \u5219\u51fd\u6570\u5177\u6709\u51f8\u6027\u3002\u5177\u5907\u51f8\u6027\u7684\u51fd\u6570\u5c40\u90e8\u6700\u4f18\u7b49\u4ef7\u4e8e\u5168\u5c40\u6700\u4f18\uff0c\u56e0\u6b64\u57fa\u4e8e\u51f8\u6027\u6709\u4e00\u7cfb\u5217\u9ad8\u6548\u7684\u4f18\u5316\u7b97\u6cd5\u3002</p> <p>\u4e3a\u4e86\u6784\u9020\u8fd9\u4e2a\u66ff\u4ee3\u51fd\u6570\uff0c\u6211\u4eec\u5f15\u5165\u4e00\u4e2a\u4f18\u52bf\u51fd\u6570\u7684\u5b9a\u4e49\uff1a</p> \\[ A_\\pi(s,a) = Q_\\pi(s,a) - V_\\pi(s) \\] <p>\u8fd9\u4e2a\u51fd\u6570\u8868\u793a\u7b56\u7565\\(\\pi\\)\u91c7\u53d6\u52a8\u4f5c\\(a\\)\u65f6\u7684\u5956\u52b1\u6bd4\u5e73\u5747\u5956\u52b1\u9ad8\u591a\u5c11\u3002TRPO\u6700\u7ec8\u6c42\u89e3\u7684\u95ee\u9898\u5c31\u53d8\u6210 $$ \\begin{aligned} \\max_{\\theta} &amp; E[\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{old}}(a|s)} A_\\theta(s,a)] \\ \\textrm{s.t.} &amp;\u3000E[D_{KL}(\\pi_{\\theta_{old}}(a|s) \\pi_\\theta(a|s))] \\le \\delta \\end{aligned} $$</p> <p>\u5176\u4e2d\uff0c\\(\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{old}}(a|s)}\\)\u662f \u91cd\u8981\u6027\u91c7\u6837 \u3002\u7531\u4e8e\u8bad\u7ec3\u65f6\u53ea\u80fd\u4f7f\u7528\u65e7\u7b56\u7565\u4ea7\u51fa\u7684\u8f68\u8ff9\uff0c\u6211\u4eec\u9700\u8981\u901a\u8fc7\u91cd\u8981\u6027\u91c7\u6837\u5bf9\u76ee\u6807\u51fd\u6570\u4e2d\u7684\u671f\u671b\u8fdb\u884c\u4fee\u6b63\uff0c\u4f7f\u5176\u80fd\u591f\u53cd\u6620\u65b0\u7b56\u7565\u7684\u671f\u671b\u56de\u62a5\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#33-ppoproximal-policy-optimization","title":"3.3. \u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u7684\u6539\u8fdb\u2013PPO(Proximal Policy Optimization)","text":"<p>\u8fd1\u7aef\u4f18\u5316\uff08Proximal Optimization\uff09\u662f\u8fd9\u6837\u4e00\u79cd\u4f18\u5316\u65b9\u6cd5\uff1a\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u8fd1\u7aef\u7ea6\u675f\u9879\uff0c\u8ba9\u4f18\u5316\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\u6b65\u957f\u5c3d\u53ef\u80fd\u5c0f\uff0c\u907f\u514d\u56e0\u6743\u91cd\u5267\u70c8\u53d8\u5316\u800c\u5e26\u6765\u7684\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002Proximal OPtimization\u5728\u4f20\u7edf\u7684\u51f8\u4f18\u5316\u9886\u57df\u6709\u7740\u5e7f\u6cdb\u7684\u5e94\u7528\u3002 $$   \\theta^* = \\arg \\max_\\theta \\left(      f(\\theta) + \\lambda |\\theta - \\theta_t|_p   \\right) $$ \u5176\u4e2d\\(p \\in \\{1, 2\\}\\)\uff0c\u5e38\u89c1\u4f7f\u7528\\(L_1\\)\u6216\u8005\\(L_2\\)\u4f5c\u4e3a\u7ea6\u675f\u9879\u3002</p> <p>PPO\u901a\u8fc7clip\u64cd\u4f5c\u9650\u5236\u7b56\u7565\u7684\u66f4\u65b0\u5e45\u5ea6</p> <p>$$ J_{PPO}(\\theta) = \\mathbb{E} \\left[    \\min(     \\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{old}}(a|s)}A(s,a),     clip(\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{old}}(a|s)}, 1-\\epsilon,1+\\epsilon) A(s,a)     ) \\right] $$ \u5176\u4e2d\\(clip()\\)\u51fd\u6570\u4f1a\u5c06\\(\\frac{\\pi_\\theta(a|s)}{\\pi_{\\theta_{old}}(a|s)}\\)\u8fd9\u4e2a\u6bd4\u503c\u9650\u5236\u5728\\([1-\\epsilon,1+\\epsilon]\\)\u3002</p> <p>TRPO\u7b97\u6cd5\u5728\u8ba1\u7b97\u4fe1\u8d56\u57df\u65f6\u9700\u8981\u8ba1\u7b97Fisher\u4fe1\u606f\u77e9\u9635\uff0c\u5e76\u4f7f\u7528\u5171\u8f6d\u68af\u5ea6\u65b9\u6cd5\u6765\u66f4\u65b0\uff0c\u8ba1\u7b97\u91cf\u8f83\u5927\u3002\u800cPPO\u4ec5\u9700\u8981\u5bf9\u91cd\u8981\u6027\u91c7\u6837\u8fdb\u884c\u622a\u65ad\uff0c\u66f4\u52a0\u7684\u9ad8\u6548\u548c\u7a33\u5b9a\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#_2","title":"\u4f18\u52bf\u51fd\u6570\u7684\u4f30\u8ba1","text":"<p>\u5728\u8fdb\u884c\u4f18\u52bf\u51fd\u6570\uff08Advantage Function\uff09\u4f30\u8ba1\u7684\u65f6\u5019\uff0c\u901a\u5e38\u6709\u4e24\u79cd\u65b9\u6cd5\uff1a\u8499\u7279\u5361\u6269\u4f30\u8ba1\u4e0e\u65f6\u95f4\u5dee\u5206\u4f30\u8ba1\uff1a</p> <ol> <li>\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\uff1a\u901a\u8fc7\u5b8c\u6574\u56de\u62a5\u8fd1\u4f3c\\(Q(s,a)\\)\uff0c\u9700\u8981\u5b8c\u6574\u7684\u8f68\u8ff9\u624d\u80fd\u8ba1\u7b97\uff0c\u4e00\u822c\u7528\u4e8e\u79bb\u7ebf\u6570\u636e</li> </ol> \\[ A(s,a) = Q(s,a)-V(s) \\approx \\sum \\gamma^tr_{t} - V(s) \\] <ol> <li>\u65f6\u95f4\u5dee\u5206\u4f30\u8ba1\uff1a\u901a\u8fc7\u6298\u6263\u672a\u6765\u5956\u52b1\u6765\u8fd1\u4f3c\\(Q(s,a)\\)\uff0c\u53ef\u5b9e\u65f6\u66f4\u65b0</li> </ol> \\[ A(s,a) = Q(s,a) - V(s) \\approx r_t+\\gamma V(s_{t+1}) -V(s) \\] <p>\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u53ef\u4ee5\u7ed9\u51fa\u65e0\u504f\u4f30\u8ba1\uff0c\u4f46\u662f\u4f18\u52bf\u51fd\u6570\u7684\u65b9\u5dee\u8f83\u5927\uff0c\u800c\u65f6\u95f4\u5dee\u5206\u65b9\u5dee\u8f83\u5c0f\uff0c\u4f46\u8bef\u5dee\u504f\u5dee\u8f83\u5927\u3002\u4e3a\u4e86\u5e73\u8861\u4e24\u8005PPO\u5f15\u5165\u4e86GAE\uff08Generalized Advantage Estimation\uff09\uff1a</p> \\[ A_t^{GAE(\\gamma, \\lambda)} = \\sum_{l=0}^{T-t}(\\gamma \\lambda)^l\\delta_t +l \\] <p>\u5176\u4e2d\\(\\delta_t\\)\u662f\\(t\\)\u65f6\u523b\u7684TD\u6b8b\u5dee</p> \\[ \\delta_t = r_{t+1} + \\gamma V(s_{t+1}) - V(s_t) \\] <p>\u53c2\u6570\\(\\lambda\\)\u7528\u6765\u63a7\u5236\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u4e0e\u65f6\u95f4\u5dee\u5206\u4f30\u8ba1\u4e4b\u524d\u7684\u6743\u8861\uff1a</p> <ol> <li>\\(\\lambda\\) \u8d8a\u5927\u8d8a\u8d8b\u5411\u4e8e\u672a\u6765\u5956\u52b1\uff0c\u66f4\u503e\u5411\u4e8e\u8499\u7279\u5361\u7f57\u65b9\u6cd5\uff0c\u63d0\u4f9b\u9ad8\u65b9\u5dee\u4f4e\u504f\u5dee\u7684\u4f30\u8ba1\uff1b</li> <li>\\(\\lambda\\) \u8d8a\u5c0f\u8d8a\u8d8b\u5411\u4e8e\u5373\u65f6\u5956\u52b1\uff0c\u66f4\u52a0\u503e\u5411\u4e8e\u65f6\u95f4\u5dee\u5206\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4f4e\u65b9\u5dee\u4f46\u9ad8\u504f\u5dee\u7684\u4f30\u8ba1\uff1b</li> </ol>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#rlhf-with-ppo","title":"RLHF with PPO","text":"<p>RLHF\u5de7\u5999\u7684\u5728PPO\u6846\u67b6\u4e0b\u5f15\u5165\u4e86\u4eba\u7c7b\u53cd\u9988\uff08Human Feedback\uff09\uff0c\u6574\u4e2a\u6846\u67b6\u5171\u6d89\u53ca4\u4e2a\u6a21\u578b\uff1a</p> <ul> <li>Actor Model\uff1a \u6f14\u5458\u6a21\u578b\uff0c\u5c31\u662f\u9700\u8981\u5bf9\u9f50\u7684LLM\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u4f9b\u7b56\u7565\\(\\pi(a|s)\\)\uff1b</li> <li>Critic Model\uff1a \u8bc4\u8bba\u5bb6\u6a21\u578b\uff0c\u7528\u4e8e\u4f30\u8ba1\u603b\u6536\u76ca \\(V_t\\)\uff1b</li> <li>Reward Model\uff1a \u5956\u52b1\u6a21\u578b\uff0c\u7528\u4e8e\u4f30\u8ba1\u8ba1\u7b97\u5373\u65f6\u6536\u76ca \\(R_t\\)\uff1b</li> <li>Reference Model\uff1a \u53c2\u8003\u6a21\u578b\uff0c\u7528\u4e8e\u63d0\u4f9b\u8bad\u7ec3\u9636\u6bb5\u7684\u7ea6\u675f\uff0c\u9632\u6b62\u6a21\u578b\u8bad\u6b6a\uff08\u7528\u4e8e\u8ba1\u7b97KL\u6563\u5ea6\uff09\uff1b</li> </ul> <p>\u8bad\u7ec3\u65f6\uff0cRM\u6a21\u578b\u9700\u8981\u72ec\u7acb\u8bad\u7ec3\uff0c\u800cActor Model\u4e0eCritic Model\u5219\u662f\u5728PPO\u7684\u8fc7\u7a0b\u4e2d\u4e00\u8d77\u8bad\u7ec3\u3002\u5982\u679c\u4e24\u8005\u5171\u4eab\u53c2\u6570\uff0c\u4f46\u662f\u4f7f\u7528\u4e0d\u540c\u7684head\uff0c\u6211\u4eec\u4e5f\u79f0Actor Model\u4e3a\u7b56\u7565\u7f51\u7edc\uff0cCritic Model\u4e3a\u503c\u7f51\u7edc\u3002</p> <p>RLHF\u7684\u8fc7\u7a0b\u76f8\u5f53\u7e41\u7410\uff0c\u5e76\u4e14\u8bad\u7ec3\u8fc7\u7a0b\u4e5f\u5e76\u4e0d\u975e\u5e38\u7a33\u5b9a\uff0c\u56e0\u6b64LLaMa\u7cfb\u5217\u6a21\u578b\u5728\u5f00\u59cb\u7684\u65f6\u5019\u4ec5\u4f7f\u7528\u4e86SFT\uff0c\u4f46\u662f\u5728LLaMa2\u65f6\u53c8\u91cd\u65b0\u5f15\u5165\u4e86RL\u8fdb\u884c\u504f\u597d\u5bf9\u9f50\uff0c\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#34-grpogroup-relative-policy-optimization","title":"3.4. \u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\u7684\u6539\u8fdb\u2013GRPO\uff08Group Relative Policy Optimization\uff09","text":"<p>PPO\u7b97\u6cd5\u4e2d\u7684\u503c\u51fd\u6570\u53ea\u5bf9\u6700\u540e\u4e00\u4e2atoken\u8bc4\u4f30\uff0c\u590d\u6742\u5e76\u4e14\u5f15\u5165\u989d\u5916\u7684\u4e0d\u786e\u5b9a\u6027\u3002GRPO\u80fd\u591f\u907f\u514d\u503c\u51fd\u6570\u4f30\u8ba1\uff0c\u4f7f\u5f97\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u66f4\u52a0\u7b80\u5355\uff0c\u5177\u4f53\u6765\u8bf4\uff1a</p> \\[ J_{GRPO}(\\theta) = \\frac{1}{G} \\sum_{i=1}^G\\frac{1}{|o_i|} \\sum_{t=1}^{o_i} \\{  \\min \\left [  \\frac{\\pi_\\theta}{\\pi_{\\theta_{old}}} \\hat{A}_{i,t}  clip\\left(    \\frac{\\pi_\\theta}{\\pi_{\\theta_{old}}},    1-\\epsilon,    1+\\epsilon \\right) \\hat{A}_{i,t} \\right ] -\\beta \\mathbb{D}_{KL}[\\pi_\\theta \\| \\pi_{\\theta_{old}}] \\} \\] <p>\u5bf9\u4e8e\u6bcf\u4e2a\u95ee\u9898\\(q\\)\uff0c\u751f\u6210\\(G\\)\u4e2a\u56de\u7b54\\(o_i, i\\in[1..G]\\)\uff0c\u6bcf\u4e2a\u7b54\u6848\u7684\u957f\u5ea6\u4e3a\\(|o_i|\\)\u3002</p> <p>GRPO\u5f15\u5165\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u4f18\u52bf\u51fd\u6570\u5b9a\u4e49\uff1a</p> \\[ \\hat{A}_{i,t} = \\frac{r_i - mean(r)}{std(r)} \\] <p>\u5373\u7b2c\\(i\\)\u4e2a\u8f93\u51fa\u7684\u5956\u52b1\\(r_i\\)\uff0c\u76f8\u5bf9\u6574\u4e2aGroup\u7684\u4f18\u52bf\uff0c\u8be5\u5f0f\u4e0eBatch Normal\u6781\u4e3a\u7c7b\u4f3c\u3002\u8ba1\u7b97\u8fd9\u4e2a\u4f18\u52bf\u51fd\u6570\u53ea\u9700\u8981\u8ba1\u7b97\u6bcf\u4e2a\u8f93\u51fa\u7684\u5956\u52b1\u5373\u53ef\uff0c\u65e0\u9700\u518d\u4f30\u8ba1\u503c\u51fd\u6570\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#deepseek-r1","title":"DeepSeek R1","text":"<p>\u5956\u52b1\u662fGRPO\u6574\u4e2a\u8bad\u7ec3\u7684\u4fe1\u53f7\u6765\u6e90\uff0cDeepSeek R1\u5728\u8bad\u7ec3\u4e2d\u4e3b\u8981\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u3002\u4e00\u65b9\u9762\u57fa\u4e8e\u89c4\u5219\u7684\u5956\u52b1\u80fd\u591f\u8282\u7ea6\u8bad\u7ec3\u8d44\u6e90\uff0c\u53e6\u4e00\u65b9\u9762\u4e5f\u80fd\u907f\u514dReward Hacking\u95ee\u9898\u3002</p> <p>\u4ec0\u4e48\u662fReward Hacking</p> <p>Reward Hacking\u662f\u6307\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u65f6\uff0cAgent\u901a\u8fc7\u4e0d\u7b26\u5408\u9884\u671f\u7684\u65b9\u5f0f\uff0c\u5229\u7528\u5956\u52b1\u51fd\u6570\u7684\u6f0f\u6d1e\u6765\u6700\u5927\u5316\u5176\u5956\u52b1\uff0c\u4ece\u800c\u7834\u89e3\u8bad\u7ec3\u8fc7\u7a0b\u3002\u4ea7\u751fReward Hacking\u7684\u4e3b\u8981\u539f\u56e0\u5728\u4e8e\u5956\u52b1\u51fd\u6570\u672c\u8eab\u4e0d\u5b8c\u7f8e\uff0c\u7279\u522b\u662f\u4e00\u4e9b\u57fa\u4e8e\u89c4\u5219\u8bbe\u8ba1\u7684\u590d\u6742\u5956\u52b1\u51fd\u6570\uff0c\u5728\u4e0d\u9650\u5b9a\u53ef\u884c\u57df\u7684\u65f6\u5019\uff0c\u7ecf\u5e38\u4f1a\u5bfc\u81f4Agent\u5c1d\u8bd5\u9003\u9038\u5230\u975e\u53ef\u884c\u57df\uff0c\u4ece\u800c\u83b7\u5f97\u8d85\u989d\u5956\u52b1\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#deepseek-r1-zero","title":"DeepSeek R1-Zero","text":"<p>DeepSeek R1-Zero\u662f\u7eaf\u7cb9\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u4e3b\u8981\u91c7\u7528\u4e86\u4e24\u79cd\u89c4\u5219\u5956\u52b1\uff1a</p> <ul> <li> <p>Accuracy Rewards\uff1a\u4e3b\u8981\u540c\u5f52\u89c4\u5219\uff0c\u6bd4\u5982\u6587\u672c\u5339\u914d\u548c\u6b63\u5219\u8868\u8fbe\u5f0f\u6765\u7ed9\u51fa\u5956\u52b1\uff0c\u9488\u5bf9LeetCode\u751a\u81f3\u4f1a\u4f7f\u7528compiler\u4f5c\u4e3a\u5956\u52b1\u53cd\u9988\u7684\u6765\u6e90\uff1b</p> </li> <li> <p>Format Rewards\uff1a\u5956\u52b1\u6a21\u578b\u5c06\u601d\u8003\u8fc7\u7a0b\u653e\u5165<code>&lt;think&gt;...&lt;/think&gt;</code>\u6807\u7b7e\u4e2d\uff1b</p> </li> </ul> <p>\u5728\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4f7f\u7528\u4e86\u5982\u4e0b\u7684\u6a21\u677f\uff1a</p> <pre><code>A conversation between User and Assistant. The user asks a question, and the Assistant solves it.\nThe assistant first thinks about the reasoning process in the mind and then provides the user\nwith the answer. The reasoning process and answer are enclosed within &lt;think&gt; &lt;/think&gt; and\n&lt;answer&gt; &lt;/answer&gt; tags, respectively, i.e., &lt;think&gt; reasoning process here &lt;/think&gt;\n&lt;answer&gt; answer here &lt;/answer&gt;. User: prompt. Assistant:\n</code></pre> <p>\u5728R1-Zero\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u770b\u5230\u6a21\u578b\u5728Reasoning Task\u4e0a\u6301\u7eed\u7a33\u5b9a\u5219\u6027\u80fd\u6539\u5584\u3002\u5e76\u4e14\u89c2\u6d4b\u5230\u4e86Aha-Moment\u3002</p> <p>Aha Moment</p> <p>Aha Moment\u662f\u6307\u67d0\u4e2a\u4eba\u7a81\u7136\u7406\u89e3\u6216\u8005\u9886\u609f\u67d0\u4e2a\u6982\u5ff5\u3001\u95ee\u9898\u6216\u8005\u60f3\u6cd5\u7684\u77ac\u95f4\uff0c\u4e2d\u6587\u53ef\u4ee5\u79f0\u4f5c\u201c\u987f\u609f\u201d\u65f6\u523b\uff0c\u4f7f\u5f97\u5bf9\u67d0\u4e2a\u95ee\u9898\u7684\u89e3\u51b3\u6709\u4e00\u4e2a\u98de\u8dc3\u3002</p> <p></p> <p>\u867d\u7136R1-Zero\u8868\u73b0\u51fa\u4e86\u5f88\u8f7b\u7684Reasoning\u80fd\u529b\uff0c\u4f46\u5176\u8f93\u51fa\u7684\u53ef\u8bfb\u6027\u8f83\u5dee\uff0c\u5e76\u4e14\u4f1a\u4e2d\u82f1\u6587\u3002\u4e3a\u4e86\u8ba9\u6a21\u578b\u7684\u4f53\u73b0\u66f4\u597d\uff0c\u53c8\u5f00\u53d1\u4e86R1\uff0c\u52a0\u5165human-friendly\u7684\u51b7\u542f\u52a8\u6570\u636e\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#deepseek-r1_1","title":"DeepSeek R1","text":"","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#cold-start","title":"Cold Start","text":"<p>\u4f7f\u7528\u6570\u5343\u6761\u957fCoT\u6570\u636e\u5bf9\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff1a</p> <ul> <li>\u6570\u636e\u53ef\u8bfb\u6027\uff1a\u4e3b\u8981\u89e3\u51b3\u591a\u8bed\u8a00\u6df7\u5408\u95ee\u9898\u4e0eMarkdown\u683c\u5f0f\u7f3a\u5931\u95ee\u9898\uff1b</li> <li>\u6f5c\u529b\uff1a\u57fa\u4e8e\u4eba\u5de5\u5148\u9a8c\u8bbe\u8ba1\u6570\u636e\uff1b</li> </ul>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#reasoning-rl","title":"Reasoning RL","text":"<p>\u4f7f\u7528RL\u63d0\u5347\u6a21\u578b\u7684Reasoning\u80fd\u529b\uff0c\u4e3a\u4e86\u907f\u514d\u591a\u8bed\u8a00\u6df7\u5408\uff0c\u5f15\u5165\u4e86\u60e9\u7f5a\u9879\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#sft","title":"\u62d2\u7edd\u91c7\u6837\u4e0eSFT","text":"<p>\u4e3b\u8981\u4e3a\u4e86\u63d0\u5347Reasoning\u4ee5\u5916\u7684\u80fd\u529b\uff0c\u6bd4\u5982\u5199\u4f5c\u548c\u5bf9\u8bdd\uff0c\u901a\u8fc7SFT\u6765\u5b9e\u73b0\u3002\u6570\u636e\u4e3b\u8981\u5305\u542b\uff1a</p> <ul> <li>Reasoning\u6570\u636e\uff1a\u4f7f\u7528\u751f\u6210\u5f0fReward\u51fd\u6570\uff0c\u5c06ground truth\u548c\u6a21\u578b\u8f93\u51fa\u540c\u65f6\u8f93\u5165\u7ed9base\u6a21\u578b\u8fdb\u884c\u5224\u65ad\uff1b\u4ee5\u6b64\u79cd\u65b9\u5f0f\u6536\u96c660W\u8bad\u7ec3\u6570\u636e\uff1b</li> <li>Non-Reasong\u6570\u636e\uff1a\u4f7f\u7528prompt\u8ba9\u6a21\u578b\u4e3awriting\u3001QA\u7b49\u4efb\u52a1\u6dfb\u52a0CoT\uff0c\u5e76\u6536\u96c620W\u8f93\u51fa\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\uff1b</li> </ul>","tags":["LLM","Training","RL"]},{"location":"2025/02/09/rl_ds_r1/#rl-for-all-scenarios","title":"RL for all scenarios","text":"<p>\u518d\u6b21\u901a\u8fc7RL\u63d0\u5347\u6a21\u578b\u7684helpness\u548charmlessness\u3002</p>","tags":["LLM","Training","RL"]},{"location":"2025/02/12/fp8_training/","title":"\u4eceDeepSeek V3\u770bFP8\u8bad\u7ec3\u7684\u6311\u6218","text":"<p>\u81ea Nvidia 2022 \u5e74\u53d1\u5e03 H100 GPU \u96c6\u6210 FP8 \u652f\u6301\u4ee5\u6765\uff0c\u8be5\u683c\u5f0f\u4f5c\u4e3a\u9996\u4e2a\u9762\u5411\u8bad\u7ec3\u573a\u666f\u8bbe\u8ba1\u7684 8 \u4f4d\u6d6e\u70b9\u89c4\u8303\uff0c\u66fe\u88ab\u5bc4\u671b\u5ef6\u7eed TF32 \u5728\u63a8\u7406\u52a0\u901f\u548c BF16 \u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u4e0a\u7684\u6210\u529f\uff0c\u5ef6\u7eed Huang\u2019s Law\u3002\u786c\u4ef6\u5c42\u9762 2 \u500d\u4e8e FP16 \u7684\u7406\u8bba\u7b97\u529b\u63d0\u5347\uff0c\u4f7f\u5176\u88ab\u89c6\u4e3a\u7a81\u7834\u5927\u6a21\u578b\u7b97\u529b\u5899\u7684\u5173\u952e\u8def\u5f84\uff1a\u4e0d\u4ec5\u80fd\u51cf\u5c11\u8ba1\u7b97\u548c\u5b58\u50a8\u7684\u5f00\u9500\uff0c\u8fd8\u80fd\u5927\u5e45\u63d0\u5347\u8bad\u7ec3\u901f\u5ea6\u3002\u4f46\u662f\uff0c\u53e4\u5c14\u4e39\uff0c\u4ee3\u4ef7\u662f\u4ec0\u4e48\u5462\uff1f</p> <p>FP8 \u7aef\u5230\u7aef\u7684\u6027\u80fd\u63d0\u5347\u53ea\u6709 30%\uff0c\u8ddd\u79bb\u7406\u8bba\u503c 100%\u76f8\u53bb\u751a\u8fdc\uff1b\u4f7f\u7528 FP8 \u9700\u8981\u9762\u4e34\u7cbe\u5ea6\u98ce\u9669\uff0c\u5f88\u591a\u5b9e\u9a8c\u53d1\u73b0\u4e0d\u5c0f\u4e8e 2%\u7684 loss diff\uff1b\u9700\u8981\u4fee\u6539\u8bad\u7ec3\u6846\u67b6\uff0c\u7cbe\u5de7\u7684\u5ef6\u8fdf\u7f29\u653e\u7b56\u7565\uff0c\u9700\u8981\u6846\u67b6\u5c42\u9762\u5f15\u5165\u9664\u4e86\u540c\u6b65\u3001\u5f02\u6b65\u4ee5\u5916\u7684\u7b2c\u4e09\u79cd\u65f6\u5e8f\uff1b\u9700\u8981\u5728\u4ee3\u7801\u91cc\u589e\u52a0\u4e24\u79cd\u5168\u65b0\u7684\u6570\u503c\u683c\u5f0f\uff0cE4M3 \u548c E5M2\uff1b\u9700\u8981\u4ed8\u51fa\u989d\u5916\u7684\u663e\u5b58\uff0cTransformerEngine \u5b98\u65b9\u6587\u6863\u63d0\u5230\uff0c\u663e\u5b58\u5f00\u9500\u9700\u8981\u589e\u52a0 5%\u3002\u4ee3\u4ef7\u5c31\u662f\u8fd9\u4e00\u5207\u3002</p> <p>\u8fd9\u5c31\u5bfc\u81f4\u4e86 LLM \u5382\u5546\u4ecd\u7136\u4ee5 BF16 \u4e3a\u4e3b\uff0c\u9c9c\u6709\u5728\u751f\u4ea7\u6a21\u578b\u4e0a\u5c1d\u8bd5 FP8 \u8bad\u7ec3\u8005\u3002\u800c DeepSeek V3 \u521b\u65b0\u6027\u7684\u5f15\u5165\u4e86\u5757\u7c92\u5ea6\u91cf\u5316\u7b56\u7565\uff0c\u6210\u4e3a\u4e86\u6548\u679c\u80fd\u591f\u6bd4\u80a9 GPT4 \u7684\u6a21\u578b\u4e2d\u7b2c\u4e00\u4e2a\u8dd1\u901a\u4e86 FP8 \u8bad\u7ec3\u7684\u573a\u4e0a\uff0c\u7aef\u5230\u7aef\u8bad\u7ec3\u6210\u672c\u53ea\u6709 GPT4 \u7684 1/10\u3002\u4e5f\u8ba9 FP8 \u8bad\u7ec3\u91cd\u65b0\u5f15\u8d77\u5e7f\u6cdb\u5173\u6ce8\u3002\u672c\u6587\u5c1d\u8bd5\u5206\u6790 DeepSeek V3 \u7684 FP8 \u8bad\u7ec3\u65b9\u6848\u80cc\u540e\u6240\u9762\u4e34\u7684\u7cbe\u5ea6\u6311\u6218\u4e0e\u5e94\u5bf9\u65b9\u6cd5\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#1-fp8","title":"1. FP8 \u6d6e\u70b9\u683c\u5f0f\u4ecb\u7ecd","text":"","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#11-ieee-754","title":"1.1. IEEE 754 \u6807\u51c6\u4e0e\u6d6e\u70b9\u6570","text":"<p>IEEE 754 \u662f\u76ee\u524d\u5e7f\u4e3a\u4f7f\u7528\u7684\u6d6e\u70b9\u6570\u89c4\u8303\uff0c\u5b9a\u4e49\u4e86\u6d6e\u70b9\u6570\u7684 bitwise \u8868\u8fbe\u4e0e\u91cf\u5316\u65b9\u5f0f\u3002\u6d6e\u70b9\u6570\u7684\u4e8c\u8fdb\u5236\u8868\u8fbe\u5206\u4e3a\u4e09\u90e8\u5206\uff1a</p> <ul> <li>\u7b26\u53f7\u4f4d\uff08sign\uff09</li> <li>\u6307\u6570\u4f4d\uff08exponent\uff09</li> <li>\u5c3e\u6570\u4f4d\uff08mantissa\uff09</li> </ul> <pre><code>block-beta\n    columns 33\n    FP32[\"fp32\"]\n    S1[\"S\"]\n    E1[\"E\"]\n    E2[\"E\"]\n    E3[\"E\"]\n    E4[\"E\"]\n    E5[\"E\"]\n    E6[\"E\"]\n    E7[\"E\"]\n    E8[\"E\"]\n    M1[\"M\"]\n    M2[\"M\"]\n    M3[\"M\"]\n    M4[\"M\"]\n    M5[\"M\"]\n    M6[\"M\"]\n    M7[\"M\"]\n    M8[\"M\"]\n    M9[\"M\"]\n    M10[\"M\"]\n    M11[\"M\"]\n    M12[\"M\"]\n    M13[\"M\"]\n    M14[\"M\"]\n    M15[\"M\"]\n    M16[\"M\"]\n    M17[\"M\"]\n    M18[\"M\"]\n    M19[\"M\"]\n    M20[\"M\"]\n    M21[\"M\"]\n    M22[\"M\"]\n    M23[\"M\"]\n\n    BF16[\"bf16\"]\n    SS1[\"S\"]\n    EE1[\"E\"]\n    EE2[\"E\"]\n    EE3[\"E\"]\n    EE4[\"E\"]\n    EE5[\"E\"]\n    EE6[\"E\"]\n    EE7[\"E\"]\n    EE8[\"E\"]\n    MM1[\"M\"]\n    MM2[\"M\"]\n    MM3[\"M\"]\n    MM4[\"M\"]\n    MM5[\"M\"]\n    MM6[\"M\"]\n    MM7[\"M\"]\n    space:16\n\n    FP16[\"fp16\"]\n    space:3\n    ss1[\"S\"]\n    ee1[\"E\"]\n    ee2[\"E\"]\n    ee3[\"E\"]\n    ee4[\"E\"]\n    ee5[\"E\"]\n    mm1[\"M\"]\n    mm2[\"M\"]\n    mm3[\"M\"]\n    mm4[\"M\"]\n    mm5[\"M\"]\n    mm6[\"M\"]\n    mm7[\"M\"]\n    mm8[\"M\"]\n    mm9[\"M\"]\n    mm10[\"M\"]\n    space:13\n\n    E5M2[\"fp8\"]\n    space:3\n    s1[\"S\"]\n    e1[\"E\"]\n    e2[\"E\"]\n    e3[\"E\"]\n    e4[\"E\"]\n    e5[\"E\"]\n    m1[\"M\"]\n    m2[\"M\"]\n    space:21\n\n    E4M3[\"fp8\"]\n    space:4\n    sss1[\"S\"]\n    eee1[\"E\"]\n    eee2[\"E\"]\n    eee3[\"E\"]\n    eee4[\"E\"]\n    mmm1[\"M\"]\n    mmm2[\"M\"]\n    mmm3[\"M\"]\n    space:21\n\n    classDef name fill:#00000000, stroke:#00000000\n    class FP32,BF16,FP16,E4M3,E5M2 name\n\n    classDef sign fill:#EE0000, stroke:#00000000\n    class S1,SS1,s1,ss1,sss1 sign\n\n    classDef exp fill:#00EE00, stroke:#00000000\n    class E1,E2,E3,E4,E5,E6,E7,E8 exp\n    class EE1,EE2,EE3,EE4,EE5,EE6,EE7,EE8 exp\n    class e1,e2,e3,e4,e5,e6,e7,e8 exp\n    class ee1,ee2,ee3,ee4,ee5,ee6,ee7,ee8 exp\n    class eee1,eee2,eee3,eee4,eee5,eee6,eee7,eee8 exp</code></pre>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#12-fp8","title":"1.2. FP8 \u7684\u4e24\u79cd\u683c\u5f0f","text":"<p>\u5f53\u4ece 16 \u4f4d\u8fdb\u4e00\u6b65\u964d\u4f4e\u6d6e\u70b9\u6570\u4f4d\u6570\u65f6\uff0c\u4f1a\u9762\u4e34\u52a8\u6001\u8303\u56f4\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u56e0\u6b64 Nvidia\u3001Arm \u548c Intel \u5728\u5176\u63d0\u51fa\u7684 FP8 \u89c4\u8303\u4e2d\u8bbe\u8ba1\u4e86\u4e24\u79cd\u6d6e\u70b9\u6570\u7c7b\u578b<sup>1</sup>\uff1aE4M3 \u548c E5M2</p> E4M3 E5M2 format(s/e/m) 1:4:3 1:5:2 Exponent bias 7 15 Infinities N/A S.11111.00 NaN S.1111.111 S.11111.{01,10,11} Zeros S.0000.000 S.00000.00 Max normal S.1111.110 = \\(1.75 \\times 2^8\\) = 448 S.11110.11 = \\(1.75 \\times 2^15\\) = 57.344 Min normal S.0001.0000 = \\(2^{-6}\\) S.00001.00 = \\(2^{-14}\\) Max subnorm S.0000.111 = \\(0.875 \\times 2^{-6}\\) S.00000.11 = \\(0.75\\times 2^{-14}\\) Min subnorm S.0000.001 = \\(2^{-9}\\) S.00000.01 = $ 2^{-16}$ <p>\u82e5\u4e25\u683c\u9075\u5faa IEEE 754 \u89c4\u8303\uff0cE4M3 \u4f1a\u6d6a\u8d39 8 \u4e2a\u4e8c\u8fdb\u5236\u8868\u8fbe\u5728 Inf \u4e0e NaN \u4e0a\u3002\u56e0\u6b64\u5728\u5b9a\u4e49 E4M3 \u89c4\u8303\u65f6\u5bf9\u8fd9\u4e9b\u4e8c\u8fdb\u5236\u8868\u8fbe\u8fdb\u884c\u4e86\u989d\u5916\u5f00\u53d1\uff0c\u4ec5\u5728\u6307\u6570\u4f4d\u5c3e\u6570\u4f4d\u540c\u65f6\u5168\u4e3a 1 \u65f6\u624d\u8868\u793a NaN\u3002</p> <p></p> <p>H100 \u63d0\u4f9b 3 \u500d A100 FP16 \u6027\u80fd\uff0c\u82e5\u542f\u7528 FP8 \u7b97\u529b\u80fd\u591f\u518d\u6b21\u7ffb\u500d\u3002\u6839\u636e Nvidia \u5b98\u65b9\u7684\u4ecb\u7ecd\uff1a</p> <ol> <li>Nvidia \u901a\u8fc7 Transformer Engine \u63d0\u4f9b\u81ea\u52a8 FP8 \u8f6c\u6362\uff0c\u7528\u6237\u53ef\u65e0\u7f1d\u5207\u6362\u5230 FP8\uff1b</li> <li>\u5df2\u7ecf\u4f7f\u7528 BF16 \u8bad\u7ec3\u7684\u4efb\u52a1\uff0c\u53ef\u4ee5\u4f7f\u7528 FP8 \u7ee7\u7eed\u8bad\u7ec3\uff1b</li> <li>\u901a\u8fc7\u5f15\u5165 delayed scaling \u7b56\u7565\uff0c\u81ea\u52a8\u5bf9 FP8 \u7684 tensor \u8fdb\u884c\u7f29\u653e\uff1b</li> </ol> <p>\u4f46\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\uff0cTransformerEngine \u7684 FP8 \u65b9\u6848\u5728\u7cbe\u5ea6\u4e0a\u4ecd\u4f1a\u4e0e BF16 \u5b58\u5728\u5dee\u5f02\uff0c\u56e0\u6b64\u5404\u5927\u516c\u53f8\u548c\u7ec4\u7ec7\u4ecd\u7136\u4f18\u5148\u9009\u62e9 BF16\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#2-transformer-engine-fp8","title":"2. Transformer Engine \u7684 FP8 \u65b9\u6848","text":"<p>Transformer Engine \u662f Nvidia \u4e3a FP8 \u8bad\u7ec3\u5f00\u53d1\u7684 Transformer \u52a0\u901f\u5e93\uff0c\u63d0\u4f9b\u4ece<code>Linear</code>\u3001<code>Attention</code>\u5230<code>LayerNorm</code>\u7b49\u57fa\u7840\u7ec4\u4ef6\u7684 FP8 \u5b9e\u73b0\u3002\u4e0b\u56fe\u662f\u652f\u6301 FP8 \u7684\u4e00\u4e2a\u8bf4\u660e\u56fe\u793a\uff1a</p> <p></p> <p>\u6743\u91cd\u548c\u68af\u5ea6\u5747\u4f7f\u7528\u9ad8\u7cbe\u5ea6\u5b58\u50a8\uff0c\u4ec5\u77e9\u9635\u4e58\u4f7f\u7528 FP8 \u8fdb\u884c\u8fd0\u7b97\uff0c\u6765\u63d0\u5347\u7b97\u529b\u3002\u5728\u77e9\u9635\u4e58\u4e4b\u524d\u901a\u8fc7 cast \u64cd\u4f5c\u5c06\u9ad8\u7cbe\u5ea6\u7684\u6743\u91cd\u548c\u6fc0\u6d3b\u8f6c\u6362\u4e3a FP8\u3002\u77e9\u9635\u4e58\u7684\u8f93\u51fa\u4ecd\u4e3a\u9ad8\u7cbe\u5ea6\uff0c\u4e0d\u5f71\u54cd bias \u64cd\u4f5c\u4e0e\u6fc0\u6d3b\u64cd\u4f5c\u3002</p> <p>TransformerEngine \u5728 BF16 \u7cbe\u5ea6\u4e0b\uff0c\u80fd\u591f\u964d\u4f4e\u663e\u5b58\u4f7f\u7528\uff0c\u82e5\u542f\u7528 FP8 \u8bad\u7ec3\uff0c\u80fd\u591f\u63d0\u901f 30%\uff0c\u4f46\u65e0\u6cd5\u5e26\u6765\u989d\u5916\u7684\u663e\u5b58\u8282\u7ea6\uff0c\u53cd\u800c\u4f1a\u56e0\u4e3a checkpoint \u4e2d\u5b58\u50a8\u989d\u5916\u7684 scaling \u503c\uff0c\u5bfc\u81f4\u66f4\u591a 5%\u7684\u663e\u5b58\u5360\u7528\u3002</p> <p>TE \u7684 FP8 \u65b9\u6848\u8bc4\u4ef7: FP \u6709\u4e09\u90e8\u5206\u7406\u8bba\u6536\u76ca\uff1a</p> <ol> <li>\u8ba1\u7b97\u6027\u80fd\u7ffb\u500d\uff1b</li> <li>\u663e\u5b58\u5f00\u9500\u51cf\u534a\uff1b</li> <li>\u901a\u4fe1\u541e\u5410\u51cf\u534a\uff1b</li> </ol> <p>TE \u6240\u4f7f\u7528\u7684 FP8 \u65b9\u6848\u5b9e\u9645\u4e0a\u53ea\u62ff\u5230\u4e86 30%\u7684\u8ba1\u7b97\u6027\u80fd\u6536\u76ca\uff0c\u4ecd\u6709\u5de8\u5927\u7684\u4f18\u5316\u6539\u8fdb\u7a7a\u95f4\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#3-deepseek-v3-fp8","title":"3. DeepSeek V3 \u7684 FP8 \u65b9\u6848","text":"<p>\u4e0e TransformerEngine \u7684\u4e3b\u8981\u4e0d\u540c\uff1a</p> <ol> <li>weight \u4f7f\u7528 FP8 \u5b58\u50a8\uff1b</li> <li>\u5168\u90e8\u4f7f\u7528 E4M3 \u6d6e\u70b9\u683c\u5f0f\uff1b</li> <li>\u4f7f\u7528 block-wise scaling\uff0c\u800c\u4e0d\u662f pre-tensor scaling\uff1b</li> </ol> <p>master weight\u3001\u6743\u91cd\u68af\u5ea6\u4f7f\u7528 FP32,\u6fc0\u6d3b\u68af\u5ea6\u3001\u4f18\u5316\u5668\u72b6\u6001\u4f7f\u7528 BF16\u3002\u8fd9\u4e9b\u9ad8\u7cbe\u5ea6\u6570\u636e\u4f1a\u88ab\u5207\u5206\u5230\u4e0d\u540c\u7684 DP rank \u4e0a\uff0c\u56e0\u6b64\u5bf9\u6574\u4f53\u663e\u5b58\u5f00\u9500\u5f71\u54cd\u53ef\u4ee5\u63a7\u5236\u5f97\u6bd4\u8f83\u597d\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#31","title":"3.1. \u964d\u4f4e\u663e\u5b58\u5f00\u9500\u4e0e\u901a\u4fe1\u5f00\u9500","text":"<ul> <li>\u4f4e\u7cbe\u5ea6\u4f18\u5316\u5668\u72b6\u6001\uff1a AdamW \u4f18\u5316\u5668\u7684\u4e00\u9636\u52a8\u91cf\u4e0e\u4e8c\u9636\u52a8\u91cf\u4f7f\u7528 BF16 \u5b58\u50a8\u6765\u964d\u4f4e\u663e\u5b58\u538b\u529b\uff0c\u4f46\u662f master weight \u4e0e main grad \u4ecd\u7136\u4f7f\u7528 FP32 \u5b58\u50a8;</li> <li>\u4f4e\u7cbe\u5ea6\u6fc0\u6d3b\u503c\uff1a \u9488\u5bf9\u4e0d\u540c\u7684\u6fc0\u6d3b\u503c\u4f7f\u7528\u4e86\u4e0d\u540c\u7684\u7cbe\u5ea6</li> <li>Attention \u4e4b\u540e\u7684 Linear \u5c42\uff0c\u7531\u4e8e attention \u7684\u68af\u5ea6\u8ba1\u7b97\u5bf9\u7cbe\u5ea6\u654f\u611f\uff0c\u8fd9\u4e9b\u6fc0\u6d3b\u4f7f\u7528\u4e86 E5M6 \u6570\u636e\u7c7b\u578b\u3002\u5e76\u4e14\u4e3a\u4e86\u907f\u514d\u5f15\u5165\u989d\u5916\u7684\u91cf\u5316\u8bef\u5dee\uff0c\u4f1a\u4f7f\u7528\u5e42\u6b21\u7f29\u653e\u56e0\u5b50\uff1b</li> <li>MoE \u4e2d SwiGLU \u7684\u8f93\u5165\uff1a \u5f15\u5165 recompute \u7b56\u7565\uff0c\u4f7f\u7528 FP8 \u683c\u5f0f\u7f13\u5b58\u8f93\u5165\uff1b</li> <li>\u4f4e\u7cbe\u5ea6\u901a\u4fe1\uff1aMoE \u7684\u901a\u4fe1\u662f\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6700\u4e3b\u8981\u7684\u74f6\u9888\u4e4b\u4e00\u3002\u4e3a\u4e86\u964d\u4f4e\u8fd9\u90e8\u5206\u5f00\u9500\uff0c\u5c06 MoE \u524d\u5411 up-projection \u64cd\u4f5c\u4e0e\u53cd\u5411\u7684 down-projection \u64cd\u4f5c\u524d\u7684\u6fc0\u6d3b/\u6fc0\u6d3b\u68af\u5ea6\u8fdb\u884c FP8 \u91cf\u5316\uff0c\u4e4b\u540e\u518d\u8fdb\u884c dispatch \u903b\u8f91\uff0c\u91cf\u5316\u8fc7\u7a0b\u4f7f\u7528\u5e42\u6b21\u7f29\u653e\u56e0\u5b50\u3002\u5bf9\u4e8e combine \u6a21\u5757\uff0c\u4f7f\u7528 BF16 \u6765\u4fdd\u8bc1\u8bad\u7ec3\u7cbe\u5ea6\u3002</li> </ul>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#32","title":"3.2. \u7ec6\u7c92\u5ea6\u91cf\u5316\u65b9\u6cd5","text":"<p>FP8 \u4e24\u79cd\u6570\u636e\u7c7b\u578b\uff0cE5M2 \u4fdd\u7559\u52a8\u6001\u8303\u56f4\u4f46\u662f\u7f29\u51cf\u4e86\u5c3e\u6570\u7cbe\u5ea6\uff0cE4M3 \u591a\u4fdd\u7559\u4e86\u4e00\u4f4d\u5c3e\u6570\u7cbe\u5ea6\u4f46\u662f\u727a\u7272\u4e86\u52a8\u6001\u8303\u56f4\u3002\u4e0d\u7ba1\u90a3\u4e00\u79cd\u90fd\u4f1a\u52a0\u5267\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u4e0a\u6ea2\u548c\u4e0b\u6ea2\u95ee\u9898\u3002\u597d\u5728 LLM \u6a21\u578b\u8bad\u7ec3\u65f6\uff0c\u6743\u91cd\u4e0e\u6fc0\u6d3b\u7684\u52a8\u6001\u6027\u7814\u7a76\u53d1\u73b0\u5927\u591a\u6570\u6570\u503c\u5206\u5e03\u96c6\u4e2d\u5728 0 \u9644\u8fd1\uff0c\u4f46\u4f1a\u5e26\u6709\u660e\u663e\u7684\u5c11\u6570 outlier\u3002\u96c6\u4e2d\u5728 0 \u9644\u8fd1\u610f\u5473\u7740\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u7f29\u653e\u56e0\u5b50\uff08scaling factor\uff09\u5bf9\u6570\u503c\u8fdb\u884c\u7f29\u653e\uff0c\u4ece\u800c\u66f4\u597d\u7684\u5229\u7528\u6709\u9650\u7684\u52a8\u6001\u8303\u56f4\u3002\u4f46 outlier \u7684\u5b58\u5728\u5bfc\u81f4\u5f88\u96be\u5728\u6574\u4e2a tensor \u5c42\u9762\u9009\u53d6\u51fa\u9002\u5f53\u7684\u7f29\u653e\u56e0\u5b50\u3002</p> <p>\u4e3a\u4e86\u5e73\u8861\u6570\u503c\u7684\u6574\u4f53\u5206\u5e03\u4e0e\u5c11\u6570 outlier \u7684\u5206\u5e03\uff0c\u53ef\u4ee5\u5f15\u5165\u5206\u5757\u91cf\u5316\u7b56\u7565\uff1a\u5c06\u6570\u636e\u5206\u6210 1x128 \u6216\u8005 128x128 \u7684 block\uff0c\u5e76\u5bf9\u6bcf\u4e2a block \u9009\u53d6\u4e00\u4e2a\u7f29\u653e\u56e0\u5b50\u3002\u5bf9\u4e8e\u5927\u591a\u6570 block \u53ef\u4ee5\u9009\u62e9\u8f83\u5927\u7684\u7f29\u653e\u56e0\u5b50\u6765\u66f4\u597d\u7684\u5229\u7528\u52a8\u6001\u8303\u56f4\uff0c\u800c\u5bf9\u4e8e\u5b58\u5728 outlier \u7684 block \u53ef\u4ee5\u4f7f\u7528\u8f83\u5c0f\u7684\u7f29\u653e\u56e0\u5b50\u6765\u907f\u514d\u51fa\u73b0\u4e0a\u6ea2\u3002</p> <pre><code>block-beta\n    columns 16\n    a1[\"0.01\"] a2[\"0.02\"] a3[\"0.01\"] a4[\"...\"] a5[\"\u2192\"] a6[\"100 x\"] a7[\"1\"] a8[\"2\"] a9[\"1\"] a10[\"...\"] space:6\n    b1[\"0.02\"] b2[\"0.03\"] b3[\"1.0\"] b4[\"...\"] b5[\"\u2192\"] b6[\"1 x\"] b7[\"0.02\"] b8[\"0.03\"] b9[\"1.0\"] b10[\"...\"]\n\n    style a4 fill:#FFFFFF, stroke:#FFFFFF\n    style b4 fill:#FFFFFF, stroke:#FFFFFF\n    style a10 fill:#FFFFFF, stroke:#FFFFFF\n    style b10 fill:#FFFFFF, stroke:#FFFFFF\n    style a5 fill:#FFFFFF, stroke:#FFFFFF\n    style b5 fill:#FFFFFF, stroke:#FFFFFF\n    style a6 fill:#EE0000, stroke:#FFFFFF\n    style b6 fill:#00EE00, stroke:#FFFFFF</code></pre> <p>\u4f7f\u7528\u5757\u7c92\u5ea6\u91cf\u5316\u540e\u7684\u77e9\u9635\u4e58\u8fd0\u7b97\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <ul> <li> <p>\u9ad8\u7cbe\u5ea6 Accumulation\uff1a Nvidia H800 GPU \u7684 Tensor Core \u5728\u6267\u884c FP8 \u77e9\u9635\u8ba1\u7b97\u65f6\uff0c\u7d2f\u79ef\u7cbe\u5ea6\u88ab\u9650\u5236\u5728\u5927\u7ea6 14 \u4f4d\uff0c\u8fdc\u5c0f\u4e8e FP32 \u7cbe\u5ea6\u3002\u5f53 LLM \u8bad\u7ec3\u7684\u6743\u91cd\u77e9\u9635\u89c4\u6a21\u4e0e\u8f93\u5165\u89c4\u6a21\u53d8\u5927\u65f6\uff0c\u8fd9\u4e2a\u95ee\u9898\u4f1a\u8d8a\u6765\u8d8a\u663e\u8457\u3002DeepSeek \u56e2\u961f\u7684\u6d4b\u8bd5\u4e2d\uff0c\u5927\u5c0f\u4e3a 4096 \u7684\u77e9\u9635\u4e58\u8fd0\u7b97\u56e0\u4e3a\u7d2f\u79ef\u7cbe\u5ea6\u95ee\u9898\u51fa\u73b0\u4e86\u6700\u5927 2%\u7684\u76f8\u5bf9\u8bef\u5dee\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5f15\u5165\u4e86\u5206\u7ea7\u7d2f\u52a0\uff1a\u4f7f\u7528 Tensor Core \u9ed8\u8ba4\u7684\u7d2f\u52a0\u7cbe\u5ea6\u8fdb\u884c\u8ba1\u7b97\uff0c\u5f53\u7d2f\u79ef\u4e00\u5b9a\u6b21\u6570\u540e\uff0c\u518d\u5c06\u8fd9\u4e2a\u90e8\u5206\u7d2f\u52a0\u7ed3\u679c\u642c\u8fd0\u5230 CUDA Core \u4e0a\u8fdb\u884c FP32 \u7d2f\u52a0\u3002</p> </li> <li> <p>E4M3 \u4e0e\u5728\u7ebf\u91cf\u5316\uff1a \u5f15\u5165\u7ec6\u7c92\u5ea6\u91cf\u5316\u540e\uff0c\u4e0d\u518d\u9700\u8981\u540c\u65f6\u7ef4\u62a4 E4M3 \u548c E5M2 \u4e24\u79cd\u7cbe\u5ea6\uff0c\u56e0\u6b64 DeepSeek \u56e2\u961f\u53ea\u4f7f\u7528 E4M3 \u6570\u636e\u683c\u5f0f\u3002\u540c\u65f6\uff0c\u4e3a\u4e86\u7ef4\u62a4\u597d\u5206\u5757\u91cf\u5316\u7684\u7f29\u653e\u56e0\u5b50\uff0c\u5e76\u7b80\u5316\u6846\u67b6\uff0c\u4f7f\u7528\u7b97\u5b50\u5185\u90e8\u7684\u5728\u7ebf\u91cf\u5316\u4ee3\u66ff TransformerEngine \u4e2d\u7684\u5ef6\u8fdf\u91cf\u5316\u3002</p> </li> </ul> <p>DeepSeek \u56e2\u961f\u5728 FP8 \u7cbe\u5ea6\u4e0a\u5bf9\u7b97\u5b50\u548c\u6846\u67b6\u4f5c\u4e86\u5927\u5e45\u5ea6\u7684\u4f18\u5316\uff0c\u8fd9\u4e9b\u4f18\u5316\u9700\u8981\u5bf9\u6a21\u578b\u6846\u67b6\u3001\u8bad\u7ec3\u8fc7\u7a0b\u7684\u52a8\u6001\u6027\u4ee5\u53ca\u786c\u4ef6\u7684\u5b9e\u73b0\u7ec6\u8282\u90fd\u6709\u5145\u5206\u7684\u4e86\u89e3\u3002\u6574\u4f53\u65b9\u6848\u5728\u8ba1\u7b97\u3001\u663e\u5b58\u548c\u901a\u4fe1\u4e0a\u90fd\u6709\u4e0d\u5c0f\u7684\u6536\u76ca\uff1a</p> <ul> <li>\u8ba1\u7b97\uff1aDeepSeek \u65b9\u6848\u4e0e TransformerEngine \u65b9\u6848\u90fd\u80fd\u52a0\u901f Linear \u76f8\u5173\u7684\u4e09\u6b21\u77e9\u9635\u8ba1\u7b97\uff08\u524d\u5411\uff0c\u6743\u91cd\u53cd\u5411\u548c\u6fc0\u6d3b\u53cd\u5411\uff09\uff0c\u56e0\u6b64\u80fd\u591f\u62ff\u5230\u7684\u6536\u76ca\u5e94\u8be5\u4e0e TransformerEngine \u7684 30%\u7c7b\u4f3c\u3002\u5c11\u4e86\u4e00\u6b21\u6743\u91cd\u7684 cast\uff0c\u4f46\u662f\u591a\u51fa\u4e86\u5757\u91cf\u5316\u4e0e\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\u64cd\u4f5c\uff1b</li> <li>\u5b58\u50a8\uff1a\u4f7f\u7528 16 \u4f4d\u4f18\u5316\u5668\u72b6\u6001\uff0c\u8fd9\u90e8\u5206\u663e\u5b58\u5f00\u9500\u964d\u4f4e\u4e00\u534a\u3002Attention \u540e\u7684\u6fc0\u6d3b\u4f7f\u7528 12 bit \u5b58\u50a8\uff0c\u5bf9\u6bd4 BF16 \u964d\u4f4e 25%\u3002SwiGLU \u90e8\u5206\u6fc0\u6d3b\u901a\u8fc7 recompute \u964d\u4f4e 4 \u500d\uff0c\u901a\u8fc7 FP8 \u518d\u964d\u4f4e\u4e00\u534a\uff1b</li> <li>\u901a\u4fe1\uff1a\u4f7f\u7528 FP8 \u5c06\u901a\u4fe1\u6570\u636e\u91cf\u964d\u4f4e\u4e00\u500d\uff1b</li> </ul>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#4-fp8","title":"4. FP8 \u7cbe\u5ea6\u95ee\u9898\u5206\u6790","text":"<p>DeepSeek \u56e2\u961f\u5df2\u7ecf\u5206\u6790\u4e86\u5f71\u54cd\u7cbe\u5ea6\u7684\u4e3b\u8981\u539f\u56e0\u4e4b\u4e00\u2014\u2014\u77e9\u9635\u89c4\u6a21\u3002\u6b64\u5904\u6211\u4eec\u66f4\u52a0\u7cfb\u7edf\u6027\u7684\u8ba8\u8bba\u5f71\u54cd\u7cbe\u5ea6\u7684\u56e0\u7d20\u6709\u54ea\u4e9b\u3002\u7b97\u5b50\u7cbe\u5ea6\u6d89\u53ca\u5404\u79cd\u4e0d\u540c\u7684\u6570\u636e\u7c7b\u578b\u3001\u77e9\u9635\u5f62\u72b6\u548c\u8fd0\u7b97\u7c7b\u578b(attention\uff0cmatmul\u7b49)\uff0c\u5bfc\u81f4\u7cbe\u5ea6\u5206\u6790\u95ee\u9898\u53d8\u5f97\u6781\u4e3a\u590d\u6742\u3002\u4e3a\u4e86\u7b80\u5316\u7cbe\u5ea6\u5206\u6790\u5de5\u4f5c\uff0c\u6211\u4eec\u901a\u8fc7\u5bf9\u6a21\u578b\u4e2d\u7684\u5404\u79cd\u8fd0\u7b97\u8fdb\u884c\u5206\u6790\uff0c\u53d1\u73b0\u5927\u591a\u6570\u8ba1\u7b97\u53ef\u4ee5\u62c6\u89e3\u6210\u5411\u91cf\u5185\u79ef\u64cd\u4f5c\u7684\u96c6\u5408\u3002\u56e0\u6b64\uff0c\u901a\u8fc7\u7814\u7a76\u5411\u91cf\u5185\u79ef\u64cd\u4f5c\u7684\u7cbe\u5ea6\uff0c\u5373\u53ef\u5bf9\u7b97\u5b50\u7cbe\u5ea6\u8fdb\u884c\u4e00\u4e2a\u7cfb\u7edf\u5168\u9762\u7684\u5206\u6790\u3002\u4ee5LLM\u6a21\u578b\u4e3a\u4f8b\uff0c\u6d89\u53ca\u5230\u7684\u4e3b\u8981\u8fd0\u7b97\u5982\u4e0b\uff1a</p> <ol> <li>Attention \u8ba1\u7b97 Score \u5305\u542b\u4e86 Q \u548c K \u7684\u5185\u79ef\u8ba1\u7b97\uff1b</li> </ol> \\[ score = Softmax\\left( \\frac{QK^T}{\\sqrt{d_k}} \\right) =Softmax\\left( \\frac{    \\begin{bmatrix}    Q_0 \\cdot K_0^T &amp; Q_0 \\cdot K_1^T &amp; \\dots \\\\    Q_1 \\cdot K_0^T &amp; Q_1 \\cdot K_1^T &amp; \\dots \\\\    \\vdots &amp; \\vdots &amp; \\ddots \\\\    \\end{bmatrix} }{\\sqrt{d_k}} \\right) \\] <ol> <li>Attention \u8ba1\u7b97\u6839\u636e Score \u7684\u52a0\u6743 V\uff0c\u672c\u8d28\u662f score \u5411\u91cf\u4e0e V \u4e0d\u540c channel \u6784\u6210\u7684\u5411\u91cf\u7684\u5185\u79ef\u8ba1\u7b97\uff1b</li> </ol> \\[ Output = score \\cdot V = score \\cdot \\begin{bmatrix}     c_0 \\\\     c_1 \\\\     \\vdots \\end{bmatrix} = \\begin{bmatrix}     score \\cdot c_0 \\\\     score \\cdot c_0 \\\\     \\vdots \\end{bmatrix} \\] <ol> <li>\u77e9\u9635\u8ba1\u7b97\u53ef\u4ee5\u62c6\u89e3\u6210\u5f88\u591a\u5411\u91cf\u5185\u79ef\u8ba1\u7b97\uff1a</li> </ol> \\[ A \\times B = \\begin{bmatrix} a_0 \\\\ a_1 \\\\ \\vdots \\end{bmatrix} \\times \\begin{bmatrix} b_0 ; b_1; \\dots \\end{bmatrix} = \\begin{bmatrix} a_0 b_0 &amp; a_0 b_1 &amp; \\dots \\\\ a_1 b_0 &amp; a_1 b_1 &amp; \\dots \\\\ \\vdots &amp; \\vdots &amp; \\ddots \\\\ \\end{bmatrix} \\] <p>\u6240\u4ee5\uff0c\u7814\u7a76 FP8 \u5bf9 LLM \u7cbe\u5ea6\u7684\u5f71\u54cd\uff0c\u9996\u5148\u9700\u8981\u7814\u7a76\u5176\u5bf9\u5411\u91cf\u5185\u79ef\u7684\u6570\u503c\u7cbe\u5ea6\u7684\u5f71\u54cd\u3002\u800c\u7ecf\u8fc7\u4e00\u756a\u5b9e\u9a8c\u540e\uff0c\u53d1\u73b0\u5f71\u54cd\u8fd9\u4e2a\u6570\u503c\u7cbe\u5ea6\u7684\u4e3b\u8981\u56e0\u7d20\u6709\u4e24\u4e2a\uff1a</p> <ol> <li>\u5411\u91cf\u957f\u5ea6\u7684\u5f71\u54cd\uff0c\u5411\u91cf\u957f\u5ea6\u8d8a\u957f\uff0c\u53cd\u6620\u5230 LLM \u4e2d\u5c31\u610f\u5473\u8fd9\u6743\u91cd\u77e9\u9635\u89c4\u6a21\u8d8a\u5927\uff1b</li> <li>\u5411\u91cf\u76f8\u5173\u6027\u7684\u5f71\u54cd\uff0cLLM \u4e2d\u7684 Attention \u8ba1\u7b97\u4f1a\u9762\u4e34\u5927\u91cf\u5f3a\u76f8\u5173\u7684\u5411\u91cf\u5185\u79ef\uff1b</li> </ol>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#41","title":"4.1. \u5411\u91cf\u957f\u5ea6\u7684\u5f71\u54cd","text":"<p>\u5148\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u7684\u5b9e\u9a8c\u89c2\u5bdf\u4e0b\u5411\u91cf\u957f\u5ea6\uff08\u77e9\u9635\u89c4\u6a21\uff09\u5bf9\u8bef\u5dee\u7684\u5f71\u54cd\uff0c\u5728\u5b9e\u9a8c\u4e2d\u6784\u9020\u6ee1\u8db3\u5206\u5e03 \\(x_i \\sim \\mathcal{N}(0, 0.01)\\)\u7684\u968f\u673a\u5411\u91cf\\([x_i]\\)\u3002\u5c06\u4e24\u4e2afloat64\u5411\u91cf\u7684\u5185\u79ef\u4f5c\u4e3a\u5bf9\u7167\u7ec4\uff1b\u5c06\u4e24\u4e2a\u5411\u91cf\u91cf\u5316\u4e3a FP8 E4M3 \u683c\u5f0f\u5728\u8ba1\u7b97\u5411\u91cf\u5185\u79ef\u4f5c\u4e3a\u5b9e\u9a8c\u7ec4\u3002\u5b9e\u9a8c\u5f15\u5165tensor-wise scaling factor\u6765\u6a21\u62dfTransformerEngine\u7684\u884c\u4e3a\uff0c\u6d4b\u8bd5\u4e09\u7ec4\u4e0d\u540c\u7684\u5411\u91cf\u957f\u5ea6\u4e0b\uff0cscaling factor\u5bf9\u91cf\u5316\u8bef\u5dee\u7684\u5f71\u54cd\u3002\u91cd\u590d\u5b9e\u9a8c200\u6b21\uff0c\u7ed8\u5236\u91cf\u5316\u8bef\u5dee\u7684\u76f4\u65b9\u5206\u5e03\u5982\u4e0b\uff1a</p> <p></p> <p>\u4e0a\u56fe\u6a2a\u8f74\u4e3a\u91cf\u5316\u8bef\u5dee\uff0c\u7eb5\u8f74\u4e3a\u6837\u672c\u8ba1\u6570\u3002\u968f\u7740\u5411\u91cf\u957f\u5ea6\u7684\u589e\u5927\uff0c\u5185\u79ef\u8ba1\u7b97\u4e2d\u7684\u91cf\u5316\u8bef\u5dee\u5448\u73b0\u4e0a\u5347\u8d8b\u52bf\u3002\u8fd9\u53ef\u4ee5\u5f52\u56e0\u4e8e\u5185\u79ef\u8fd0\u7b97\u4e2d\uff0c\u5404\u9879\u7684\u91cf\u5316\u8bef\u5dee\u5728\u7d2f\u52a0\u8fc7\u7a0b\u4e2d\u4e0d\u65ad\u53e0\u52a0\uff0c\u5bfc\u81f4\u6574\u4f53\u8bef\u5dee\u660e\u663e\u589e\u52a0\u3002scaling factor\u80fd\u591f\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6539\u5584\u91cf\u5316\u8bef\u5dee\u7684\u5206\u5e03\uff0c\u91cf\u5316\u8bef\u5dee\u5206\u5e03\u66f4\u96c6\u4e2d\u5728\u96f6\u9644\u8fd1\u3002\u4e3a\u4e86\u66f4\u5408\u7406\u7684\u8bc4\u4f30\u91cf\u5316\u8bef\u5dee\u7684\u5927\u5c0f\uff0c\u53ef\u4ee5\u5f15\u5165\u4fe1\u566a\u6bd4\u6982\u5ff5<sup>2</sup>\uff1a</p> \\[ SNR = 10 \\times \\log\\_{10} \\frac{\\sum{signal_i^2} }{\\sum{nosie_i^2}}\\] <p>\u5176\u4e2d\uff1a</p> <ul> <li>\u5206\u5b50 \\(\\sum signal_i^2\\) \u8868\u793a\u771f\u5b9e\u4fe1\u53f7\u7684\u80fd\u91cf\uff1b</li> <li>\u5206\u6bcd \\(\\sum noise_i^2\\) \u5219\u4ee3\u8868\u91cf\u5316\u8bef\u5dee\uff08\u566a\u58f0\uff09\u7684\u80fd\u91cf\uff1b</li> </ul> <p>\u901a\u8fc7\u4fe1\u566a\u6bd4\uff0c\u6211\u4eec\u53ef\u4ee5\u5feb\u901f\u786e\u5b9a\u4fe1\u53f7\u6bd4\u566a\u58f0\u80fd\u91cf\u5927\u591a\u5c11\uff0c\u6bd4\u5982 20 dB \u4ee3\u8868\u7740 \\(10 \\times \\log_{10} 10^2\\)\uff0c\u4fe1\u53f7\u80fd\u91cf\u6bd4\u566a\u58f0\u80fd\u91cf\u5927 100 \u500d\uff0c40 db \u4ee3\u8868\\(10 \\times \\log_{10} 10^4\\)\uff0c\u4fe1\u53f7\u80fd\u91cf\u6bd4\u566a\u58f0\u80fd\u91cf\u5927 10000 \u500d\u3002</p> <p>\u5982\u4f55\u89e3\u8bfb\u4fe1\u566a\u6bd4\u6570\u636e</p> <ul> <li> <p>\u6b63\u503c SNR\uff1a \u8bf4\u660e\u4fe1\u53f7\u80fd\u91cf\u5927\u4e8e\u566a\u58f0\u80fd\u91cf\uff0c\u8f83\u9ad8\u7684 SNR \u8868\u793a\u91cf\u5316\u8bef\u5dee\u5bf9\u6574\u4f53\u8ba1\u7b97\u5f71\u54cd\u8f83\u5c0f\uff0c\u6570\u503c\u66f4\u63a5\u8fd1\u9ad8\u7cbe\u5ea6\u8ba1\u7b97\u7684\u7ed3\u679c\uff1b</p> </li> <li> <p>SNR \u63a5\u8fd1 0\uff1a \u4fe1\u53f7\u4e0e\u566a\u58f0\u80fd\u91cf\u63a5\u8fd1\u5e73\u8861\uff0c\u8868\u793a\u91cf\u5316\u8bef\u5dee\u5df2\u7ecf\u8fbe\u5230\u4e0e\u4fe1\u53f7\u80fd\u91cf\u76f8\u5f53\u7684\u89c4\u6a21\uff0c\u6b64\u65f6\u8fd0\u7b97\u7ed3\u679c\u53ef\u80fd\u5f00\u59cb\u51fa\u73b0\u8f83\u5927\u504f\u5dee\uff1b</p> </li> <li> <p>\u8d1f\u503c SNR\uff1a \u610f\u5473\u7740\u7d2f\u79ef\u7684\u91cf\u5316\u566a\u58f0\u80fd\u91cf\u8d85\u8fc7\u4e86\u4fe1\u53f7\u80fd\u91cf\uff0c\u4fe1\u53f7\u5728\u566a\u58f0\u4e2d\u201c\u88ab\u6df9\u6ca1\u201d\uff1b</p> </li> </ul>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#tensor-wise-scaling","title":"Tensor-wise Scaling\u7684\u4f5c\u7528","text":"<p>\u901a\u8fc7\u4fe1\u566a\u6bd4\u6765\u8bc4\u4f30TransformerEngine\u4e2dtensor-wise scaling factor\u7684\u4f5c\u7528\uff1a</p> <p></p> <p>\u5728\u4e0d\u8fdb\u884cscaling\u7684\u60c5\u51b5\u4e0b\uff08scaling=1\uff09\uff0c\u5185\u79ef\u8ba1\u7b97\u7684\u4fe1\u566a\u6bd4\u5728\u57280\u9644\u8fd1\uff0c\u610f\u5473\u7740\u4fe1\u53f7\u4e0e\u566a\u58f0\u80fd\u91cf\u5dee\u4e0d\u591a\uff0c\u8ba1\u7b97\u8bef\u5dee\u6781\u5927\u3002\u800c\u5f15\u5165scaling\u540e\uff0c\u53ef\u663e\u8457\u6539\u5584\u4fe1\u566a\u6bd4\u7684\u5206\u5e03\uff0c\u5927\u91cf\u6837\u672c\u7684\u5411\u91cf\u5185\u79ef\u4fe1\u566a\u6bd4\u663e\u8457\u9ad8\u4e8e\u96f6\uff0c\u5177\u6709\u6bd4\u8f83\u9ad8\u7684\u8ba1\u7b97\u7cbe\u5ea6\uff0c\u4f46\u4ecd\u6709\u5927\u91cfcase\u4fe1\u566a\u6bd4\u5c0f\u4e8e0\uff0c\u5373\u4fe1\u53f7\u88ab\u566a\u58f0\u6df9\u6ca1\u3002\u4ece\u8fd9\u4e2a\u5b9e\u9a8c\u53ef\u4ee5\u770b\u51fa\uff0cTransformerEngine\u7684tensor-wise scaling\u65b9\u6848\u80fd\u591f\u6539\u5584\u5411\u91cf\u5185\u79ef\u8ba1\u7b97\u7684\u4fe1\u566a\u6bd4\u3002 \u63a5\u4e0b\u6765\u6211\u4eec\u6765\u5206\u6790DeepSeek V3\u7684FP8\u65b9\u6848\u5728\u7cbe\u5ea6\u65b9\u9762\u6709\u54ea\u4e9b\u4e0d\u540c\uff0c\u662f\u5426\u80fd\u591f\u5e26\u6765\u66f4\u591a\u6536\u76ca\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#_1","title":"\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\u7684\u4f5c\u7528","text":"<p>\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\u662fDeepSeek V3\u7684FP8\u65b9\u6848\u4e2d\u7684\u91cd\u8981\u4e00\u73af\uff0c\u662f\u6307\u4f7f\u7528\u8f83\u9ad8\u7684\u7cbe\u5ea6\uff0832bit\uff09\u8fdb\u884c\u5411\u91cf\u5185\u79ef\u7684\u7d2f\u52a0\u64cd\u4f5c\u3002\u53d7\u9650\u4e8eNvidia GPU\u786c\u4ef6\u7684\u9650\u5236\uff0cTensorCore\u9ed8\u8ba4\u7d2f\u52a0\u4f7f\u752814 bit\u7d2f\u52a0\u5668\u3002\u4e3a\u4e86\u63d0\u9ad8\u7d2f\u52a0\u7cbe\u5ea6\uff0cDeepSeek V3\u4f7f\u7528\u4e86\u5206chunk\u7684\u7d2f\u52a0\u65b9\u6848\uff1a\u5728chunk\u5185\u90e8\u4f7f\u7528tensor core\u81ea\u5e26\u7684\u4f4e\u7cbe\u5ea6\u8fdb\u884c\u7d2f\u52a0\uff0c\u5728chunk\u95f4\u4f7f\u7528\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\uff0c\u5b9e\u9a8c\u7ed3\u679c\u5982\u4e0b</p> <p></p> <p>\u5b9e\u9a8c\u4f7f\u7528tensor-wise scaling\u7cfb\u657064\uff0cchunk=none\u4e3a\u4e0d\u4f7f\u7528\u5206chunk\u7684\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\uff0c\u7b49\u4ef7\u4e8eTransformerEngine\u7684\u65b9\u6848\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u5bf9\u6bd4\u53c2\u8003\u3002\u5728\u5f15\u5165\u5206chunk\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\u540e\uff0c\u6574\u4f53\u7684\u4fe1\u566a\u6bd4\u5206\u5e03\u6709\u4e86\u8f83\u5927\u7684\u6539\u5584\uff0cchunk\u8d8a\u5c0f\uff0c\u6539\u5584\u5e45\u5ea6\u8d8a\u5927\u3002\u4f46\u662f\u4ecd\u7136\u5b58\u5728\u5927\u91cfcase\uff0c\u4fe1\u566a\u6bd4\u5c0f\u4e8e\u96f6\u3002\u6211\u4eec\u9700\u8981\u8fdb\u4e00\u6b65\u4f18\u5316FP8\u91cf\u5316\u65b9\u6848\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#block-wise-scaling","title":"Block-wise Scaling\u7684\u4f5c\u7528","text":"<p>Block-wise Scaling \u662fDeepSeek V3\u5bf9FP8\u65b9\u6848\u7684\u53e6\u4e00\u4e2a\u4e3b\u8981\u4f18\u5316\uff0c\u662f\u6307\u5bf9\u5411\u91cf\u8fdb\u884c\u5206\u5757\uff0c\u5e76\u5bf9\u6bcf\u4e00\u4e2a\u5206\u5757\u5355\u72ec\u8ba1\u7b97\u6700\u4f18\u7684\u7f29\u653e\u56e0\u5b50\u3002\u5bf9\u4e0d\u540c\u7684\u5206\u5757\u513fchunksize\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u5982\u4e0b\uff1a</p> <p></p> <p>\u8fd9\u91ccchunk=none\u4e3a\u4e0d\u5206chunk\uff0c\u6574\u4e2atensor\u8ba1\u7b97\u4e00\u4e2a\u6700\u4f18\u7684scaling\u7cfb\u6570\uff0c\u5373\u9000\u5316\u4e3atensor-wise scaling\u3002\u5bf9\u6bd4\u5b8c\u5168\u6ca1\u6709\u52a8\u6001scaling\u7684\u7ed3\u679c\uff0c\u4fe1\u566a\u6bd4\u5f97\u5230\u4e86\u5927\u5e45\u6539\u8fdb\u3002\u53e6\u5916\u4e24\u7ec4\u5b9e\u9a8c\u5206\u522b\u5728\u5927\u5c0f\u4e3a512\u548c128\u7684chunk\u5185\u8ba1\u7b97\u6700\u4f18\u7684scaling\u7cfb\u6570\uff0c\u5e76\u8fdb\u884c\u7f29\u653e\u540e\u5728\u505a\u5185\u79ef\u8ba1\u7b97\u3002\u53ef\u4ee5\u53d1\u73b0\uff0c\u901a\u8fc7\u5f15\u5165chunk\u5185scaling\u7cfb\u6570\uff0c\u53ef\u4ee5\u5927\u5e45\u6539\u8fdb\u4fe1\u566a\u6bd4\u3002chunk\u8d8a\u7ec6\uff0c\u4fe1\u566a\u6bd4\u8d8a\u597d\u3002\u5f15\u5165 Block-wise \u52a8\u6001Scaling\u540e\uff0c\u57fa\u672c\u80fd\u591f\u907f\u514d\u4fe1\u566a\u6bd4\u5c0f\u4e8e\u96f6\uff08\u5373\u4fe1\u53f7\u88ab\u566a\u58f0\u6df9\u6ca1\u7684\u60c5\u51b5\uff09\u7684\u60c5\u51b5\u3002</p> <p>\u6700\u540e\uff0c\u6211\u4eec\u770b\u4e0bDeepSeek\u56e2\u961f\u662f\u5982\u4f55\u4e00\u6b65\u6b65\u8fbe\u6210V3\u4e2d\u7684FP8\u91cf\u5316\u65b9\u6848\u7684\uff1a</p> <p></p> <p>\u4e0a\u56fe\u56fe\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u4e00\u6b65\u6b65\u4f18\u5316\uff0c\u53ef\u4ee5\u770b\u5230\u901a\u8fc7\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\uff0c\u5206\u5757\u52a8\u6001scaling\u4e0e\u7cbe\u5fc3\u9009\u62e9chunk\u5927\u5c0f\uff0cDeepSeekV3\u7684FP8\u65b9\u6848\u8f83\u4e3a\u5b8c\u7f8e\u7684\u63a7\u5236\u4f4f\u4e86\u5411\u91cf\u5185\u79ef\u8fd0\u7b97\u7684\u4fe1\u566a\u6bd4\u3002\u82e5\u5355\u72ec\u5206\u6790\u6bcf\u4e00\u9879\u4f18\u5316\uff0c\u5176\u5e26\u6765\u7684\u63d0\u5347\u4ece\u76f4\u65b9\u56fe\u4e0a\u6765\u770b\u5e76\u4e0d\u662f\u7279\u522b\u7684\u7a81\u51fa\u548c\u663e\u8457\u3002\u6574\u4f53\u4fe1\u566a\u6bd4\u5bf9\u6bd4Nvidia\u7684TransformerEngine\u65b9\u6848\u5177\u5907\u4f18\u52bf\uff0c\u4f46\u6ca1\u6709\u7279\u522b\u663e\u8457\u7684\u5dee\u5f02\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#42","title":"4.2. \u5411\u91cf\u76f8\u5173\u6027\u7684\u5f71\u54cd","text":"<p>\u5411\u91cf\u5185\u79ef\u65f6\u5f71\u54cd\u7ed3\u679c\u7684\u4e00\u4e2a\u91cd\u8981\u56e0\u7d20\u662f\u4e24\u4e2a\u5411\u91cf\u7684\u76f8\u5173\u6027\uff0c\u8fd9\u91cc\u6211\u4eec\u5148\u770b\u4e0b\u5f53\u4e24\u4e2a\u8f93\u5165\u5411\u91cf\u7684\u76f8\u5173\u6027\\(\\rho\\)\u4e0d\u540c\u65f6\uff0c\u91cf\u5316\u8bef\u5dee\u662f\u5426\u5b58\u5728\u5dee\u522b\uff1a</p> <p></p> <p>\u5b9e\u9a8c\u6d4b\u8bd5\u4e86\u4e09\u4e2a\u4e0d\u540c\u7684\u5411\u91cf\u957f\u5ea6\u4e0b(128\u30011024 \u548c 4096)\uff0c\u5411\u91cf\u76f8\u5173\u6027\u5bf9FP8 \u5185\u79ef\u8ba1\u7b97\u8bef\u5dee\u7684\u5f71\u54cd\u3002\u53ef\u4ee5\u53d1\u73b0\uff0c\u4e0d\u7ba1\u662f\u54ea\u4e00\u4e2a\u5411\u91cf\u957f\u5ea6\uff0c\u76f8\u5173\u6027\u8d8a\u5927\uff0c\u8ba1\u7b97\u8bef\u5dee\u8d8a\u5927\u3002\u800c\u5411\u91cf\u8d8a\u957f\uff0c\u76f8\u5173\u6027\u7684\u5f71\u54cd\u4e5f\u8d8a\u5927\u3002\u4e3a\u4e86\u66f4\u597d\u7684\u8fdb\u884c\u5206\u6790\uff0c\u6211\u4eec\u4ecd\u7136\u4f7f\u7528\u4fe1\u566a\u6bd4\u6765\u5ea6\u91cf\u8bef\u5dee\u3002\u4e0b\u56fe\u4e3a\u76f4\u65b9\u56fe\uff0c\u6a2a\u8f74\u4e3a\u4fe1\u566a\u6bd4\uff0c\u7eb5\u8f74\u4e3a\u6837\u672c\u8ba1\u6570\uff1a</p> <p></p> <p>\u4ece\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230\uff0c\u5411\u91cf\u76f8\u5173\u6027\u5bf9\u589e\u5f3a\u65f6\uff0c\u91cf\u5316\u8bef\u5dee\u51fa\u73b0\u6bd4\u8f83\u5927\u7684\u53d8\u5316\uff0c\u4f1a\u4ece\u6bd4\u8f83\u53d1\u6563\u7684\u5206\u5e03\u53d8\u6210\u66f4\u52a0\u96c6\u4e2d\u7684\u5206\u5e03\u3002\u8fd9\u6709\u4e24\u65b9\u9762\u7684\u5f71\u54cd\uff1a\u4e00\u65b9\u9762\u6539\u8fdb\u4e86\u6700\u574f\u60c5\u51b5\uff0c\u4fe1\u566a\u6bd4\u5c0f\u4e8e0\u7684\u60c5\u51b5\u5728\u76f8\u5173\u6027\\(\\rho\\)\u589e\u5927\u65f6\u9010\u6e10\u6d88\u5931\u4e86\uff1b\u53e6\u4e00\u65b9\u9762\uff0c\u4fe1\u566a\u6bd4\u7684\u4e0a\u9650\u4e5f\u51fa\u73b0\u4e86\u660e\u663e\u7684\u4e0b\u964d\u3002\u901a\u8fc7\u4e0a\u8ff0\u5b9e\u9a8c\u6211\u4eec\u53d1\u73b0\u5411\u91cf\u76f8\u5173\u6027\u5bf9\u5411\u91cf\u5185\u79ef\u7684\u91cf\u5316\u8bef\u5dee\u5177\u6709\u5f88\u5927\u5f71\u54cd\uff0c\u63a5\u4e0b\u6765\u6211\u4eec\u5206\u6790DeepSeek V3\u7684FP8\u4f18\u5316\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u7684\u4f5c\u7528\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#_2","title":"\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\u7684\u4f5c\u7528","text":"<p>\u6211\u4eec\u6d4b\u8bd5\u957f\u5ea6\u4e3a4096\u7684\u5411\u91cf\u5728\u4e0d\u540c\u5411\u91cf\u76f8\u5173\u6027\u60c5\u51b5\u4e0b\uff0c\u5185\u79ef\u7684\u91cf\u5316\u8bef\u5dee\u53d7\u5206\u5757\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\u7684\u5f71\u54cd\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u4ece\u4e0a\u56fe\u4e2d\u53ef\u4ee5\u660e\u663e\u770b\u5230\uff0c\u76f8\u5173\u6027\u8d8a\u5f3a\u4fe1\u566a\u6bd4\u7684\u5206\u5e03\u8d8a\u96c6\u4e2d\uff0c\u8d8a\u504f\u5411\u4f4e\u4fe1\u566a\u6bd4\u3002\u800c\u4f7f\u7528\u5206\u5757\u9ad8\u7cbe\u5ea6\u7d2f\u52a0\u540e\uff0c\u4fe1\u566a\u6bd4\u7684\u5206\u5e03\u5f97\u5230\u4e86\u6781\u5927\u6539\u5584\u3002\u76f8\u5173\u6027\u8d8a\u5f3a\u8fd9\u79cd\u6539\u5584\u8d8a\u4e3a\u660e\u663e\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#block-wise-scaling_1","title":"Block-wise Scaling","text":"<p>\u6d4b\u8bd5\u957f\u5ea6\u4e3a4096\u7684\u5411\u91cf\u5728\u4e0d\u540c\u5411\u91cf\u76f8\u5173\u6027\u60c5\u51b5\u4e0b\uff0c\u5185\u79ef\u7684\u91cf\u5316\u8bef\u5dee\u53d7Block-wise Scaling\u7684\u5f71\u54cd\u5982\u4e0b\u56fe\u6240\u793a\uff1a</p> <p></p> <p>\u4ece\u5b9e\u9a8c\u7ed3\u679c\u53ef\u4ee5\u770b\u51fa\uff0c\u5728\u5b58\u5728\u5411\u91cf\u76f8\u5173\u6027\u7684\u60c5\u51b5\u4e0b\uff0c\u5206\u5757 scaling \u7b56\u7565\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u4fe1\u566a\u6bd4\u3002\u5411\u91cf\u76f8\u5173\u6027\u8d8a\u5f3a\uff0c\u63d0\u5347\u7684\u6548\u679c\u8d8a\u663e\u8457\u3002</p> <p>\u8fd9\u4e9b\u53d1\u73b0\u4e3a LLM \u8bad\u7ec3\u4e2d\u7684 FP8 \u4f18\u5316\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\uff1a\u5728\u5904\u7406 Attention \u8fd9\u6837\u7684\u9ad8\u76f8\u5173\u6027\u8ba1\u7b97\u65f6\uff0c\u5e94\u8be5\u4f18\u5148\u8003\u8651\u91c7\u7528\u5408\u9002\u5927\u5c0f\u7684\u5206\u5757\u7b56\u7565\uff0c\u800c\u4e0d\u662f\u7b80\u5355\u5730\u8c03\u6574\u5168\u5c40 scaling factor\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/12/fp8_training/#43","title":"4.3. \u7ed3\u8bba","text":"<p>\u6211\u4eec\u8ba8\u8bba\u4e86TransformerEngine\u4e0eDeepSeek V3\u4f7f\u7528\u7684\u4e24\u79cd\u4e0d\u540c\u7684FP8\u8bad\u7ec3\u65b9\u6848\uff0c\u5e76\u4e14\u4ece\u5411\u91cf\u5185\u79ef\u7684\u91cf\u5316\u566a\u58f0\u5206\u6790\u5165\u624b\uff0c\u5bf9\u6bd4\u4e86\u4e24\u8005\u5728\u968f\u673a\u5411\u91cf\u4e0e\u76f8\u5173\u5411\u91cf\u4e0b\u7684\u8868\u73b0\u3002\u5728\u5b8c\u5168\u968f\u673a\u5411\u91cf\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u4e00\u6b65\u6b65\u5f15\u5165\u4f18\u5316\uff0c\u9010\u6b65\u63d0\u9ad8\u5185\u79ef\u8ba1\u7b97\u7684\u4fe1\u566a\u6bd4\u3002\u65e0\u6cd5\u786e\u5b9aDeepSeek\u56e2\u961f\u5728\u8bbe\u8ba1\u81ea\u5df1\u7684FP8\u65b9\u6848\u65f6\uff0c\u662f\u5426\u4f7f\u7528\u4e86\u7c7b\u4f3c\u7684\u91cf\u5316\u5206\u6790\u624b\u6bb5\u3002\u4f46\u8fd9\u79cd\u5206\u6790\u65b9\u6cd5\u4e5f\u8bb8\u53ef\u4ee5\u5e2e\u52a9\u6211\u4eec\u8fdb\u4e00\u6b65\u6539\u8fdbFP8\u6216\u8005\u5176\u4ed6\u4f4e\u7cbe\u5ea6\u65b9\u6848\u3002</p> <p>\u5f53\u5206\u6790\u5230\u76f8\u5173\u5411\u91cf\u7684\u5185\u79ef\u4fe1\u566a\u6bd4\u65f6\uff0c\u6211\u8ba4\u4e3a\u51fa\u73b0\u4e86\u6240\u8c13\u7684\u201dAha Moment\u201d\u3002\u5bf9\u6bd4TransformerEngine\uff0cDeepSeek\u7684\u65b9\u6848\u867d\u6709\u6240\u4f18\u52bf\uff0c\u4f46\u8fd8\u4e0d\u591f\u60ca\u8273\u3002\u4f46\u8003\u8651\u5411\u91cf\u76f8\u5173\u6027\u540e\uff0c\u6211\u4eec\u89c2\u5bdf\u5230\u4e86\u975e\u5e38\u660e\u663e\u7684\u4fe1\u566a\u6bd4\u63d0\u5347\u3002\u6211\u8ba4\u4e3a\u8fd9\u79cd\u63d0\u5347\u5e76\u975e\u662f\u65e0\u5fc3\u7684\u7ed3\u679c\uff0c\u800c\u662f\u7ecf\u8fc7\u53ef\u4ee5\u8bbe\u8ba1\u7684\u3002\u6bd5\u7adf\u5728\u771f\u5b9e\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u5b8c\u6574\u7684FP8\u65b9\u6848\u9700\u8981\u5de8\u989d\u7684\u6295\u5165\uff0c\u5f88\u96be\u60f3\u8c61DeepSeek\u56e2\u961f\u5728\u6a21\u578b\u4e0a\u76f4\u63a5\u7aef\u5230\u7aef\u8bad\u7ec3\u6765\u8fdb\u884c\u4f18\u5316\u624b\u6bb5\u7684\u6d88\u878d\u5b9e\u9a8c\u3002</p> <p>\u672c\u6587\u5b9e\u9a8c\u4ee3\u7801\u53ef\u89c1\uff1ahttps://github.com/reiase/ieee754_simulation/blob/master/simfloat_fp8_e4m3_v2.ipynb</p> <ol> <li> <p>FP8 FORMATS FOR DEEP LEARNING \u21a9</p> </li> <li> <p>SNR\u4fe1\u566a\u6bd4\u5b9a\u4e49 \u21a9</p> </li> </ol>","tags":["LLM","Training","FP8"]},{"location":"2025/02/15/int8_training/","title":"INT8\u4e5f\u80fd\u8bad\u7ec3","text":"<p>\u5728\u524d\u4e00\u7bc7\u535a\u5ba2\u4e2d\u5206\u6790\u4e86DeepSeek V3\u5982\u4f55\u4f7f\u7528FP8\u8bad\u7ec3\uff0c\u600e\u4e48\u514b\u670d\u6f5c\u5728\u7684\u7cbe\u5ea6\u95ee\u9898\u3002\u4f7f\u7528\u76f8\u540c\u65b9\u6cd5\u5bf9INT8\u5904\u7406\u5411\u91cf\u5185\u79ef\u8fd0\u7b97\u7684\u6570\u503c\u7cbe\u5ea6\u8fdb\u884c\u7814\u7a76\uff0c\u53d1\u73b0\u8fd0\u7b97\u7684\u4fe1\u566a\u6bd4\u5e76\u4e0d\u6bd4FP8\u5dee\u5f88\u591a\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/15/int8_training/#int8","title":"INT8 \u91cf\u5316","text":"<p>\u7ed9\u5b9a\u4e00\u4e2a\u6d6e\u70b9\u6570\u5411\u91cf \\(x \\in \\mathbb{R}^n\\)\uff0cINT8\u91cf\u5316\u7684\u76ee\u6807\u662f\u5c06\u5176\u6620\u5c04\u5230 [-128, 127] \u7684\u6574\u6570\u7a7a\u95f4\u3002\u8fd9\u4e2a\u8fc7\u7a0b\u9700\u8981\u786e\u5b9a\u7f29\u653e\u56e0\u5b50 \\(\\alpha\\) \u4e0e\u96f6\u70b9\u504f\u79fb \\(\\beta\\)\uff0c\u4f7f\u5f97\uff1a</p> \\[ x_q = round(\\frac{x}{\\alpha}) + \\beta \\] <p>\u5176\u4e2d \\(x_q\\) \u8868\u793a\u91cf\u5316\u540e\u7684INT8\u503c\u3002\u7f29\u653e\u56e0\u5b50 \\(\\alpha\\) \u901a\u5e38\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u8ba1\u7b97\uff1a</p> \\[ \\alpha = \\frac{max(|x|)}{127} \\] <p>\u8fd9\u786e\u4fdd\u4e86\u91cf\u5316\u540e\u7684\u503c\u4e0d\u4f1a\u8d85\u51faINT8\u7684\u8868\u793a\u8303\u56f4\u3002\u800c\u96f6\u70b9\u504f\u79fb \\(\\beta\\) \u5728\u5bf9\u79f0\u91cf\u5316\u573a\u666f\u4e0b\u901a\u5e38\u8bbe\u7f6e\u4e3a0\uff0c\u5728\u975e\u5bf9\u79f0\u91cf\u5316\u65f6\u5219\u9700\u8981\u6839\u636e\u6570\u636e\u5206\u5e03\u6765\u786e\u5b9a\u3002</p> <p>\u5bf9\u4e8eLLM\u8bad\u7ec3\u573a\u666f\uff0c\u7531\u4e8e\u6743\u91cd\u548c\u6fc0\u6d3b\u503c\u901a\u5e38\u5448\u73b0\u5bf9\u79f0\u5206\u5e03\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5bf9\u79f0\u91cf\u5316\u65b9\u6848\uff1a</p> <pre><code>def symmetric_quantize(x: torch.Tensor) -&gt; Tuple[torch.Tensor, float]:\n    alpha = x.abs().max() / 127.0  # \u8ba1\u7b97\u7f29\u653e\u56e0\u5b50\n    x_q = torch.round(x / alpha)   # \u91cf\u5316\n    x_q = torch.clamp(x_q, -128, 127)  # \u622a\u65ad\n    return x_q, alpha\n</code></pre> <p>\u53cd\u91cf\u5316\u64cd\u4f5c\u5219\u662f\u5c06INT8\u503c\u6620\u5c04\u56de\u6d6e\u70b9\u6570\u7a7a\u95f4\uff1a</p> \\[ x_r = (x_q - \\beta) \\times \\alpha \\] <p>\u5176\u4e2d \\(x_r\\) \u662f\u53cd\u91cf\u5316\u540e\u7684\u6d6e\u70b9\u6570\u503c\u3002\u5728\u5bf9\u79f0\u91cf\u5316\u573a\u666f\u4e0b\uff0c\u7531\u4e8e \\(\\beta = 0\\)\uff0c\u53cd\u91cf\u5316\u7b80\u5316\u4e3a\uff1a</p> <pre><code>def symmetric_dequantize(x_q: torch.Tensor, alpha: float) -&gt; torch.Tensor:\n    return x_q * alpha\n</code></pre> <p>\u4e0eFP8\u4e0d\u540c\uff0cINT8\u91cf\u5316\u662f\u5747\u5300\u91cf\u5316\uff0c\u4e5f\u5c31\u662f\u8bf4\u76f8\u90bb\u7684\u4e24\u4e2a\u91cf\u5316\u7ea7\u522b\u4e4b\u95f4\u7684\u95f4\u9694\u662f\u56fa\u5b9a\u7684\u3002\u8fd9\u610f\u5473\u7740INT8\u57280\u9644\u8fd1\u7684\u7cbe\u5ea6\u4e0d\u5982FP8\uff0c\u4f46\u5728\u8f83\u5927\u503c\u9644\u8fd1\u7684\u7cbe\u5ea6\u53ef\u80fd\u4f18\u4e8eFP8\u3002\u8fd9\u79cd\u7279\u6027\u4f7f\u5f97INT8\u5728\u5904\u7406\u67d0\u4e9b\u5206\u5e03\u8f83\u4e3a\u5747\u5300\u7684\u6570\u636e\u65f6\u53ef\u80fd\u4f1a\u6709\u66f4\u597d\u7684\u8868\u73b0\u3002</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/15/int8_training/#int8_1","title":"INT8\u91cf\u5316\u8bef\u5dee\u5206\u6790","text":"<p>\u9488\u5bf94\u79cd\u4e0d\u540c\u7684\u5411\u91cf\u957f\u5ea6\uff0c128/1024/2048/4096\uff0c\u5206\u522b\u8fdb\u884c50\u6b21\u5411\u91cf\u5185\u79ef\u5b9e\u9a8c\uff0c\u5e76\u5206\u522b\u8ba1\u7b97FP8\u4e0eINT8\u91cf\u5316\u7684\u4fe1\u566a\u6bd4\uff1a</p> <p></p> <p>\u5b9a\u6027\u6765\u770b\uff0cINT8\u7684\u4fe1\u566a\u6bd4\u76f8\u6bd4FP8\u5e76\u4e0d\u5f88\u5dee\uff0c\u6700\u5dee\u60c5\u51b5\u751a\u81f3\u6bd4FP8\u8981\u597d\u4e00\u4e9b\u3002\u8fdb\u4e00\u6b65\u5f15\u5165\u5206\u5757\u91cf\u5316\uff0c\u770bINT8\u91cf\u5316\u65b9\u6cd5\u7684\u4e0a\u9650\u5982\u4f55\uff1a</p> <p></p> <p>\u4f7f\u7528\u5206\u5757\u5927\u5c0f128\u65f6\uff0cINT8\u91cf\u5316\u65b9\u6cd5\u7684\u4fe1\u566a\u6bd4\u4e0eFP8\u5176\u4e92\u76f8\u5f53\uff0c\u751a\u81f3\u5728\u90e8\u5206\u5411\u91cf\u957f\u5ea6\u4e0b\u751a\u81f3\u7565\u597d\u4e00\u4e9b\u3002\u5177\u4f53\u5b9e\u9a8c\u4ee3\u7801\u89c1\uff1ahttps://github.com/reiase/ieee754_simulation/blob/master/simfloat_fp8_vs_int8.ipynb</p>","tags":["LLM","Training","FP8"]},{"location":"2025/02/15/int8_training/#_1","title":"\u4e00\u4e9b\u8ba8\u8bba","text":"<p>\u901a\u8fc7\u4fe1\u566a\u6bd4\u7684\u5b9e\u9a8c\uff0c\u6211\u4eec\u53d1\u73b0\u4f7f\u7528\u5206\u5757\u91cf\u5316\u7684int8\u5411\u91cf\u5185\u79ef\u7cbe\u5ea6\u5e76\u4e0d\u4e00\u5b9a\u6bd4fp8\u5dee\uff0c\u8fd9\u4e2a\u5b9e\u9a8c\u9700\u8981\u66f4\u52a0\u7cfb\u7edf\u6027\u7684\u6269\u5c55\uff0c\u6bd4\u5982\u6d4b\u8bd5\u4e0d\u540c\u7684\u91cf\u5316\u65b9\u6cd5\u548cround\u7b56\u7565\u3002\u4f46\u5982\u679c\u4ec5\u4ec5\u50cfTransformerEngine\u90a3\u6837\u66ff\u4ee3LLM\u4e2d\u539f\u6709\u7684\u77e9\u9635\u4e58\u6cd5\uff0c\u5e94\u8be5\u4e0d\u4f1a\u6709\u592a\u5927\u95ee\u9898\u3002\u63a8\u7406\u9636\u6bb5\u4e5f\u53ef\u4ee5\u4f7f\u7528\u7c7b\u4f3cLLM.int8\u7684\u65b9\u6cd5<sup>1</sup>\u6765\u4fdd\u8bc1\u7cbe\u5ea6\u3002</p> <ol> <li> <p>LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale \u21a9</p> </li> </ol>","tags":["LLM","Training","FP8"]},{"location":"2024/01/20/review-llm/","title":"LLM\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u975e\u6b63\u5f0f\u8bc4\u8bba","text":"<p>\u6700\u8fd1\u8c03\u7814\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u65f6\uff0c\u53d1\u73b0\u4e86\u9887\u6709\u610f\u601d\u7684\u4e00\u4e9b\u5185\u5bb9\uff0c\u51c6\u5907\u5199\u4e00\u4e9b\u5173\u4e8e\u9884\u8bad\u7ec3\u5927\u6a21\u578b\u7684\u975e\u6b63\u5f0f\u8bc4\u8bba\uff1a</p> <ul> <li>\u5173\u4e8eScaling Law\u7684\u975e\u6b63\u5f0f\u8bc4\u8bba</li> <li>\u5173\u4e8e\u6a21\u578b\u7ed3\u6784\u7684\u975e\u6b63\u5f0f\u8bc4\u8bba</li> <li>\u5173\u4e8e\u4f18\u5316\u5668\u7684\u975e\u6b63\u5f0f\u8bc4\u8bba</li> <li>\u5173\u4e8e\u5206\u5e03\u5f0f\u5e76\u884c\u8bad\u7ec3\u7684\u975e\u6b63\u5f0f\u8bc4\u8bba</li> </ul>","tags":["LLM","Pretrain"]},{"location":"2024/01/21/review-scaling-law/","title":"\u5173\u4e8eScaling Law\u7684\u975e\u6b63\u5f0f\u8bc4\u8bba","text":"<p>\u5927\u6a21\u578b\u88ab\u5e7f\u6cdb\u5173\u6ce8\u7684\u8d77\u70b9\u662fOpenAI\u53d1\u5e03ChatGPT\uff0c\u51ed\u501f\u4f18\u79c0\u7684\u5bf9\u8bdd\u80fd\u529b\u4e0eIn-Context Learning\u7684\u80fd\u529b\uff0c\u5438\u5f15\u4e86\u6574\u4e2aAI\u5708\u7684\u5173\u6ce8\u3002 LLM\u6280\u672f\u7684\u53d1\u5c55\u4e3b\u8981\u5f97\u76ca\u4e8eScaling Law\u7ed9\u51fa\u7684\u4e00\u7cfb\u5217\u9884\u6d4b\uff0c\u8fd9\u4e9b\u9884\u6d4b\u4e3b\u5bfc\u4e86\u6700\u8fd1\u51e0\u5e74LLM\u6a21\u578b\u5728\u53c2\u6570\u3001\u6570\u636e\u548c\u7b97\u529b\u89c4\u6a21\u4e0a\u5feb\u901f\u589e\u957f\u3002 \u751a\u81f3\u6709\u4eba\u63d0\u51fa\u4e86\u201dScale is All You Need!\u201d\u3002\u672c\u6587\u4e3b\u8981\u8ba8\u8bbaLLM\u884c\u4e3a\u7684\u53ef\u9884\u6d4b\u6027\uff0c\u8bb0\u5f55\u5173\u4e8eScaling Law\u3001Grokking\u548cDouble descent\u7b49empirical phenomenon\u7684\u8ba8\u8bba\u3002</p>"},{"location":"2024/01/21/review-scaling-law/#_1","title":"\u5927\u6a21\u578b\u7684\u826f\u597d\u6cdb\u5316\u6027","text":"<p>OpenAI\u5728GPT3\u8bba\u6587\u4e2d\u63d0\u51faGPT-3\u7b49\u8bed\u8a00\u6a21\u578b\uff08language model\uff09\u662ffew shot learner\u3002\u8fd9\u4e00\u6982\u5ff5\u51fa\u81eaIn-Context Learning\uff0c\u5177\u4f53\u662f\u6307\u5728\u6a21\u578b\u9884\u6d4b\u65f6\u901a\u8fc7\u4e0a\u4e0b\u6587\u4e2d\u7ed9\u51fa\u8db3\u591f\u7684\u80cc\u666f\u77e5\u8bc6\u548c\u4efb\u52a1\u63cf\u8ff0\uff0c\u7136\u540e\u76f4\u63a5\u9884\u6d4b<sup>1</sup>\uff0c\u6bd4\u5982\uff1a</p> <ul> <li>Zero-shot\uff08\u6ca1\u6709\u793a\u4f8b\uff09\uff1a{8+9=?}</li> <li>One-shot\uff08\u4e00\u4e2a\u793a\u4f8b\uff09\uff1a5+5=10, {8+9=?}</li> <li>Few-shot\uff08\u591a\u4e2a\u793a\u4f8b\uff09\uff1a6+7=13,6+6=12,5+5=10, {==8+9=? ==}</li> </ul> <p>Open AI\u57282020\u5e74\u7684\u5927\u6a21\u578bScaling Law\u8bba\u6587\u4e2d\u53d1\u73b0\uff0c\u82e5\u5c06\u6a21\u578b\u8fc1\u79fb\u5230\u65b0\u7684\u6570\u636e\u96c6\uff0c\u65b0\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5loss\u4e0e\u8bad\u7ec3\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5loss\u5b58\u5728\u4e00\u4e2a\u76f8\u5bf9\u6052\u5b9a\u7684offset\u3002\u968f\u7740\u6a21\u578b\u89c4\u6a21\u7684\u589e\u5927\uff0c\u8bad\u7ec3\u6570\u636e\u96c6\u548c\u65b0\u6570\u636e\u96c6\u4e0a\u7684\u6d4b\u8bd5loss\u8fd1\u4f3c\u540c\u6b65\u4e0b\u964d\u3002\u8fd9\u4e5f\u5c31\u610f\u5473\u7740\u53ef\u4ee5\u901a\u8fc7\u6301\u7eed\u589e\u5927\u6a21\u578b\u5927\u5c0f\u6765\u964d\u4f4e\u6a21\u578b\u5728\u6240\u6709\u6570\u636e\u96c6\u4e0a\u7684loss\u3002</p> <p></p> <p>\u8fd9\u79cd\u4f18\u79c0\u7684\u6cdb\u5316\u6027\u7ed9\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u63a2\u7d22\u65b9\u5411\uff1a\u76f8\u6bd4\u63a2\u7d22\u66f4\u590d\u6742\u7684\u6a21\u578b\u7ed3\u6784\uff0c\u63a2\u7d22\u66f4\u5927\u7684\u6a21\u578b\u662f\u5426\u80fd\u591f\u6210\u4e3a\u6df1\u5ea6\u5b66\u4e60\u7684\u5168\u65b0\u8def\u5f84\u3002</p>"},{"location":"2024/01/21/review-scaling-law/#_2","title":"\u5927\u6a21\u578b\u7684\u53ef\u9884\u6d4b\u6027","text":"<p>\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u7684\u9ed1\u76d2\u70bc\u4e39\u662f\u88ab\u5e7f\u4e3a\u8bdf\u75c5\u7684\u95ee\u9898\u3002\u867d\u7136\u4e0d\u4e4f\u4e39\u672f\u5df2\u81f3\u81fb\u5883\u7684\u9876\u7ea7\u4e39\u5e08\uff0c\u4f46\u4e1a\u52a1\u65b9\u548c\u8d44\u672c\u65b9\u662f\u4e07\u4e07\u4e0d\u6562\u5728\u5355\u6b21\u8bad\u7ec3\u8d85\u4e00\u4e2a\u6708\uff0c\u8017\u8d44\u8d85\u767e\u4e07\u7684LLM\u8bad\u7ec3\u4ea4\u7ed9\u8fd9\u4e9b\u4e39\u5e08\u6765\u8d1f\u8d23\u7684\u3002\u5982\u4f55\u9884\u6d4b\u4e00\u6b21\u8bad\u7ec3\u80fd\u8fbe\u5230\u7684\u7cbe\u5ea6\uff0c\u4ee5\u53ca\u5982\u4f55\u5206\u914d\u8fd9\u79cd\u8d85\u767e\u4e07\u7ea7\u522b\u7684\u8bad\u7ec3\u6210\u672c\u6295\u5165\uff0c\u5c31\u53d8\u6210\u4e86\u8bad\u7ec3LLM\u7684\u5fc5\u8981\u6761\u4ef6\u3002\u8fd9\u65b9\u9762\u6bd4\u8f83\u91cd\u8981\u7684\u5de5\u4f5c\u6709\u4e24\u7bc7\uff1a\u4e00\u7bc7\u662fOpenAI\u63d0\u51fa\u7684Kaplan Scaling Law<sup>2</sup>\uff0c\u4e3b\u8981\u7814\u7a76\u4e86\u6a21\u578bloss\u548c\u51e0\u4e2a\u4e3b\u8981\u53c2\u6570\uff1a\u6a21\u578b\u53c2\u6570\u89c4\u6a21N\u3001\u8bad\u7ec3\u6570\u636e\u89c4\u6a21D\u4ee5\u53ca\u7b97\u529b\u6295\u5165C\u4e4b\u95f4\u7684\u5173\u7cfb\uff1b\u53e6\u4e00\u7bc7\u662fDeepMind\u63d0\u51fa\u7684Chinchilla Optimal<sup>3</sup>\uff0c\u4e3b\u8981\u7814\u7a76\u8ba1\u7b97\u8d44\u6e90\u9650\u5b9a\u4e0b\uff0c\u7b97\u529b\u7684\u5206\u914d\u95ee\u9898\uff0c\u6bd4\u5982\u6bcf\u4e2a\u53c2\u6570\u5bf9\u5e94\u591a\u5c11token\u3002</p>"},{"location":"2024/01/21/review-scaling-law/#kaplan-scaling-law","title":"Kaplan Scaling Law","text":"<p>Kaplan Scaling Law\u53d1\u8868\u4e8e2020\u5e74\uff0c\u540c\u5e74OpenAI\u4e5f\u6b63\u5f0f\u53d1\u8868\u4e86GPT3\u3002\u56e0\u6b64\u4ece\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u6765\u8bf4\uff0cKaplan Scaling Law\u5373\u662f\u5bf9GPT3\u6a21\u578b\u8bad\u7ec3\u7684\u4e00\u4e2a\u603b\u7ed3\uff0c\u4e5f\u662fOpenAI\u575a\u5b9a\u6295\u5165\u5927\u6a21\u578b\u548c\u5927\u7b97\u529b\u7684\u4fe1\u5fc3\u6240\u5728\u3002\u5148\u7b80\u5355\u770b\u4e0bKaplan Scaling Law\u7684\u51e0\u4e2a\u4e3b\u8981\u7ed3\u8bba\uff1a</p> <ol> <li>\u9650\u5b9a\u6a21\u578b\u53c2\u6570\u89c4\u6a21N\uff0c\u7ed9\u8db3\u591f\u5927\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u5230\u6536\u655b\uff1a \\(L(N) = \\left (\\frac{N_c}{N}\\right ) ^{\\alpha_N}; \\alpha_N \\simeq 0.076, N_c \\simeq 8.8 \\times 10^{13}\\)</li> <li>\u9650\u5b9a\u6570\u636e\u89c4\u6a21D\uff0c\u901a\u8fc7early stopping \u8bad\u7ec3\u5927\u6a21\u578b\uff1a \\(L(D) = \\left ( \\frac{D_c}{D} \\right)^{\\alpha_D};\\alpha_D \\simeq 0.095, D_c \\simeq 5.4 \\times 10^{13}\\)</li> <li>\u9650\u5b9a\u8ba1\u7b97\u8d44\u6e90\uff0c\u7ed9\u8db3\u591f\u5927\u7684\u6570\u636e\u96c6\u3001\u6700\u4f18\u6a21\u578b\u89c4\u6a21\u4e0e\u8db3\u591f\u5c0f\u7684batch size\uff1a \\(L(C_{min})=\\left ( \\frac{C_c^{min}}{C}\\right )^{\\alpha_C^{min}}; \\alpha_C^{min} \\simeq 0.050, C_C^{min} \\simeq 3.1 \\times 10^8\\  (PFdays)\\) </li> </ol> <p>\u76f4\u89c2\u4e00\u70b9\u5c31\u662f\u8bf4\u5f71\u54cdloss\u7684\u4e3b\u8981\u56e0\u7d20\u662fN\u3001D\u548cC\u3002\u968f\u7740\u4e09\u8005\u7684\u6307\u6570\u589e\u957f\uff0closs\u7ebf\u6027\u4e0b\u964d\uff1a</p> <p></p> <p>\u53e6\u4e00\u65b9\u9762\u6a21\u578b\u7ed3\u6784\u8d85\u53c2\u3001\u5b66\u4e60\u5668\u7684\u8d85\u53c2\u6ca1\u90a3\u4e48\u91cd\u8981\uff0c\u6574\u4f53\u5bf9loss\u5f71\u54cd\u4e0d\u5927\uff1a</p> <p></p> <p>\u6709\u4e9b\u53c2\u6570\u5728\u4e00\u5230\u4e24\u4e2a\u5c3a\u5ea6\u5185\u53d8\u5316\uff0c\u800c\u5bf9\u6700\u7ec8\u7684loss\u5f71\u54cd\u57282%\u4ee5\u5185\u3002\u800c\u5b66\u4e60\u7387\u53ea\u8981\u4e0d\u8fc7\u4e8e\u5c0f\uff0c\u6216\u8005\u8870\u51cf\u8fc7\u4e8e\u8fc5\u901f\uff0c\u5bf9\u6700\u7ec8loss\u7684\u5f71\u54cd\u5e76\u4e0d\u5927\u3002</p> <p></p> <p>Kaplan Scaling Law\u6700\u4e3a\u91cd\u5927\u7684\u610f\u4e49\u5728\u4e8e\u4e24\u70b9\uff1a</p> <ul> <li>\u7ed9\u51fa\u4e86\u5f71\u54cd\u6a21\u578b\u6548\u679c\u7684\u4e3b\u8981\u56e0\u7d20\u6a21\u578b\u53c2\u6570\u89c4\u6a21N\u548c\u8bad\u7ec3\u6570\u636e\u89c4\u6a21D\uff0c\u5e76\u8ba4\u4e3a\u5176\u4ed6\u8d85\u53c2\u662f\u6b21\u8981\u56e0\u7d20\uff0c\u5f71\u54cd\u4e0d\u5927\uff0c\u56e0\u6b64\u4e5f\u5c31\u907f\u514d\u4e86LLM\u4e0a\u7ee7\u7eed\u9ed1\u76d2\u70bc\u4e39\uff1b</li> <li>\u7ed9\u51fa\u4e86\u5bf9Loss\u7684\u9884\u6d4b\u65b9\u6cd5\uff0c\u53ea\u8981\u6307\u6570\u589e\u957fN\u3001D\u548c\u7b97\u529bC\uff0c\u5373\u53ef\u83b7\u5f97loss\u7684\u7ebf\u6027\u6539\u8fdb\uff1b \u6839\u636eKaplan Scaling Law\uff0cGPT3\u7684175B\u53c2\u6570\u9700\u8981300B token\u8bad\u7ec3\uff0c\u7ea6\u6bcf\u4e2a\u53c2\u65701.7\u4e2atoken\uff08\u5177\u4f53\u53c2\u8003kaplan vs chinchilla\uff09\u3002</li> </ul>"},{"location":"2024/01/21/review-scaling-law/#chinchila-scaling-law","title":"Chinchila Scaling Law","text":"<p>Chinchila Scaling Law\u7531DeepMind\u53d1\u8868\u4e8e2022\u5e74\uff0c\u540c\u5e74Google\u53d1\u8868\u4e86PaLM\uff08Language Modeling with Pathways<sup>4</sup>\uff09\u3002Chinchila Scaling Law \u5173\u6ce8\u6c42\u89e3\u7b97\u529b\u7ea6\u675f\u4e0b\uff0c\u6700\u4f18\u6a21\u578b\u89c4\u6a21N\u4e0e\u6570\u636e\u89c4\u6a21D\uff0c\u5373\uff1a \\(N_{opt}(C), D_{opt}(C) = \\underset{N, D, \\ s.t.\\ FLOPs(N,D)=C}{\\arg\\min} L(N, D)\\) \u6700\u7ec8\u53ef\u4ee5\u62df\u5408\u51fa\u6765N\u3001D\u4e0e\u7b97\u529bC\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a\\(N_{opt} \\propto  C^a, D_{opt} \\propto C^b\\)\u3002DeepMind\u7ed9\u51fa\u4e86\u4e09\u79cd\u5b9e\u73b0\uff1a</p> \u5b9e\u73b0 \u53c2\u6570\\(a\\) \u53c2\u6570\\(b\\) \u56fa\u5b9aN\uff0c\u641c\u7d22\u6700\u4f18D 0.50 0.50 \u56fa\u5b9aC\uff0c\u641c\u7d22\u6700\u4f18N\u548cD 0.49 0.51 \u62df\u5408L(N,D)\uff0c\u641c\u7d22\u6700\u4f18N\u548cD 0.46 0.54 Kaplan Scaling Law 0.73 0.27 <p>\u5176\u4e2d\u7b2c\u4e09\u79cd\u5b9e\u73b0\u62df\u5408\u4e86\u5982\u4e0b\u5173\u7cfb \\(L(N,D)=E+\\frac{A}{N^{\\alpha}}+\\frac{B}{D^{\\beta}}\\) \u5176\u4e2d\\(E\\)\u523b\u753b\u7684\u662f\u7406\u60f3\u6a21\u578b\u7684loss\uff0c\\(\\frac{A}{N^{\\alpha}}\\)\u523b\u753b\u7684\u662f\u6709\u9650\u6a21\u578b\u53c2\u6570\u5bf9loss\u7684\u5f71\u54cd\uff0c\\(\\frac{B}{D^{\\beta}}\\)\u523b\u753b\u7684\u662f\u6709\u9650\u6570\u636e\u91cf\u5bf9loss\u7684\u5f71\u54cd\u3002\u57fa\u4e8e\u8fd9\u4e2a\u62df\u5408\u51fa\u6765\u7684loss\uff0c\u53ef\u4ee5\u7ed8\u5236\u5982\u4e0b\u56fe\u50cf\uff1a  \u5728\u5de6\u56fe\u4e2d\uff0c\u6bcf\u6761loss\u7b49\u9ad8\u7ebf\u90fd\u6709\u4e00\u4e2a\u7b97\u529b\u6700\u4f18\u70b9\uff0c\u8fd9\u4e9b\u7b97\u529b\u6700\u4f18\u70b9\u53c8\u5728log-log\u5750\u6807\u4e0a\u8fde\u6210\u4e86\u4e00\u6761\u8fd1\u4f3c\u76f4\u7ebf\uff0c\u76f4\u7ebf\u4e0a\u7684\u70b9\u5373Chinchilla Optimal\u70b9\u3002\u8fbe\u5230Chinchilla Optimal\uff0c\u6bcf\u4e2a\u53c2\u6570\u5927\u7ea6\u9700\u898120\u4e2atoken\u3002</p>"},{"location":"2024/01/21/review-scaling-law/#beyond-power-law-scaling","title":"Beyond Power Law Scaling","text":"<p>Kaplan Scaling Law\u4e0eChinchilla Scaling Law\u6240\u7ed9\u51fa\u7684\u90fd\u662f\u6570\u636e\u4e0eloss\u4e4b\u95f4\u7684Power Law\uff0c\u5373\u6570\u636e\u6307\u6570\u589e\u957f\uff0closs\u7ebf\u6027\u6539\u8fdb\u3002\u6839\u636eChinchilla Scaling Law\uff0c\u5927\u6a21\u578b\u7684\u53c2\u6570\u89c4\u6a21\u4e0e\u6570\u636e\u91cf\u4ecd\u67092-3\u4e2a\u6570\u91cf\u7ea7\u7684\u63d0\u5347\u7a7a\u95f4\uff1a</p> Model size(params) Training tokens (round) Training data used (estimate) How much data is that? If 1 book is about 500KB of text (estimate) 70B 1.4 Trillion 2.3TB More books than in The Kindle store on Amazon US (6.4M). 250B 5 Trillion 8.3TB All 30 libraries at Yale University (16.6M). 500B 10 Trillion 16.6TB The Google Books collection (33.2M). 1T 20 Trillion 33.3TB The US Library of Congress (66.6M). 10T 200 Trillion 333TB All US public libraries combined (666M). 100T 2 Quadrillion 3.3PB All bibles ever sold worldwide (6.6B). 250T 5 Quadrillion 8.3PB A stack all the way to the Moon (16.6B). 500T 10 Quadrillion 16.6PB 4 books about every living human (33.2B). Dataset sizes needed to align with Chinchilla data optimization for models<sup>5</sup>. <ol> <li> <p>2020, OpenAI, Language Models are Few-Shot Learners\u00a0\u21a9</p> </li> <li> <p>2020, OpenAI, Scaling Laws for Neural Language Models\u00a0\u21a9</p> </li> <li> <p>2022, DeepMind, Training Compute-Optimal Large Language Models\u00a0\u21a9</p> </li> <li> <p>2022, DeepMind, PaLM: Scaling Language Modeling with Pathways\u00a0\u21a9</p> </li> <li> <p>2022, https://lifearchitect.ai/the-sky-is-bigger/ \u21a9</p> </li> </ol>"},{"location":"2024/01/25/review-dist-train/","title":"\u5173\u4e8e\u5206\u5e03\u5f0f\u6a21\u578b\u5e76\u884c\u7684\u5206\u6b63\u5f0f\u8bc4\u8bba","text":"<p>\u5173\u4e8eData Parallel\uff08DP\uff09\u3001Tensor Parallel\uff08TP\uff09\u548cPipeline Parallel\uff08PP\uff09\u7b49\u5206\u5e03\u5f0f\u5e76\u884c\u7b56\u7565\uff0c\u4e0eMegatron\u3001DeepSpeed\u548cFSDP\u7b49\u5b9e\u73b0\u7684\u4e00\u4e9b\u6df1\u5165\u7814\u7a76\u4e0e\u8ba8\u8bba\u3002\u5206\u5e03\u5f0f\u5e76\u884c\u8bad\u7ec3\u4e3b\u8981\u89e3\u51b3\u4e24\u7c7b\u95ee\u9898\uff1a</p> <ol> <li>\u6a21\u578b\u5206\u7247\uff1a\u6a21\u578b\u5927\u5c0f\u8fdc\u8d85\u5355\u8282\u70b9\u5b58\u50a8\u4e0a\u6765\uff0c\u9700\u8981\u591a\u8282\u70b9\u5206\u7247\u5b58\u50a8\u548c\u8ba1\u7b97\u62c5\uff1b</li> <li>\u5e76\u884c\u8bad\u7ec3\uff1a\u63d0\u9ad8\u5355\u4f4d\u65f6\u95f4\u5185\u7684\u7b97\u529b\u5bc6\u5ea6\uff0c\u8fdb\u800c\u964d\u4f4e\u6574\u4f53\u8bad\u7ec3\u65f6\u95f4\uff1b \u5206\u5e03\u5f0f\u5e76\u884c\u8bad\u7ec3\u51e0\u4e4e\u603b\u662f\u4f1a\u5f15\u5165\u6602\u8d35\u7684\u6210\u672c\uff0c\u6bd4\u5982\u589e\u52a0\u4e86\u6602\u8d35\u7684\u591a\u8282\u70b9\u901a\u4fe1\u3001\u5f15\u5165\u4e86\u989d\u5916\u7684\u591a\u673a\u7a33\u5b9a\u6027\u95ee\u9898\u3001\u4ee5\u53ca\u989d\u5916\u7684\u5f00\u53d1\u4e0e\u8c03\u8bd5\u6210\u672c\u7b49\uff0c\u56e0\u6b64\u6211\u4eec\u5e94\u8be5\u5c3d\u91cf\u907f\u514d\u5f15\u5165\u5206\u5e03\u5f0f\u5e76\u884c\u8bad\u7ec3\u3002\u800c\u4e0d\u5f97\u4e0d\u5f15\u5165\u5206\u5e03\u5f0f\u8bad\u7ec3\u7684\u573a\u666f\u4e2d\uff0c\u4e5f\u5e94\u5145\u5206\u8003\u8651\u901a\u4fe1\u5f00\u9500\uff0c\u5c3d\u91cf\u964d\u4f4e\u5e76\u884c\u7684\u89c4\u6a21\u3002</li> </ol>","tags":["LLM","Training"]},{"location":"2024/01/25/review-dist-train/#3d","title":"3D\u6a21\u578b\u5e76\u884c","text":"<p>\u6839\u636e\u5207\u5206\u7ef4\u5ea6\u7684\u4e0d\u540c\uff0c\u5e76\u884c\u7b56\u7565\u4e3b\u8981\u5206\u4e3a\u5982\u4e0b\u51e0\u7c7b\uff1a</p> <ol> <li>Data Parallel\uff08DP\uff09\uff1a\u5c06\u6570\u636e\u5207\u5206\u6210N\u4efd\uff0c\u6bcf\u4e2ainstance\u91c7\u7528\u5b8c\u5168\u76f8\u540c\u7684\u914d\u7f6e\uff0c\u5728\u8ba1\u7b97\u68af\u5ea6\u540e\u901a\u8fc7all reduce\u5168\u5c40\u540c\u6b65\u68af\u5ea6\uff0c\u5e76\u5206\u522b\u66f4\u65b0\uff1b</li> <li>Tensor Parallel\uff08TP\uff09\uff1a\u5c06\u6bcf\u4e2atensor\u5207\u5206\u6210N\u4efd\uff0c\u5728\u77e9\u9635\u4e58\u6cd5\u7b49\u8ba1\u7b97\u65f6\u8fdb\u884c\u540c\u6b65\uff1b\u4e5f\u79f0\u4e3a\u6a2a\u5207</li> <li>Pipeline Parallel \uff08PP\uff09\uff1a\u5c06\u6a21\u578b\u6309\u6267\u884c\u524d\u540e\u987a\u5e8f\u5207\u5206\u591a\u5206\uff08\u901a\u5e38\u6309layer\u5207\u5206\uff09\uff0c\u5e76\u6839\u636e\u987a\u5e8f\u4f9d\u6b21\u6267\u884c\uff1b</li> <li>Zero Redundancy Optimizer\uff08ZeRO\uff09\uff1a\u540c\u6837\u5c06tensor\u5207\u5206\u6210N\u4efd\uff0c\u4f46\u662f\u5728\u524d\u5411\u4e0e\u540e\u5411\u8ba1\u7b97\u65f6\u5728\u6bcf\u4e2a\u5206\u5e03\u5f0f\u8282\u70b9\u91cd\u5efa\u539f\u59cbTensor\uff1b</li> <li>Sequence Parallel\uff08SP\uff09\uff1a\u5728\u8d85\u957f\u5e8f\u5217\u4e0a\u8fdb\u884c\u8bad\u7ec3\u65f6\uff0c\u5c06\u8ba1\u7b97\u5207\u5206\u81f3\u591a\u4e2a\u8282\u70b9\uff1b</li> </ol> <p></p>","tags":["LLM","Training"]},{"location":"2024/01/25/review-dist-train/#data-parallel","title":"Data Parallel","text":"<p>Data \u5e76\u884c\u4e00\u822c\u662f\u6307\u6839\u636e\u8ba1\u7b97\u8d44\u6e90\u5c06\u6a21\u578b\u590d\u5236\u591a\u4e2a\u526f\u672c\uff0c\u6bcf\u4e2a\u6a21\u578b\u526f\u672c\u72ec\u7acb\u8fdb\u884c\u6570\u636e\u52a0\u8f7d\u4e0e\u524d\u540e\u9879\u8ba1\u7b97\uff0c\u4e4b\u540e\u901a\u8fc7\u4e00\u4e2aall reduce\u901a\u4fe1\u6765\u540c\u6b65\u68af\u5ea6\uff0c\u6700\u540e\u518d\u5206\u522b\u66f4\u65b0\u6743\u91cd\u3002 </p> <p>\u4ece\u5355\u8282\u70b9\u8bad\u7ec3\u5230\u591a\u8282\u70b9\u53ea\u9700\u8981\u6539\u52a8\u4e24\u4e2a\u5730\u65b9\uff1a</p> <ol> <li>data loader\u6839\u636e\u5bf9\u8bad\u7ec3\u6570\u636e\u5207\u7247\uff0c\u5e76\u53ea\u8bfb\u53d6\u5bf9\u5e94\u5206\u7247\u7684\u6570\u636e\uff1b</li> <li>backward\u4e4b\u540e\u901a\u8fc7all reduce\u540c\u6b65\u68af\u5ea6\uff1b \u5728PyTorch\u4e2d\u4e24\u8005\u5206\u522b\u901a\u8fc7<code>torch.utils.data.distributed.DistributedSampler</code>\u4e0e<code>torch.nn.parallel.DistributedDataParallel</code>\u5b9e\u73b0\u3002</li> </ol>","tags":["LLM","Training"]},{"location":"2024/01/25/review-dist-train/#zero-zero-redundancy-optimizer","title":"ZeRO: Zero Redundancy Optimizer","text":"<p>\u901a\u8fc7Data Parallel\u6bd4\u8f83\u5bb9\u6613\u5b9e\u73b0\u52a0\u901f\u8bad\u7ec3\uff0c\u4f46\u5bf9\u4e8e\u4e00\u4e9b\u53c2\u6570\u89c4\u6a21\u8f83\u5927\u7684\u6a21\u578b\uff0c\u5355\u8282\u70b9\u7684\u5185\u5b58/\u663e\u5b58\u96be\u4ee5\u653e\u4e0b\uff0c\u6b64\u65f6\u5c31\u65e0\u6cd5\u901a\u8fc7\u7b80\u5355\u7684Data Parallel\u7684\u6570\u636e\u5207\u7247\u6765\u5b9e\u73b0\u52a0\u901f\u4e86\u3002ZeRO\u6280\u672f\u4e3b\u8981\u5c1d\u8bd5\u901a\u8fc7\u5bf9\u6a21\u578b\u72b6\u6001\u5207\u7247\uff0c\u5b9e\u73b0\u5927\u6a21\u578b\u7684Data Parallel\u8bad\u7ec3\u3002\u5177\u4f53\u539f\u7406\u5982\u4e0b\u56fe\u6240\u793a\uff1a  \u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6a21\u578b\u72b6\u6001\u53ef\u5206\u4e3a\u4e09\u90e8\u5206\uff1a\u53c2\u6570\uff08Parameters\uff09\u3001 \u68af\u5ea6\uff08Gradients\uff09\u548c\u4f18\u5316\u5668\u72b6\u6001\uff08Optimizer States\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u4e09\u8005\u5206\u522b\u8fdb\u884c\u5207\u5206\u5e76\u5b58\u50a8\u5230\u591a\u4e2a\u8282\u70b9\u4e0a\u53bb\u3002\u6839\u636e\u5207\u5206\u65b9\u5f0f\u7684\u4e0d\u540c\u53ef\u4ee5\u5206\u4e3a\u4e09\u4e2astage\uff1a - ZeRO Stage 1\uff1a\u5207\u5206Optimizer States - ZeRO Stage 2\uff1a\u5207\u5206Optimizer States\u4e0eGradients - ZeRO Stage 3\uff1a\u5207\u5206Parameters \u5176\u4e2dZeRO1\u548cZeRO2\u5e76\u4e0d\u4f1a\u589e\u52a0\u901a\u4fe1\u91cf\uff0c\u56e0\u6b64\u5b9e\u9645\u5de5\u7a0b\u4e2d\u88ab\u91c7\u7528\u66f4\u591a\u3002</p>","tags":["LLM","Training"]},{"location":"2024/01/25/review-dist-train/#fsdp-fully-sharded-data-parallel","title":"FSDP: Fully Sharded Data Parallel","text":"<p>FSDP\u662fPyTorch\u5728v1.11\u4e4b\u540e\u5f15\u5165\u7684\u5185\u7f6eData Parallel\u5e76\u884c\u6a21\u5f0f\u3002PyTorch\u5b98\u65b9\u5728Data Parallel\u6280\u672f\u7684\u53d1\u5c55\u8def\u5f84\u662fDP -&gt; DDP -&gt; FSDP\uff0c\u4e0d\u65ad\u5438\u7eb3\u6765\u81ea\u5f00\u6e90\u793e\u533a\u7684\u65b0\u6280\u672f\u3002 </p>","tags":["LLM","Training"]},{"location":"2024/01/25/review-dist-train/#tensor-paralle","title":"Tensor Paralle","text":"<p>\u5bf9\u4e8e\u4e00\u4e9b\u8bed\u8a00\u6a21\u578b\u6765\u8bf4\uff0c\u6743\u91cd\u3001\u68af\u5ea6\u4ee5\u53ca\u4f18\u5316\u5668\u72b6\u6001\u53ef\u80fd\u5e76\u4e0d\u662f\u5185\u5b58/\u663e\u5b58\u5360\u7528\u7684\u5927\u5934\uff0c\u6fc0\u6d3b\u503c\u540c\u6837\u4f1a\u5360\u7528\u5927\u91cf\u5185\u5b58\u3002\u56e0\u6b64\u4ec5\u4ec5\u4f7f\u7528ZeRO\u6280\u672f\u5e76\u4e0d\u80fd\u5f88\u597d\u652f\u6301\u8d85\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u3002\u6b64\u65f6\u9700\u8981Tensor Parallel\u8fdb\u4e00\u6b65\u5bf9\u6fc0\u6d3b\u503c\u8fdb\u884c\u5207\u5206\u3002 Tensor Parallel\u6280\u672f\u7684\u57fa\u7840\u662f\u77e9\u9635\u5206\u5757\u4e58\u6cd5\uff0c\u5982\u4e0b\u56fe\u6240\u793a\uff1a  \u77e9\u9635\u4e58\u6cd5\u7684\u5e76\u884c\u53ef\u5206\u4e3a\u5217\u5e76\u884c\u4e0e\u884c\u5e76\u884c\uff1a - \u5217\u5e76\u884c\uff1a $$ GeLU(WA) = GeLU(W[A_1, A_2, \u2026, A_n]) = [GeLU(WA_1),GeLU(WA_2),\u2026,GeLU(WA_n)] $$ - \u884c\u5e76\u884c\uff1a$$ GeLU(WA) = GeLU( [W_1, W_2, \u2026, W_n] \\left [ \\begin{smallmatrix} A_1 \\ A_2 \\ \u2026 \\ A_n  \\end{smallmatrix} \\right ] ) = GeLU(W_1A_1+W_2A_2+\u2026+W_nA_n) $$</p>","tags":["LLM","Training"]},{"location":"2024/01/25/review-dist-train/#pipeline","title":"Pipeline\u5e76\u884c","text":"","tags":["LLM","Training"]},{"location":"2024/01/25/review-dist-train/#sequence","title":"Sequence\u5e76\u884c","text":"","tags":["LLM","Training"]},{"location":"archive/2025/","title":"2025","text":""},{"location":"archive/2024/","title":"2024","text":""},{"location":"category/llm/","title":"LLM","text":""},{"location":"category/training/","title":"Training","text":""},{"location":"category/fp8/","title":"FP8","text":""},{"location":"category/rl/","title":"RL","text":""}]}